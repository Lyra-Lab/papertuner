{
  "id": "http://arxiv.org/abs/cmp-lg/9702012v1",
  "title": "Design and Implementation of a Computational Lexicon for Turkish",
  "authors": [
    "Abdullah Kurtulus Yorulmaz"
  ],
  "abstract": "All natural language processing systems (such as parsers, generators,\ntaggers) need to have access to a lexicon about the words in the language. This\nthesis presents a lexicon architecture for natural language processing in\nTurkish. Given a query form consisting of a surface form and other features\nacting as restrictions, the lexicon produces feature structures containing\nmorphosyntactic, syntactic, and semantic information for all possible\ninterpretations of the surface form satisfying those restrictions. The lexicon\nis based on contemporary approaches like feature-based representation,\ninheritance, and unification. It makes use of two information sources: a\nmorphological processor and a lexical database containing all the open and\nclosed-class words of Turkish. The system has been implemented in SICStus\nProlog as a standalone module for use in natural language processing\napplications.",
  "text": "arXiv:cmp-lg/9702012v1  19 Feb 1997\nDESIGN AND IMPLEMENTATION\nOF\nA COMPUTATIONAL LEXICON\nFOR TURKISH\na thesis\nsubmitted to the department of computer engineering\nand information science\nand the institute of engineering and science\nof bilkent university\nin partial fulfillment of the requirements\nfor the degree of\nmaster of science\nBy\nAbdullah Kurtulu¸s Yorulmaz\nFebruary, 1997\nii\nI certify that I have read this thesis and that in my opinion it is\nfully adequate, in scope and in quality, as a thesis for the degree of\nMaster of Science.\nAsst. Prof. Kemal Oﬂazer(Advisor)\nI certify that I have read this thesis and that in my opinion it is\nfully adequate, in scope and in quality, as a thesis for the degree of\nMaster of Science.\nAssoc. Prof. Halil Altay G¨uvenir\nI certify that I have read this thesis and that in my opinion it is\nfully adequate, in scope and in quality, as a thesis for the degree of\nMaster of Science.\nAsst. Prof. ˙Ilyas C¸i¸cekli\nApproved for the Institute of Engineering and Science:\nProf. Dr. Mehmet Baray, Director of Institute of Engineering and Science\niii\nABSTRACT\nDESIGN AND IMPLEMENTATION\nOF\nA COMPUTATIONAL LEXICON\nFOR TURKISH\nAbdullah Kurtulu¸s Yorulmaz\nM.S. in Computer Engineering and Information Science\nSupervisor: Asst. Prof. Kemal Oﬂazer\nFebruary, 1997\nAll natural language processing systems (such as parsers, generators, taggers) need to have\naccess to a lexicon about the words in the language. This thesis presents a lexicon architecture\nfor natural language processing in Turkish. Given a query form consisting of a surface form\nand other features acting as restrictions, the lexicon produces feature structures containing\nmorphosyntactic, syntactic, and semantic information for all possible interpretations of the\nsurface form satisfying those restrictions. The lexicon is based on contemporary approaches\nlike feature-based representation, inheritance, and uniﬁcation. It makes use of two information\nsources: a morphological processor and a lexical database containing all the open and closed-\nclass words of Turkish. The system has been implemented in SICStus Prolog as a standalone\nmodule for use in natural language processing applications.\nKey words: Natural Language Processing, Lexicon\niv\n¨OZET\nT¨URKC¸E ˙IC¸ ˙IN\nB˙IR HESAPSAL S¨OZL¨UˇG¨UN TASARIMI VE\nGERC¸EKLES¸T˙IR˙ILMES˙I\nAbdullah Kurtulu¸s Yorulmaz\nBilgisayar ve Enformatik M¨uhendisli˘gi, Y¨uksek Lisans\nTez Y¨oneticisi: Yrd. Do¸c. Dr. Kemal Oﬂazer\nS¸ubat, 1997\nB¨ut¨un doˇgal dil i¸sleme sistemleri (¨orneˇgin ¸c¨oz¨umleyiciler, ¨ureticiler, metin i¸saretleyiciler) dildeki\nkelimeler hakkında, bir s¨ozl¨uˇge eri¸smeye ihtiya¸c duyarlar. Bu tezde, T¨urk¸ce’de doˇgal dil i¸sleme\ni¸cin bir s¨ozl¨uk mimarisi sunulmu¸stur. Bir kelimenin y¨uzeysel hali ve kısıtlayıcı diˇger ¨ozellikler\ni¸ceren sorguya kar¸sılık, s¨ozl¨uk, verilen kelimenin y¨uzeysel halinin, bu kısıtlayıcı ¨ozellikleri\nsaˇglayan her ¸c¨oz¨um¨u i¸cin bi¸cimbirimsel/s¨ozdizinsel, ¸sekilsel ve anlamsal ¨ozellikler i¸ceren bir\n¨ozellik yapısı ¨uretir. S¨ozl¨uk, ¨ozellik temelli temsil, kalıtım ve birle¸stirme gibi ¸caˇgda¸s yakla¸sımlara\ndayanır. ˙Iki bilgi kaynaˇgı kullanır: bir s¨ozc¨ukyapısal i¸sleyici ve T¨urk¸ce’nin b¨ut¨un a¸cık ve ka-\npalı kelime gruplarını i¸ceren bir kelime veritabanı.\nSistem, SICStus Prolog’da kendi ba¸sına\n¸calı¸sabilecek ve doˇgal dil i¸sleme uygulamalarında kullanılabilecek ¸sekilde ger¸cekle¸stirilmi¸stir.\nAnahtar s¨ozc¨ukler: Do˘gal Dil ˙I¸sleme, S¨ozl¨uk\nv\nACKNOWLEDGMENTS\nI am very grateful to my supervisor, Asst. Prof. Kemal Oﬂazer, for his invaluable guidance,\nmotivation, and patience during the development of this thesis. It was a real pleasure to work\nwith him.\nI would like to thank Assoc. Prof. Halil Altay G¨uvenir and Asst. Prof. ˙Ilyas C¸i¸cekli for reading\nand commenting on the thesis.\nI owe special thanks to my colleagues Dilek Z. Hakkani and G¨okhan T¨ur and other friends Y¨ucel\nSaygın, Uˇgur C¸etintemel, Gamze D. Tunalı and Murat Bayraktar for their endless intellectual\nand moral support during my graduate study.\nFinally, I would like to express my deepest gratitude to my parents for their inﬁnite moral\nsupport and patience to me. I dedicate this thesis to them.\nContents\n1\nIntroduction\n1\n2\nThe Lexicon\n4\n2.1\nLexicon\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4\n2.2\nThe Role of Lexicon in NLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n2.2.1\nThe Role of Lexicon in Syntactic Analysis . . . . . . . . . . . . . . . . .\n5\n2.2.2\nThe Role of Lexicon in Verb Sense Disambiguation . . . . . . . . . . . .\n8\n2.3\nExample Work\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n10\n3\nA Lexicon Design for Turkish\n13\n3.1\nLexicon Architecture . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.2\nLexical Representation Langugage\n. . . . . . . . . . . . . . . . . . . . . . . . .\n14\n3.3\nLexical Categories\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.4\nNominals\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.4.1\nNouns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.4.2\nPronouns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n3.4.3\nSentential Nominals\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n29\n3.5\nAdjectivals\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n3.5.1\nDeterminers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n35\nvi\nCONTENTS\nvii\n3.5.2\nAdjectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n3.6\nAdverbials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n45\n3.6.1\nDirection Adverbs\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n3.6.2\nTemporal Adverbs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n47\n3.6.3\nManner Adverbs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n50\n3.6.4\nQuantitative Adverbs\n. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n53\n3.6.5\nSentential Adverbs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n3.7\nVerbs\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n3.7.1\nPredicative Verbs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n60\n3.7.2\nExistential Verbs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n69\n3.7.3\nAttributive Verbs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n69\n3.8\nConjunctions\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n72\n3.8.1\nCoordinating Conjunctions\n. . . . . . . . . . . . . . . . . . . . . . . . .\n73\n3.8.2\nBracketing Conjunctions . . . . . . . . . . . . . . . . . . . . . . . . . . .\n73\n3.8.3\nSentential Conjunctions . . . . . . . . . . . . . . . . . . . . . . . . . . .\n74\n3.9\nPost-positions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n74\n3.9.1\nPost-positions with Nominative Subcategorization\n. . . . . . . . . . . .\n75\n3.9.2\nPost-positions with Accusative Subcategorization . . . . . . . . . . . . .\n77\n3.9.3\nPost-positions with Dative Subcategorization . . . . . . . . . . . . . . .\n77\n3.9.4\nPost-positions with Ablative Subcategorization . . . . . . . . . . . . . .\n77\n3.9.5\nPost-positions with Genitive Subcategorization . . . . . . . . . . . . . .\n77\n3.9.6\nPost-positions with Instrumental Subcategorization . . . . . . . . . . . .\n78\n4\nOperational Aspects of the Lexicon\n79\nCONTENTS\nviii\n4.1\nInterfacing with the Lexicon . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n80\n4.2\nProducing Feature Structures . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n84\n4.2.1\nMorphological Analysis\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n85\n4.2.2\nRetrieving Information in the Static Lexicon\n. . . . . . . . . . . . . . .\n86\n4.2.3\nApplication of Restrictions\n. . . . . . . . . . . . . . . . . . . . . . . . .\n93\n4.3\nProblems and Limitations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n93\n5\nImplementation\n95\n5.1\nFeature Structure Database . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n96\n5.2\nSample Runs\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n97\n5.2.1\nExample 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n97\n5.2.2\nExample 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n102\n5.2.3\nExample 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n106\n6\nConclusions and Suggestions\n111\nA The Lexicon Categories\n114\nList of Figures\n1.1\nSimpliﬁed architecture of the MT system that would use our lexicon. . . . . . .\n3\n3.1\nArchitecture of the lexicon.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n3.2\nThe main lexical categories of Turkish. . . . . . . . . . . . . . . . . . . . . . . .\n16\n3.3\nSubcategories of nominals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.4\nLexicon categories of nominals. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n17\n3.5\nSubcategories of nouns.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n18\n3.6\nForms of common nouns.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n19\n3.7\nDerivation history of evdekiler.\n. . . . . . . . . . . . . . . . . . . . . . . . . . .\n20\n3.8\nSubcategories of pronouns. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n26\n3.9\nSubcategories of sentential nominals. . . . . . . . . . . . . . . . . . . . . . . . .\n29\n3.10 Subcategories of inﬁnitives.\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n30\n3.11 Subcategories of participles. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n33\n3.12 Subcategories of adjectivals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n3.13 Lexicon categories of adjectivals.\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n34\n3.14 Subcategories of determiners. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n36\n3.15 Subcategories of adjectives. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n38\n3.16 Subcategories of quantitative adjectives. . . . . . . . . . . . . . . . . . . . . . .\n38\nix\nLIST OF FIGURES\nx\n3.17 Subcategories of adverbials. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n45\n3.18 Lexicon categories of adverbials.\n. . . . . . . . . . . . . . . . . . . . . . . . . .\n46\n3.19 Subcategories of temporal adverbs. . . . . . . . . . . . . . . . . . . . . . . . . .\n47\n3.20 Subcategories of time-period adverbs.\n. . . . . . . . . . . . . . . . . . . . . . .\n50\n3.21 Subcategories of manner adverbs. . . . . . . . . . . . . . . . . . . . . . . . . . .\n51\n3.22 Subcategories of quantitative adverbs. . . . . . . . . . . . . . . . . . . . . . . .\n53\n3.23 Subcategories of verbs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n54\n3.24 Subcategories of conjunctions. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n73\n3.25 Subcategories of post-positions. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n74\n4.1\nData ﬂow in the lexicon. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n81\n4.2\nNLP subsystems interfacing with the lexicon. . . . . . . . . . . . . . . . . . . .\n82\n4.3\nInterpretations of the surface form kazma. . . . . . . . . . . . . . . . . . . . . .\n85\n4.4\nThe derivation path to the manner adverb akıllıca. . . . . . . . . . . . . . . . .\n86\n4.5\nA portion of the table used for category mapping for root words. . . . . . . . .\n87\n4.6\nNested feature structures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n89\n5.1\nThe entry for the existential verb var in the feature structure database.\n. . . .\n96\n5.2\nProlog representation of a feature structure. . . . . . . . . . . . . . . . . . . . .\n96\nList of Tables\n4.1\nThe table used for category mapping for derived words.\n. . . . . . . . . . . . .\n88\nA.1 The lexicon categories (nominals and adjectivals) . . . . . . . . . . . . . . . . .\n114\nA.2 The lexicon categories (adverbials, verbs, conjunctions, and post-positions)\n. .\n115\nxi\nChapter 1\nIntroduction\nNatural language processing (NLP) is a research area, under which the aim is to design and\ndevelop systems to process, understand, and interpret natural language. It employs knowledge\nfrom various ﬁelds like artiﬁcial intelligence (in knowledge representation, reasoning), formal\nlanguage theory (in language analysis, parsing), and theoretical and computational linguistics\n(in models of language structure).\nThere are many applications of NLP such as translation of natural language text from one\nlanguage to another, interfacing machines with speech or speech-to-speech translation, natural\nlanguage interfaces to databases, text summarization, text preparation aids such as spelling\nand grammar checking/correction, etc.\nOne of the ﬁrst applications of NLP is machine translation (MT). The research was funded by\nmilitary and intelligence communities. These systems, what we call ﬁrst generation, translate\ntext almost word by word; the result was a failure.\nBut considering the lack of theories,\nmethods, and resources with semantics and ambiguities in natural language text, the result is\nnot surprising [4]. 1 Today with the advance of theories, resources, etc., MT is not a dream;\neven there are MT systems available in the market.\nMany components of NLP systems, like syntactic analyzers, text generators, taggers, and se-\nmantic disambiguators, need knowledge about words in the language. This information is stored\n1 Consider the following well-known utterance:\n(1) a. Time ﬂies like an arrow.\nb. Fruit ﬂies like a banana.\nThe ambiguity in the sentences above can be resolved by utilizing the knowledge: fruit ﬂies is\na meaningful phrase but time ﬂies is not. However, even today, most systems cannot access\nthis kind of information.\n1\nCHAPTER 1. INTRODUCTION\n2\nin the lexicon, which is becoming one of the central components of all NLP systems.\nIn this thesis, we designed and implemented a computational lexicon for Turkish to be employed\nin an MT project, which aims to develop scientiﬁc background and tools to translate computer\nmanuals from Turkish to English and vice versa (see Figure 1.1 for a simpliﬁed architecture of\nthis system).\nA similar work for this project is the design and implementation of a verb lexicon for Turkish\nby Yılmaz [16]. This lexicon contains only verb entries to be utilized in syntactic analysis and\nverb sense disambiguation.\nOur work aims to develop a generic lexicon for Turkish, which can provide morphosyntactic,\nsyntactic, and semantic information about words to NLP systems. The lexicon contains entries\nfor all lexical categories of Turkish with the information content also covering the Yılmaz’s\nwork. The morphosyntactic information is not directly encoded in the lexicon, rather obtained\nthrough a morphological analyzer integrated into the system.\nThe development of our work is carried out in two steps:\n1. determining the lexical speciﬁcation for each of the lexical categories of Turkish, that is\nmorphosyntactic, syntactic and semantic phenomena to be encoded in the lexicon,\n2. developing a standalone system that will provide the encoded information to NLP systems\nfor a given input.\nIn this thesis, we present design and implementation of such a lexicon.\nThe outline of the thesis is as follows: In Chapter 2, we introduce the concept of lexicon with\nexamples from related work.\nIn Chapter 3, we present a comprehensive categorization for\nTurkish lexical types and associated lexical speciﬁcation. Next chapter gives the operational\naspects of our lexicon, that is the interface of the system and algorithms used in producing the\nresult. In Chapter 5, we go through the implementation of the system and give sample runs.\nChapter 6 concludes and gives suggestions.\nCHAPTER 1. INTRODUCTION\n3\nMorphological\nanalyzer/generator\nTurkish lexicon for \nanalysis\nTurkish lexicon for \ngeneration\nEnglish parser\nEnglish generator\nmachine translation\nHuman-assisted\napplication\nTurkish parser\nTurkish generator\nFigure 1.1: Simpliﬁed architecture of the MT system that would use our lexicon.\nChapter 2\nThe Lexicon\nLexicon is the collection of morphological/morphosyntactic, syntactic and semantic information\nabout words in the language. It has been a critical component of all NLP systems as they move\nfrom toy system operating in demonstration mode to real world applications requiring wider\nvocabulary coverage and richer information content.\nIn this chapter, we will ﬁrst brieﬂy introduce the concept of lexicon and the need for it. Then,\nwe will give the role of lexicon in NLP with speciﬁc examples from syntactic analysis and verb\nsense disambiguation. Finally, we will present an example work, which is on reaching a common\nlexical speciﬁcation in the lexicon among European languages.\n2.1\nLexicon\nFor a long time the lexicon was seen as a collection of idiosyncratic information about words in\nthe language. As the requirements of NLP systems, which perform various tasks ranging from\nspeech recognition to machine translation (MT) in wide subject domains, grow, those systems\nneed larger lexicons. Even simple applications such as spelling checkers may require morpho-\nlogical, orthographic, phonological, syntactic, and semantic information (for disambiguation)\nwith realistic vocabulary coverage [1]. For instance, The Core Language Engine, which is a\nuniﬁcation-based parsing and generation system for English, has a lexicon containing 1800\nsenses of 1200 words and phrases [2]. Thus, the lexicon design and development has become\nthe one of the central issues for all NLP systems.\nThere are two ways to develop the information content of a lexicon: hand-crafting and use of\nmachine-readable resources. The ﬁrst is the classical and costly way of developing the content.\nHowever, there is a growing trend to use existing machine-readable resources, such as electronic\n4\nCHAPTER 2. THE LEXICON\n5\ndictionaries and text corpora, to derive useful information. Research in this area has yielded\nsigniﬁcant results in extracting morphosyntactic and syntactic information, but the results in\nsemantic information side are not yet satisfactory [10].\n2.2\nThe Role of Lexicon in NLP\nNLP systems need to access lexical knowledge about words in the language. This information\ncan be morphosyntactic, such as stem, inﬂectional and derivational suﬃxes (by means of list-\ning them explicitly or generation), syntactic, such as grammatical category and complement\nstructures, and semantic, such as multiple senses and thematic roles. Depending on the NLP\ntask being performed, other information can be utilized such as mapping between lexical units\nand ontological concepts for transfer tasks in MT, text planning information for generation,\northographic and phonological information for speech processing applications.\nIn the following two sections, we will describe the role of lexicon in syntactic analysis and verb\nsense disambiguation.\n2.2.1\nThe Role of Lexicon in Syntactic Analysis\nThe following paragraph is taken from Zaenen and Uszkoreit [17], which brieﬂy describes text\nanalysis:\n“We understand larger textual units by combining our understanding of smaller ones. The main\naim of linguistic theory is to show how these units of meaning arise out of the combination of\nthe smaller ones. This is modeled by means of a grammar. Computational linguistics then\ntries to implement this process in an eﬃcient way. It is traditional to subdivide the task into\nsyntax and semantics, where syntax describes how the diﬀerent formal elements of a textual\nunit, most often the sentence, can be combined and semantics describes how the interpretation\nis calculated.”\nThe grammar consists of two parts: a set of rules describing how to combine small textual\nunits into larger ones, and a lexicon containing information about those small units. In recent\ntheories of grammar, the ﬁrst part is reduced to one or two general principles, and the rest of\nthe information is encoded in the lexicon.\nNow we will brieﬂy describe the analysis lexicon in KBMT-89 system [5].\nKBMT-89 is a\nknowledge-based machine translation system, in which source language text is analyzed into a\nlanguage independent representation (namely interlingua) and generated in the target language.\nThere are two other methods used in MT other than interlingua method: direct and transfer\nCHAPTER 2. THE LEXICON\n6\nmethod. In the former one, the source text is directly translated to target language, almost\nword by word with some arrangements, however, in the second one source text is analyzed\ninto an abstract representation, which is then transfered into another abstract representation\nfor the target language, and ﬁnally generated as the target language text. Knowledge-based\nMT requires more syntactic and semantic information, so a larger and richer lexicon, than the\nother methods, such as language independent knowledge-base for modeling the subworld of\ntranslation, etc.\nKnowledge acquisition in KBMT-89 is manual, but aided with special tools so that partial\nautomation is achieved. KBMT-89 uses three types of lexicon:\n1. concept lexicon, which stores semantic information for parsing and generation,\n2. generation lexicon, which contains information for the open-class words (e.g., nouns, which\naccept new words in time), in the target language (in that special case, it is Japanese),\nand\n3. analysis lexicon, which stores morphological and syntactic information, word-to-concept\nmapping rules, and information for the mapping case role structures (thematic roles) to\nsubcategorization patterns.\nEach entry in the analysis lexicon contains the following information: a word, its syntactic\ncategory, inﬂection, root-word form, syntactic features, and mappings. Syntactic features and\nmappings can be speciﬁed locally or through inheritance by properly setting a pointer to a class\nin the syntactic feature or structural mapping hierarchy.\nHere are two example entries from the English analysis lexicon for the verb and noun interpre-\ntations of note:\n(‘‘note’’ (CAT V)\n(CONJ-FORM INFINITIVE)\n(FEATURES\n(CLASS CAUS-INCHO-VERB-FEAT)\n(all-features\n(*OR*\n((FORM INF) (VALENCY (*OR* INTRANS TRANS)) (COMP-TYPE NO)\n(ROOT NOTE))\n((PERSON (*OR* 1 2 3)) (NUMBER PLURAL) (TENSE PRESENT)\n(FORM FINITE) (VALENCY INTRANS TRANS)\n(COMP-TYPE NO) (ROOT NOTE))\nCHAPTER 2. THE LEXICON\n7\n((PERSON (*OR* 1 2)) (NUMBER SINGULAR) (TENSE PRESENT)\n(FORM FINITE) (VALENCY INTRANS TRANS))\n(COMP-TYPE NO) (ROOT NOTE))))\n(MAPPING (local\n(HEAD (RECORD-INFORMATION)))\n(CLASS AG-TH-VERB-MAP)))\nIn the frame above, ﬁrst three slots give the headword, its category and word form, that is\nnote, verb and inﬁnitive, respectively. The next slot, FEATURES, gives the syntactic features by\ninheriting the features of the class CAUS-INCHO-VERB-FEAT, which are the features of causative-\ninchoative verb class, and adding other features locally, such as valence, root word form, and\nagreement marker in each of the three cases, as arguments of *OR*. The last slot, MAPPING,\ngives word-to-concept mapping, that is the verb note is mapped to the ontological concept\nRECORD-INFORMATION in the concept lexicon, and mapping of case role structures to subcatego-\nrization patterns by inheriting from AG-TH-VERB-MAP class in the structural mapping hierarchy,\nwhich is the mapping for agent-theme verbs.\n(‘‘note’’ (CAT N)\n(CONJ-FORM SINGULAR)\n(FEATURES\n(CLASS DEFAULT-NOUN-FEAT)\n(all-features\n(PERSON 3) (NUMBER SINGULAR) (COUNT YES) (PROPER NO)\n(MEAS-UNIT NO) (ROOT NOTE)))\n(MAPPING\n(local\n(HEAD (MENTAL-CONTENT)))\n(local\n(HEAD (TEXT-GROUP (CONVEY (COMMUNICATIVE-CONTENT)))))\n(CLASS OBJECT-MAP)))\nThe frame above states that the noun note is singular, inherits all the syntactic features of the\nclass DEFAULT-NOUN-FEAT in addition to its local features; for example its agreement marker\nis 3sg, it is countable and not a proper noun.\nThe MAPPING slot gives its mapping to the\nentries in the concept lexicon, that is note describes a mental content or a text group convey-\ning a communicative content. It also inherits all the word-to-concept mappings of the class\nOBJECT-MAP.\nCHAPTER 2. THE LEXICON\n8\n2.2.2\nThe Role of Lexicon in Verb Sense Disambiguation\nThe second speciﬁc usage of the lexicon that we will describe is in verb sense disambiguation\nspeciﬁcally for Turkish due to the work by Yılmaz [16].\nVerb is the most important component in the sentence; it gives the predicate. Thus, resolving\nlexical ambiguities concerning the verb is very important in syntactic analysis, especially in\nMT. There are three kinds of lexical ambiguities:\n1. polysemy, in which case a lexical item has more than one senses close to each other, as in\npara ye- (cost a lot of money) and kafayı ye- (get mentally deranged). For example, T¨urk\nDil Kurumu Dictionary gives 40 senses for the verb ¸cık and 32 senses for the verb at.\n2. homonymy, in which case the words have more than one interpretation having no obvious\nrelation among them, e.g., vurul- has two interpretations: fall in love with and be wounded.\n3. categorical ambiguity, in which case the words have interpretations belonging to more\nthan one category, as in ek (noun, appendix/suﬃx) and (verb, sow).\nThe claim in Yılmaz’s work is that by trying to match the morphological, syntactic, and\nsemantic information in the sentential context of a verb (i.e., the information in its complements)\nwith the corresponding information of the verb entries in the lexicon, the correct interpretation\nand sense of the verb can be determined. For instance, consider the following example:\n(2) a. Memur\npara\nyedi.\nofficial money accept bribe+PAST+3SG\n‘The oﬃcial accepted bribe.’\nb. Araba ¸cok\npara\nyedi.\ncar\na lot of money cost+PAST+3SG\n‘The car costed a lot.’\nIn the sentences above, the verb ye- is used in two diﬀerent senses as accept bribe and cost a lot.\nThe encoding in the lexicon for the ﬁrst sense states that the head of the direct object’s noun\nphrase is para with no possessive or case marking, and the subject is human. For the second\nsense, the head of the direct object’s noun phrase is para and the subject is non-human. By\napplying those constraints, the correct interpretation can be determined. In the application of\nsemantic constraints, however, an ontology (i.e., knowledge-base, which describes the objects,\nevents, etc. in a subject domain) for nouns should be utilized, for example, in testing whether\nmemur is human or not.\nCHAPTER 2. THE LEXICON\n9\nThe lexicon consists of a list of entries for verbs. Each entry is identiﬁed with its headword, and\ncontains a list of argument structures, in which there are the labels of the arguments, morpho-\nlogical, syntactic, and semantic constraints, and a list of senses associated with those argument\nstructures. Each sense has another set of constraints speciﬁc for that sense and some descrip-\ntive information, such as semantic category, mapping of thematic roles to subcategorization\npatterns, concept name, etc.\nBelow, we provide the lexicon entry for the verb ilet-, which has two argument structures\nand three senses (i.e., conduct, convey, and tell). In order to save space, we omit the second\nargument structure and the last sense associated with it. Here is the lexicon entry for ilet-:\n((HEAD . \"ilet\")\n(ENTRY\n(ARG-ST1\n(ARGS\n(SUBJECT\n(LABEL . S)\n(SEM . T)\n(SYN OCC S OPTIONAL)\n(MORPH . T))\n(DIR-OBJ\n(LABEL . D)\n(SEM . T)\n(SYN OCC D OBLIGATORY)\n(MORPH\n(OR\n(1 CASE D NOM)\n(2 CASE D ACC)))))\n(SENSES\n(SENSE1\n(CONST POWER-ENERGY-PHYSICALOBJECT D)\n(V-CAT PROCESS-ACTION)\n(T-ROLE\n(1 AGENT S)\n(2 THEME D))\n(C-NAME . \"to conduct\")\n(EXAMPLE . \"katIlar sesi en iyi iletir.\"))\n(SENSE2\nCHAPTER 2. THE LEXICON\n10\n(CONST . T)\n(V-CAT PROCESS-ACTION)\n(T-ROLE\n(1 AGENT S)\n(2 THEME D))\n(C-NAME . \"to convey\")\n(EXAMPLE . \"yardImI ilettiler.\"))))\n(ARG-ST2\n...))\n(ALIAS-LIST ))\nIn the ﬁrst argument structure, there are subject and direct object. The subject is optional,\nwhereas the object is obligatory, and nominative or accusative case-marked. These are mor-\nphological and syntactic constraints speciﬁed in MORPH and SYN slots of the arguments, and no\nother constraint is posed by this argument structure. There are two senses associated with this\nstructure. The ﬁrst poses a semantic constraint in CONST slot, which requires that the direct\nobject must be an instance of POWER-ENERGY-PHYSICALOBJECT class, like electricity or sound.\nThen it gives verb category, which is process-action, mapping of thematic roles to subcatego-\nrization patterns, which maps agent to subject and theme to direct object, and concept name,\nwhich is to conduct, with an example sentence. The second sense does not pose any additional\nconstraint. The verb category and thematic role mapping of this sense are the same with those\nof the previous one. Then, the concept name is given as to convey with an example sentence.\n2.3\nExample Work\nDue to the growing needs of NLP systems for larger and richer lexicons, the cost of designing\nand developing lexicons with broad coverage and adequately rich information content is getting\nhigh. An example work, which has developed such large lexical resources, may be the Electronic\nDictionary Research (EDR) project (Japan, 1990), which run for 9 years, costed 100 million\nUS dollars and intended to develop bilingual resources for English and Japanese containing\n200,000 words, term banks containing 100,000 words, and a concept dictionary containing\n400,000 concepts. Although the development is aided by special tools, the actual eﬀort is due\nto the researchers themselves [1].\nIn order to avoid such high costs, the research institutions and companies are trying to combine\ntheir eﬀorts in developing publicly available, large scale language resources, which have adequate\ninformation content, and are generic enough (multifunctional) to satisfy various requirements\nof wide range of NLP applications. Examples of such eﬀorts include ESPRIT BRA (Basic\nResearch Action) ACQUILEX aiming reuse of information extracted from machine-readable\nCHAPTER 2. THE LEXICON\n11\ndictionaries, WordNet Project at Princeton, which created a large network of word senses\nrelated with semantic relations, and LRE EAGLES (Expert Advisory Group on Language\nEngineering Standards) project, which tries to reach a common lexical speciﬁcation at some\nlevel of linguistic detail among European languages [6].\nIn the rest of this section, we will concentrate on the EAGLES project.\nThe information\ngiven below is mainly received from Monachini and Calzolari [9]. The objective of this work\nis to propose a common set of morphosyntactic features encoded in lexicons and corpora in\nEuropean languages, namely Italian, English, German, Dutch, Greek, French, Danish, Spanish,\nand Portuguese.\nThe project has gone through three phases:\n1. to survey previous work on encoding morphosyntactic phenomena in lexicons and text\ncorpora, e.g., on MULTILEX and GENELEX models, etc.,\n2. to work on linguistic annotation of text and lexical description in lexicons to reach a\ncompatible set of features,\n3. to test the common proposal by applying concretely to European languages.\nThe common set of features came after the completion of the second phase, and is described in\nthree main levels corresponding to the level of obligatoriness:\n1. Level 0 contains only the part-of-speech category, which is the unique obligatory feature.\n2. Level 1 gives grammatical features, such as gender, number, person, etc. These are gener-\nally encoded in lexicons and corpora, and called recommended features, which constitute\nthe minimal core set of common features.\n3. Level 2 is subdivided into two:\n• Level 2a contains features which are common to languages, but either not generally\nencoded in lexicons and corpora or not purely morphosyntactic (e.g., countability\nfor nouns). These are considered as optional features.\n• Level 2b gives language-speciﬁc features.\nThe multilayered description, instead of a ﬂat one, gives more ﬂexibility in choosing the level\ndetail in speciﬁcation to match the requirements of applications. As going down from Level\n0 to Level 2, the description reaches ﬁner granularity, and the information encoded increases.\nAdditionally, this type of description helps to extend or update the framework.\nCHAPTER 2. THE LEXICON\n12\nThe aim of the common proposal is not to pose a complete speciﬁcation ready to implement,\nbut to pose a basic set of features and to leave the rest to language-speciﬁc applications.\nThe last phase of the project is the testing of the common proposal in a multilingual framework,\nnamely the MULTEXT project. The aim of MULTEXT partners is to design and implement a\nset of tools for corpus-based research and a corpus in that multilingual framework. The tasks\ninvolved are developing a common speciﬁcation for the MULTEXT lexicon and a tagset for\nMULTEXT corpus. The partners evaluated the common proposal at Level 1 (recommended\nfeatures) by also considering language-speciﬁc issues. The result is that the common set of\nfeatures ﬁts well to the description of partners, but needs further language-speciﬁc detail.\nChapter 3\nA Lexicon Design for Turkish\nAll natural language processing systems, such as parsers, generators, taggers, need to access a\nlexicon of the words in the language. The information provided by the lexicon includes:\n• morphosyntactic,\n• syntactic, and\n• semantic information.\nIn this thesis, we have designed a comprehensive lexicon for Turkish, and integrated it with a\nmorphological processor, so that the overall system is capable of providing the feature structures\nfor all interpretations of an input word form (with multiple senses incorporated).\nFor instance, consider the input word form kazma; ﬁrst, the morphological processor receives\nthis input, and provides its analysis to the static lexicon. There are three possible interpreta-\ntions:\n1. kazma (noun, pickaxe),\n2. kaz+NEG (verb, don’t dig), and\n3. kaz+INF (inﬁnitive, digging),\nfor which the static lexicon produces feature structures for all senses of the root words involved.\nMoreover, the lexicon allows the interfacing system to constraint the output. For example, the\nﬁnal category feature of the root word in the input surface form can be restricted to, say, verb.\n13\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n14\nIn this case, only information about the second interpretation, don’t dig, will be released by the\nsystem. Chapter 4 describes this process in detail.\nBy separating the system into two parts, that is a morphological analyzer and a static lex-\nicon, we make use of the morphological processor previously implemented and abstract the\nprocess of parsing surface forms. Hence, designing a static lexicon and interfacing it with the\nmorphological processor is suﬃcient to construct a lexicon system.\nIn this chapter we will present the detailed design of our static lexicon, that is the associated\nfeature structures with each of the lexical categories in Turkish. The procedural aspects (i.e.,\nhow feature structures are produced) are described in Chapter 4. We will ﬁrst introduce the\nmain lexical categories, then describe each one in detail with the associated feature structures.\n3.1\nLexicon Architecture\nThe Figure 3.1 brieﬂy describes the architecture of our lexicon, which consists of a morphological\nprocessor, a static lexicon, and a module applying restrictions.\nThe input to the system is a query form, which consists of two parts: a word form and a set of\nfeatures placing constraints in the output. The word form is ﬁrst received and processed by the\nmorphological processor, whose output is the possible interpretations of the word form. Then,\nthe static lexicon attaches features to all senses of the root words of these interpretations, and\noutputs the feature structures. But before the result is released, the feature structures that do\nnot satisfy the restrictions are eliminated, and the rest is the actual output of the system. The\ndetails of this procedure are given in Chapter 4.\n3.2\nLexical Representation Langugage\nThe lexical representation language that we will use in the rest of this chapter is feature struc-\ntures. A feature structures is a list of <feature name:feature value> pairs, in which at most one\npair with a given feature name can be present. The value of a feature name may be an atom\nor a feature structure again. Here are some examples of feature structures:1\n\nF\na\nG\nb\n\n\n1 See Shieber [12] for a detailed description of feature structures.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n15\nMorphological\nprocessor\nmorphological\nparse(s)\nApplication of\nrestrictions\nlist of \nfeature structures\nsatisfying restrictions\nlist of \nfeature structures\nNLP subsystems\nStatic lexicon\nsurface form\nrestriction feature(s)\nquery form\nLexicon\nlexicon interface and\nrestriction\nFigure 3.1: Architecture of the lexicon.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n16\n\n\nF\n\nG\na\nH\nb\n\n\nI\nc\n\n\n3.3\nLexical Categories\nFigure 3.2 shows the main lexical categories of Turkish in our lexicon. All the lexicon categories\nare depicted in Tables A.1 and A.2 on page 114.\nlexical categories\nverbs\nconjunctions\npost-positions\nnominals\nadjectivals adverbials\nFigure 3.2: The main lexical categories of Turkish.\nEach word in the lexicon has the following feature structure:\nword\n\n\nCAT\n\n\nMAJ\nmaj\nMIN\nmin\n(default: none)\nSUB\nsub\n(default: none)\nSSUB\nssub\n(default: none)\nSSSUB\nsssub\n(default: none)\n\n\nMORPH\n\nSTEM\nstem\nFORM\nlexical/derived (default: lexical)\n\n\nSEM\nh\nCONCEPT\nconcept\ni\nPHON\nphon\n\n\nThus, each word has category information in CAT feature as a 5-tuple describing major, minor\nand subcategories, STEM and FORM as morphosyntactic features, CONCEPT as semantic\nfetaure, and phonology.\nThe major and minor categories and the concept, which uniquely\ndetermine the word with its sense are given in this feature structure. Additionally, the form,\nwhich take lexical or derived values, the stem and the phonology, which is the combination of\nthe stem and inﬂections are also present in this structure, e.g., kitap (book) vs. kitaplarım (my\nbooks).\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n17\n3.4\nNominals\nThis section describes the representation of nominals in our lexicon. As shown in Figure 3.3,\nnominals are divided into three subcategories:\n• nouns,\n• pronouns,\n• sentential heads which function as nominals.\nnominals\n✟✟✟✟✟✟✟✟\n❍\n❍\n❍\n❍\n❍\n❍\n❍\n❍\nnouns\npronouns\nsentential nominals\nFigure 3.3: Subcategories of nominals.\nFigure 3.4 gives the detailed categorization for the nominal category.2\nmaj\nmin\nsub\nssub\nsssub\nnominal\nnoun\ncommon\nproper\npronoun\npersonal\ndemonstrative\nreﬂexive\nindeﬁnite\nquantiﬁcation\nquestion\nsentential\nact\ninﬁnitive\nma\nmak\nyı¸s\nfact\nparticiple\ndık\nyacak\nFigure 3.4: Lexicon categories of nominals.\nEach nominal has the following additional features, which represent the inﬂections of the word:\n2 The three subcategories of inﬁnitives and the two subcategories of participles represent\nthe verbal forms derived using the suﬃxes -mA, -mAk, -yH¸s, -dHk, and -yAcAk. These will be\nexplained later in detail.\nThe notation for suﬃxes follows this convention: A and H represent unrounded (i.e., {a, e})\nand high vowels (i.e., {ı, i, u, ¨u}), respectively. The ﬁrst y in the suﬃxes may drop.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n18\nnominal\n\nMORPH\n\n\nCASE\ncase\n(default: none)\nAGR\nagr\n(default: none)\nPOSS\nposs\n(default: none)\n\n\n\n\nA nominal may be case-marked as\n• nominative,\n• accusative,\n• dative,\n• locative,\n• ablative,\n• genitive,\n• instrumental,\n• equative.\nThird person singular and plural suﬃxes are the possible values for the agreement marker of\nnouns and sentential heads. Pronouns may take ﬁrst, second, and third person singular and\nplural agreement markers. All three types of nominals may take possessive suﬃx, which is one\nof the six person suﬃxes and none.\nIn the following sections we will describe the subcategories of nominals in detail.\n3.4.1\nNouns\nNouns denote the entities in the world, such as objects, events, concepts, etc. As shown in\nFigure 3.5, nouns can be further divided into two subcategories as common and proper nouns.\nThese are described in detail in the next two sections.\nnouns\n✟✟✟\n❍\n❍\n❍\ncommon\nproper\nFigure 3.5: Subcategories of nouns.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n19\nCommon Nouns\nCommon nouns denote classes of entities. Figure 3.6 depicts the two forms of common nouns:\nlexical and derived. Only lexical common nouns are represented in our lexicon as lexical entries,\nhowever, the system can produce feature structures for derived forms. For example, computa-\ntion of the feature structure for evdekiler (those that are at home) requires the retrieval of the\nfeature structure of the noun ev (home) and the derivation of it to an adjective (evdeki (that is\nat home)) and then to the noun evdekiler (see the derivation tree for evdekiler in Figure 3.7).\ncommon nouns\n✟✟\n✟\n❍\n❍\n❍\nlexical\nderived\nFigure 3.6: Forms of common nouns.\nCommon nouns have the following additional features: subcategorization and a set of semantic\nproperties such as countability and animateness.\ncommon\n\n\nSYN\n\nSUBCAT\n\n\n\n\n\n\n\n\n\nconstraint1, . . . ,\nconstrainti, . . . ,\nconstraintn\n\n\n\n\n\n\n\n\n\n(default: none)\n\n\nSEM\n\n\nMATERIAL\n+/−\nUNIT\n+/−\nCONTAINER\n+/−\nCOUNTABLE\n+/−\nSPATIAL\n+/−\nTEMPORAL\n+/−\nANIMATE\n+/−\n\n\n\n\nconstrainti\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nmin\nSUB\nsub\nSSUB\nssub\nSSSUB\nsssub\n\n\nMORPH\n\nCASE\ncase\nPOSS\nposs\n\n\nSEM\n[]\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n20\nevdekiler\n(noun)\nevdeki (adjective)\n✟✟✟\n❍\n❍\n❍\nev+LOC (noun)\nREL\nFigure 3.7: Derivation history of evdekiler.\nThe semantic features may only take + or −values. This is on the sense basis, since senses may\nhave diﬀerent semantic properties; for example, ekin (culture) is an abstract entity, whereas ekin\n(crop) is not. The default value for the semantic features is −.\nThe subcategorization information consists of a list of constraints on any complement of the\ncommon noun. The application of constraints is in disjunctive fashion. This concept will be\nextended to cover more than one complement (e.g., subject, objects, etc.) in Section 3.7, when\nthe verb category is introduced.\nConstraints on the complements of common nouns are of\nthree types: category, case and possessive markings, and semantic properties. Note that the\nconstraint structure for common nouns is simpler than that for verbs. For instance, constraint\nstructure for the current category does not constrain the stem and agreement features of the\narguments.\nIn the next sections we will describe the two forms of common nouns in detail with examples.\nLexical Common Nouns\nAs mentioned above, this form of common nouns are present in\nthe lexicon, and the retrieval does not involve any computation of features. The following are\nexamples of common nouns in lexical form: kum (sand), kalem (pencil), ihtiya¸c (need), sabah\n(morning), ¸car¸samba (Wednesday), ilkbahar (spring), a¸saˇgı (bottom).\nAs an example, consider the common noun ihtiyacı (his/her/its need), as used in (3):3\n(3) a. Utku’nun senin\nbu\ni¸si\nyapmana\nUtku+GEN you+GEN this job+ACC do+INF+P2SG\nihtiyacı\nvar.\nneed+P3SG existent+PRES+3SG\n‘Utku needs you to do this job.’\nb. Bunun\ni¸cin sana/Bilge’ye\nihtiyacımız var.\nthis+GEN for you/Bilge+DAT need+P1PL existent+PRES+3SG\n‘We need you/Bilge for this.’\n3 Note that some of the features are not shown; they take the default values speciﬁed.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n21\nlexical common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\n\nSTEM\n“ihtiya¸c”\nFORM\nlexical\nCASE\nnom\nAGR\n3sg\nPOSS\n3sg\n\n\nSYN\n\u0014\nSUBCAT\nn\nconstraint1, constraint2\no\u0015\nSEM\nh\nCONCEPT\n#ihtiya¸c-(need)\ni\nPHON\n“ihtiya¸c”\n\n\nconstraint1\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nn\nnoun, pronoun\no\n\n\nMORPH\nh\nCASE\ndat\ni\n\n\nconstraint2\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nma\n\n\nMORPH\nh\nCASE\ndat\ni\n\n\nThe feature structure of ihtiyacı contains information stating that ihtiyacı is a common noun in\nlexical form, inﬂected from ihtiya¸c with 3sg agreement and possessive markers. It also speciﬁes\nthat the complement of ihtiyacı should be case-marked as dative and may be in one the two\nforms: noun or pronoun, and inﬁnitive derived with the suﬃx -mA. Example sentences in (3)\ndepict these usages.\nThe following is another example, the common noun geceye (to the night), as used in (4):\n(4)\nD¨un\ngeceye\nkadar oraya\ngitmek\nyesterday night+DAT until there+DAT go+INF\nkonusunda\nkarar vermi¸s deˇgildim.\ntopic+P3SG+LOC decide+NARR NOT+PAST+1SG\n‘I had not decided on going there until last night.’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n22\nlexical common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\n\nSTEM\n“gece”\nFORM\nlexical\nCASE\ndat\nAGR\n3sg\nPOSS\nnone\n\n\nSYN\nh\nSUBCAT\nnone\ni\nSEM\n\n\nCONCEPT\n#gece-(night)\nCOUNTABLE\n+\nTEMPORAL\n+\n\n\nPHON\n“geceye”\n\n\nThe feature structure above gives the following information: geceye is a common noun in lexical\nform, inﬂected from the common noun gece with 3sg agreement and dative case markers. It is\ncountable and states temporality.\nDerived Common Nouns\nDerived forms of common nouns are not represented directly in\nthe lexicon. However, in order to produce feature structures, the lexicon employs the derivation\ninformation provided by the morphological processor. This information mainly consists of the\ntarget category and the derivational suﬃxes. The rest of the information (such as argument\nstructure, thematic roles, concept, and stem) are supplied by the lexicon. The details of this\nprocess are described in Chapter 4.\nEach derived common noun has the following additional features:\nderived common\n\n\nMORPH\nh\nDERV-SUFFIX\nderv-suﬃx (default: none)\ni\nSEM\nh\nROLES\nroles (default: none)\ni\n\n\nThese give the suﬃx used in the derivation and the semantic functions involved. The latter\nstores the thematic roles of the lexical verb which is involved somewhere in the derivation\nprocess. For example, the derived common noun yazıcı (writer) has the thematic roles of the\nverb yaz- (write), since the derivation process carries the thematic role information through\ncategories. The type of this feature’s value is given in Section 3.7.\nThe derivation suﬃx may take one of the following values: -cH, -cHk, -lHk, -yHcH, -mAzlHk,\n-yAmAzHk, -mAcA, -yAsH and none.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n23\nHowever, there is the problem of predicting the semantic properties of derived common nouns,\nand this is not an easy task. For example, consider ak¸samcı (heavy drinker) and ¨oˇglenci (the\nstudent attending the afternoon session of a school), which are both derived from common nouns\nwith the suﬃx -cH. The semantics is, however, rather unpredictable. The current system does\nnot attempt to predict those values. Instead, the default values are used; but these may not\nnecessarily be the correct values for the word in consideration. Prediction of these values is\nbeyond the scope of our work.\nThere are four types of derivation to derived common nouns:\n• Nominal derivation: This type of derivation uses the suﬃxes -cH, -cHk, -lHk, as in the\nexamples kapıcı (doorkeeper), kitap¸cık (booklet), and kitaplık (bookcase).\nConsider the feature structure for the common noun tamircim (my repairman), as used\nin the example sentence below:\n(5)\nHer zaman olduˇgu\ngibi,\ntamircim\nalways\nhappen+PART+P3SG like\nrepairman+P1SG\ni¸sini\n¸cok\niyi\nyaptı.\njob+P2SG\nvery\nwell do+PAST+3SG\n‘As it is always the case, my repairman did his job very well.’\nderived common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\n\nSTEM\n1\nFORM\nderived\nCASE\nnom\nAGR\n3sg\nPOSS\n1sg\nDERV-SUFFIX\n“cı”\n\n\nSYN\nh\nSUBCAT\n2 none\ni\nSEM\nh\nCONCEPT\nfcı( 3 )\ni\nPHON\n“tamircim”\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n24\n1\nlexical common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\nSTEM\n“tamir”\nFORM\nlexical\n\n\nSYN\nh\nSUBCAT\n2 none\ni\nSEM\nh\nCONCEPT\n3 #tamir-(repair)\ni\nPHON\n“tamir”\n\n\nThe feature structure for the noun tamircim is produced ﬁrst retrieving the features of\ntamir (repair) and ﬁlling a template for derived common nouns appropriately.\nSome\nof the feature values are obtained from the features of tamir (e.g., subcategorization\ninformation), some of them are supplied by the morphological processor (e.g., inﬂectional\nand derivational suﬃxes), and the rest is provided by the static lexicon.\nThe feature structure above gives the following information: the word tamircim is a com-\nmon noun derived from tamir with the suﬃx cH, and inﬂected with 3sg and 1sg agreement\nand possessive markers, respectively. Tamircim does not have subcategorization informa-\ntion. It also includes all the features of tamir.\n• Adjectival derivation: Derivation from adjectival uses the suﬃx -lHk, e.g., iyilik (good-\nness), temizlik (cleanliness).\nBut, derivation without suﬃx is also possible as in the\nfollowing examples, though this is not productive:\n(6)\n– bor¸clu\n‘that owing debt’,\n– akıllı\n‘intelligent’,\n– geridekine\n‘to the one behind’.\nThis is also possible in the case of participles (compare with participles in Section 3.4.3),\nsuch as\n(7)\n– getirdiˇgimi\n‘the thing that I brought’,\n– gelene\n‘to the one that came/coming’.\nAs described in the section on qualitative adjectives, this type of adjectivals are derived\nfrom verbs, and by dropping the head of the phrase that they modify and taking their\ninﬂectional suﬃxes, they become nominals. An example is given in (8):\n(8) a. Buraya\ngelen\nadamı\ng¨ord¨un\nm¨u?\nhere+DAT come+PART man+ACC see+PAST+2SG QUES\n‘Did you see the man that came here?’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n25\nb. Buraya\ngeleni\ng¨ord¨un\nm¨u?\nhere+DAT come+PART+ACC see+PAST+2SG\nQUES\n‘Did you see the one that came here?’\nIn sentence (8a), the verbal form of gapped relative clause, buraya gelen, acting as the\nmodiﬁer of adam (man) takes the inﬂections of adam, and functions as a nominal.\nThere are two types of participles (see Underhill [15]):\n– subject (such as gelen adam (the man that came/is coming)),\n– object (such as getirdiˇgim kitap (the book that I brought)).\nIn order for an object participle to be used as a nominal (speciﬁcally common noun),\nthe verb from which the adjectival is derived should take a direct object. Otherwise, the\nnominal represents a fact. For example, the verb, gel- (come), may not take a direct\nobject argument, thus the nominal, geldiˇgini in (9a) represents a fact. In (9b), however,\nthe nominal, getirdiˇgini, has two readings: a fact and a derived common noun.\n(9) a. Taner’in\ngeldiˇgini\nbiliyorum.\nTaner+GEN come+PART+P3SG know+PROG+1SG\n‘I know that Taner came.’\nb. Taner’in\ngetirdiˇgini\nbiliyorum.\nTaner+GEN bring+PART+P3SG know+PROG+1SG\n‘I know that Taner brought something.’\n‘I know the thing that Taner brought.’\n• Verb derivation: This derivation type uses the suﬃxes -yHcH, -mAcA, -mAzlHk, -yAmAzlHk,\nand -yAsH, as used in the following example nouns: yazıcı (writer), ko¸sucu (runner),\nko¸su¸sturmaca (rush/hurry), ¸cekememezlik (envy), kahrolası (damnable).\n• Post-position derivation: Derivation from post-positions do not use any suﬃx, e.g., azını\n(the one that is little), yukarısına (to the one that is above).\nProper nouns\nProper nouns are used to refer to unique entities in the world. The only additional feature that\nproper nouns have states that they are always deﬁnite, as in the examples Kurtulu¸s, Kemal,\nOﬂazer, Bilkent, and Ankara.\nproper\n\u0014\nSEM\nh\nDEFINITE\n+\ni\u0015\nAs used in (10), the following is the feature structure of the proper noun Kurtulu¸s:\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n26\n(10)\nKurtulu¸s yarım saat i¸cinde burada\nolacak.\nKurtulu¸s half hour in\nhere+LOC be+FUT+3SG\n‘Kurtulu¸s will be here in half an hour.’\nproper\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\nproper\n\n\nMORPH\n\n\nSTEM\n“Kurtulu¸s”\nCASE\nnom\nAGR\n3sg\nPOSS\nnone\n\n\nSEM\n\nCONCEPT\n#Kurtulu¸s-(Kurtulu¸s)\nDEFINITE\n+\n\n\nPHON\n“Kurtulu¸s”\n\n\n3.4.2\nPronouns\nPronouns are used in place of nouns in sentences, phrases, etc. (see Ediskun [3] and Ko¸c [8])and\nsubdivided into six categories, as shown in Figure 3.8.\nreflexive\nindefinite\npersonal\ndemonstrative\nquestion\nquantification\npronouns\nFigure 3.8: Subcategories of pronouns.\nEach pronoun also has the following semantic feature, which takes + value for personal, reﬂexive\nand demonstrative pronouns, and −value for the other subcategories.\npronoun\n\u0014\nSEM\nh\nDEFINITE\n+/−(default: −)\ni\u0015\nIn the following sections we will give examples for each subcategory of pronouns.\nPersonal pronouns\nPersonal pronouns are used to denote the speaker, the one spoken to, and the one spoken of.\nThis category consists of pronouns ben (I), sen (you), o (he/she/it), biz/bizler (we), siz/sizler\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n27\n(you), and onlar (they).\nPersonal pronouns may take all of the six person suﬃxes as the\nagreement marker, but may not take a possessive marker.\nDemonstrative pronouns\nDemonstrative pronouns denote the entities by showing them, but without mentioning their\nactual names. The following are examples of demonstrative pronouns: bu (this), ¸su (that),\nbunlar (these). Like personal pronouns, this category of pronouns does not take a possessive\nmarker. 3sg and 3pl suﬃxes are the possible values for the agreement marker. The following is\nthe feature structure of onlar (they), as used in (11):\n(11)\nBunu\nyapanın\nonlar olduˇgundan\neminim.\nthis+ACC do+PART+GEN they be+PART+P3SG+ABL sure+PRES+1SG\n‘They, I am sure, did this.’\ndemonstrative pronoun\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\npronoun\nSUB\ndemonstrative\n\n\nMORPH\n\n\nSTEM\n“o”\nCASE\nnom\nAGR\n3pl\nPOSS\nnone\n\n\nSEM\n\nCONCEPT\n#o-(he/she/it)\nDEFINITE\n+\n\n\nPHON\n“onlar”\n\n\nReﬂexive pronouns\nReﬂexive pronouns are words denoting the person or the thing on which the action in the sen-\ntence has an eﬀect. This category consists of the pronouns kendim (myself), kendin (yourself),\nkendi/kendisi (herself/himself/itself), kendimiz (ourselves), kendiniz (yourselves), and kendileri\n(themselves). The agreement and possessive markers take the same value, which is one of the\nsix person suﬃxes, e.g., it is 3pl suﬃx for kendileri. The same holds true for the indeﬁnite and\nquantiﬁcation pronouns.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n28\nIndeﬁnite pronouns\nIndeﬁnite and quantiﬁcation pronouns denote entities without showing them explicitly. The\ndiﬀerence between the two is that quantiﬁcation pronouns recall the existence of more than one\nentity. All indeﬁnite pronouns are inﬂected forms of the root word biri and kimi, e.g., biri/birisi\n(someone), birimiz (one of us), kiminiz (some of you), kimileri (some of them).4\nQuantiﬁcation pronouns\nThere are two forms of quantiﬁcation pronouns: lexical and derived.\nLexical\nThe following are examples of quantiﬁcation pronouns in lexical form: kimisi (some\nof them), kimimiz (some of us), bazısı (some of them), bir¸coˇgu (most of them), ¸coˇgumuz (most\nof us), herbirimiz (each of us), t¨um¨um¨uz (all of us), hepsi (all of them).\nConsider the feature structure of the quantiﬁcation pronoun bir¸coˇgu (most of them), as used in\n(12):\n(12)\nK¨ot¨u hava\nko¸sulları\ny¨uz¨unden, ¨oˇgrencilerin\nbad\nweather condition+3PL+P3SG due to\nstudent+3PL+GEN\nbir¸coˇgu\ngelemedi.\nmost of them come+NEG+PAST+3SG\n‘Due to bad weather conditions, most of the students couldn’t come.’\nlexical quantiﬁcation pronoun\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\npronoun\nSUB\nquantiﬁcation\n\n\nMORPH\n\n\nSTEM\n“bir¸cok”\nFORM\nlexical\nCASE\nnom\nAGR\n3pl\nPOSS\n3pl\n\n\nSEM\nh\nCONCEPT\n#bir¸cok-(most of . . . )\ni\nPHON\n“bir¸coˇgu”\n\n\n4 Note that the inﬂected forms of iki, ¨u¸c, etc. (such as ikiniz (two of you)) are classiﬁed as\nquantiﬁcation pronouns. However, this is not productive.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n29\nDerived\nThe derivation to quantiﬁcation pronouns is possible only from quantiﬁcation ad-\njectives, e.g., ikisi (two of them), ¨u¸c¨un¨uz (you three). The derivation process is not productive:\nfor example, *ikileri is not a quantiﬁcation pronoun. The derivation does not use a suﬃx.\nEach derived quantiﬁcation pronoun has the following additional feature:\nderived quantiﬁcation pronoun\n\u0014\nMORPH\nh\nDERV-SUFFIX\nnone\ni\u0015\nQuestion pronouns\nThis category of pronouns look for entities by asking questions. The following are examples of\nquestion pronouns: kim/kimler (who), ne (what), hangisi (which of them), hanginiz (which of\nyou). For the agreement and possessive markers, there are two cases:\n• they both take the same value, which is one of the six person suﬃxes, e.g., it is 2pl for\nhanginiz,\n• agreement marker takes one of 3sg and 3pl suﬃxes, and possessive marker does not take\nany value, e.g., kim vs. kimler.\n3.4.3\nSentential Nominals\nIn this section we will describe sentential nominals, which head sentences and function as nom-\ninals in syntax. As shown in Figure 3.9, sentential nominals are divided into two subcategories:\nacts and facts.\nsentential nominals\n✟✟❍\n❍\nacts\nfacts\nFigure 3.9: Subcategories of sentential nominals.\nEach sentential nominal has the following additional features:\nsentential\n\n\nMORPH\nh\nDERV-SUFFIX\nderv-suﬃx\ni\nSYN\nh\nSUBCAT\nsubcat\ni\nSEM\nh\nROLES\nroles\ni\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n30\nThe DERV-SUFFIX feature takes one of the following: -mAk, -mA, -yH¸s, -dHk, and -yAcAk.\nSubcategorization information and thematic roles are also present in this feature structure.\nActs\nThe only subcategory of acts is inﬁnitives, which is described next.\nInﬁnitives\nInﬁnitives may be further divided into three subcategories, which are derived\nfrom verbs with the suﬃxes -mA, -mAk, and -yH¸s, respectively, as shown in Figure 3.10. The\nderivation with -mAk is indeﬁnite, i.e., the inﬁnitive does not take a possessive marker, while\nthe other two may or may not take this inﬂection.\ninﬁnitives\n✟✟✟\n❍\n❍\n❍\nma\nmak\nyı¸s\nFigure 3.10: Subcategories of inﬁnitives.\nThe following are examples of inﬁnitives: gelmesi (his coming), geli¸si (his coming), ko¸smak (to\nrun), ¸calı¸smaktan (from working). As an example, consider the following feature structure for\nthe inﬁnitive bilmek (to know), as used in (13):5\n(13) a. Tolga’nin\nd¨un\nburaya\nneden geldiˇgini\nTolga+GEN yesterday here+DAT why\ncome+PART+P3SG+ACC\nbilmek\nsana\nbir¸sey\nkazandırmaz.\nto know you+DAT something gain+CAUS+NEG+ARST+3SG\n‘You will not gain anything by knowing why Tolga came here yesterday.’\nb. Araba kullanmayı\nbiliyor\nmusun?\ncar\ndrive+INF+ACC know+PRES QUES+2SG\n‘Do you know how to drive?’\nc. Bu\ni¸si\nnasıl bitirece˘gimi\nbiliyorum.\nthis job+ACC how end+PART+P1SG+ACC know+PRES+1SG\n‘I know how to end this thing.’\n5 Sentences (13b) and (13c) are given to examplify the argument structure of the verb bil-.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n31\nmak\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nmak\n\n\nMORPH\n\n\nSTEM\n1\nFORM\nderived\nDERV-SUFFIX\n“mak”\nCASE\nnom\nAGR\n3sg\nPOSS\nnone\n\n\nSYN\nh\nSUBCAT\n2\ni\nSEM\n\nCONCEPT\nfmak( 4 )\nROLES\n3\n\n\nPHON\n“bilmek”\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n32\n1\nlexical predicative verb\n\n\nCAT\n\nMAJ\nverb\nMIN\npredicative\n\n\nMORPH\n\n\nSTEM\n“bil”\nFORM\nlexical\nSENSE\npos\n\n\nSYN\n\n\nSUBCAT\n2\n*\n5\n\n\nSYN-ROLE\nsubject\nOCCURRENCE\noptional\nCONSTRAINTS\nn\nconstraint1\no\n\n,\n6\n\n\nSYN-ROLE\ndir-obj\nOCCURRENCE\noptional\nCONSTRAINTS\n\n\n\n\n\n\n\n\n\n\n\n\n\nconstraint2,\nconstraint3,\nconstraint4,\nconstraint5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n+\n\n\nSEM\n\n\nCONCEPT\n4 #bil-(to know)\nROLES\n3\n\nAGENT\n5\nTHEME\n6\n\n\n\n\nPHON\n“bil”\n\n\nconstraint1\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nn\nnoun, pronoun\no\n\n\nMORPH\nh\nCASE\nnom\ni\n\n\nconstraint2\n\n\nCAT\n\nMAJ\nnominal\nMIN\nnoun\n\n\nMORPH\n\u0014\nCASE\nn\nacc, nom\no\u0015\n\n\nconstraint3\n\n\nCAT\n\nMAJ\nnominal\nMIN\npronoun\n\n\nMORPH\nh\nCASE\nacc\ni\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n33\nconstraint4\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nma\n\n\nMORPH\nh\nCASE\nacc\ni\n\n\nconstraint5\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nfact\nSSUB\nparticiple\n\n\nMORPH\n\nCASE\nacc\nPOSS\n¬none\n\n\n\n\nFacts\nThe only subcategory of facts is participles, which is described next.\nParticiples\nParticiples may be further divided into two subcategories, which are derived\nfrom verbs with the suﬃxes -dHk and -yAcAk, respectively, as shown in Figure 3.11. Both\nsubcategories take possessive markings.\nparticiples\n✟✟❍\n❍\ndık\nyacak\nFigure 3.11: Subcategories of participles.\nThe following are two examples of participles describing facts:\n(14)\n– geldiˇgi\n‘the fact that he came’,\n– geleceˇgini\n‘the fact that he is going to come’.\nNote that Section 3.4.1 describes the participles functioning as common nouns. As an example\nof participles acting as sentential nominals and common nouns, consider (15a), which contains\na sentence with two parses. The ﬁrst mentions about the thing that Gamze brought, and the\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n34\nparticiple, getirdiˇgini, used as a common noun. The latter is about the event that Gamze brought\nsomething, and the participle is used to represent this fact. However, the participle in (15b)\ncan only be used to describe a fact.\n(15) a. Gamze’nin Ankara’dan getirdiˇgini\ng¨ord¨um.\nGamze+GEN Ankara+ABL bring+PART+P3SG+ACC see+PAST+1SG\n‘I saw the thing that Gamze brought from Ankara.’\n‘I saw that Gamze has brought it from Ankara.’\nb. Gamze’nin geldiˇgini\ng¨ord¨um.\nGamze+GEN come+PART+P3SG+ACC see+PAST+1SG\n‘I saw that Gamze came.’\n3.5\nAdjectivals\nThis section describes the representation of adjectivals in our lexicon. Adjectivals are words\nthat describe the properties of nominals (speciﬁcally common nouns) in a number of ways,\ne.g., quality, quantity, etc. and specify them by diﬀerentiating from the others. As shown in\nFigure 3.12, adjectivals consists of two subcategories: determiners and adjectives. Figure 3.13\nshows the hierarchy under the adjectival category.\nadjectivals\n✟✟✟\n❍\n❍\n❍\ndeterminers\nadjectives\nFigure 3.12: Subcategories of adjectivals.\nmaj\nmin\nsub\nssub\nadjectival\ndeterminer\narticle\ndemonstrative\nquantiﬁer\nadjective\nquantitative\ncardinal\nordinal\nfraction\ndistributive\nqualitative\nFigure 3.13: Lexicon categories of adjectivals.\nEach adjectival has the following additional feature structure, which contains syntactic and\nsemantic information. SYN | MODIFIES speciﬁes constraints on the modiﬁed of the adjectival\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n35\nincluding its category, agreement marking and countability. For example, the cardinal adjective\nbir accepts only singular countable common nouns, e.g., bir kalem vs. *bir kalemler.6\nadjectival\n\n\nSYN\n\n\nMODIFIES\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\nh\nAGR\nagr\ni\nSEM\nh\nCOUNTABLE\n+/−\ni\n\n\n\n\nSEM\n\nGRADABLE\n+/−/semi (default: −)\nQUESTIONAL\n+/−(default: −)\n\n\n\n\nThere are two semantic features. The ﬁrst one describes the gradability of the adjectival in\nconsideration, e.g., the article bir is not gradable, whereas, the adjective b¨uy¨uk is. The other one\nis used to describe whether the adjectival is in questional form, e.g., the following adjectivals\nare in this form: ka¸c (how many), ka¸cıncı (in what order), nasıl (how), hangi (which).\nIn the next sections we will describe the subcategories of adjectivals in detail.\n3.5.1\nDeterminers\nDeterminers are limiting adjectivals: they specify entities by showing them explicitly or indef-\ninitely. As shown in Figure 3.14, determiners are subdivided into three categories: indeﬁnite\narticle, demonstratives and quantiﬁers, which are described in the next sections.\nIndeﬁnite Article\nThe only article in Turkish is bir, as used in (17).\nAs the name implies, this article, like\nquantiﬁers, does not show entities explicitly.\nThe feature structure of this article is given\nbelow:\n6 The category information states that adjectivals can only modify common nouns, which\nis not accurate, in fact. Consider the following example:\n(16) a.\nAnkara’ya\nbu\ngidi¸simde\nonunla\nkonu¸sacaˇgım.\nAnkara+DAT this go+INF+P2SG+LOC him+DAT talk+FUT+1SG\n‘I will talk with him in my next visit to Ankara.’\nIn this sentence, the demonstrative bu modiﬁes a sentential nominal. However, we will omit\nthese and simplify the pattern of modiﬁed constituent of adjectival phrases.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n36\ndeterminers\n✟✟✟✟✟✟✟✟\n✟\n❍\n❍\n❍\n❍\n❍\n❍\n❍\n❍\n❍\nindeﬁnite article\ndemonstratives\nquantiﬁers\nFigure 3.14: Subcategories of determiners.\n(17) a. Dilek evinde\nb¨uy¨uk bir balık besliyor.\nDilek home+P3SG+LOC big\na\nfish look after+PROG+3SG\n‘Dilek is looking after a big ﬁsh at her home.’\narticle\n\n\nCAT\n\n\nMAJ\nadjectival\nMIN\ndeterminer\nSUB\narticle\n\n\nMORPH\nh\nSTEM\n“bir”\ni\nSYN\n\n\nMODIFIES\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\nh\nAGR\n3sg\ni\nSEM\nh\nCOUNTABLE\n+\ni\n\n\n\n\nSEM\nh\nCONCEPT\n#bir-(a)\ni\nPHON\n“bir”\n\n\nDemonstratives\nDemonstratives specify entities by showing them explicitly. Bu (this), ¸su (that), hangi (which)\nand diˇger (other) are examples of demonstratives. As a speciﬁc example, consider bu (this),\nwhich is used in (18):\n(18)\nBulduˇgum\nbu\n¨ornek\nc¨umle\n¸cok\nsa¸cma.\ndevise+PART+P1SG this example sentence very foolish+PRES+3SG\n‘This example sentence I devised is foolish.’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n37\ndemonstrative\n\n\nCAT\n\n\nMAJ\nadjectival\nMIN\ndeterminer\nSUB\ndemonstrative\n\n\nMORPH\nh\nSTEM\n“bu”\ni\nSYN\n\n\nMODIFIES\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\n\n\n\n\nSEM\nh\nCONCEPT\n#bu-(this)\ni\nPHON\n“bu”\n\n\nQuantiﬁers\nHer (each), bazı/kimi (some), biraz (a little), bir¸cok (many), and b¨ut¨un (all) are examples of\nquantiﬁers. The following is the feature structure of biraz (a little), as used in the example\nsentence below:\n(19)\nTimu¸cin, bana\nbiraz\nsu\ngetirir\nmisin?\nTimu¸cin me+DAT a little water bring+ARST QUES+2SG\n‘Timu¸cin, could you bring me a little water?’\nquantiﬁer\n\n\nCAT\n\n\nMAJ\nadjectival\nMIN\ndeterminer\nSUB\nquantiﬁer\n\n\nMORPH\nh\nSTEM\n“biraz”\ni\nSYN\n\n\nMODIFIES\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\nh\nAGR\n3sg\ni\nSEM\nh\nCOUNTABLE\n−\ni\n\n\n\n\nSEM\nh\nCONCEPT\n#biraz-(a little)\ni\nPHON\n“biraz”\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n38\n3.5.2\nAdjectives\nAdjectives are used to describe the quantity and quality of entities. Figure 3.15 presents the\nsubcategories of adjectives, which consists of quantitative and qualitative adjectives.\nThese\nsubcategories are described in the following sections.\nadjectives\n✟✟✟\n✟\n❍\n❍\n❍\n❍\nquantitative\nqualitative\nFigure 3.15: Subcategories of adjectives.\nQuantitative Adjectives\nQuantitative adjectives describe the amount of the entities. This category is further divided\ninto four subcategories, as shown in Figure 3.16.\nquantitative adjectives\n✏✏✏✏✏✏✏✏✏\n\u0000\u0000\u0000❅\n❅\n❅\nP\nP\nP\nP\nP\nP\nP\nP\nP\ncardinals\nordinals\nfractions\ndistributives\nFigure 3.16: Subcategories of quantitative adjectives.\nCardinals\nCardinals specify how many of entities are present. The following are examples\nof cardinals: bir (one), iki (two), y¨uzlerce (hundreds of), ka¸c (how many).\nOrdinals\nOrdinals specify the rank of an entity.\nThe following are examples of ordinals:\nbirinci/ilk (ﬁrst), ikinci (second), sonuncu (last), ka¸cıncı (in what order).\nFractions\nThis category of quantitative adjectives specify the relative size of the parts of\nan entity. The following are examples of fractions: b¨ut¨un/var/tam/t¨um (whole), yarım (half),\n¸ceyrek (one fourth). The following example demonstrates the fraction adjective usage of var,\nwhich may not be evident at the ﬁrst glance:\n(20)\nKazanmak i¸cin var\ng¨uc¨umle\n¸calı¸stım.\nwin+INF\nfor whole power+P1SG+INS work+PAST+1SG\n‘I word so hard to win.’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n39\nDistributives\nBirer (one each) is an example of distributives, which gives the size of each\ngroup that is obtained by dividing an entity into parts equally.\nQualitative Adjectives\nQualitative adjectives describe the properties of the entities. There are two forms of qualitative\nadjectives: lexical and derived. In the next sections we will describe these forms in detail with\nexamples.\nEach qualitative adjective has the following additional feature, which gives the subcategoriza-\ntion information:\nqualitative adj\n\u0014\nSYN\nh\nSUBCAT\nsubcat (default: none)\ni\u0015\nLexical\nThe feature structures of this form of adjectives are directly accessible in the lexicon,\ni.e., no derivation process is involved. The subcategorization information for this form consists\nof a list of constraints on the only (if any) complement of the adjective (see the example below).\nThe following are examples of qualitative adjectives in lexical form: memnun (pleased), iyi\n(good), zeki (clever), k¨u¸c¨uk (small), aynı (same), ertesi (next), ¸cok (many/much), sarı (yellow),\nnasıl (how).\nConsider the feature structure for memnun (pleased), as used in (22):7\n(22) a. Ondan\nmemnun bir tek\n¸calı¸san yok\nburada.\nhim+ABL pleased one unique worker nonexistent+PRES+3SG here+LOC\n‘There is no one worker who is pleased from him.’\nb. Olayın\nbu\n¸sekilde\ngeli¸smesinden\nmemnun\nevent+GEN this way+LOC develop+INF+P3SG+ABL pleased\ndeˇgiliz.\nNOT+PRES+1SG\n‘We are not pleased from the way it develops.’\n7 Note that the argument structure of memnun, when used with the auxilary verb ol-, is\ndiﬀerent from that of the adjective usage. Memnun ol- (be happy/satisﬁed) is considered as a\nseparate compound verb (see Section 3.7).\n(21)\nBuna\nmennun oldum.\nthis+DAT be happy+PAST+1SG\n‘I am happy with it.’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n40\nlexical qualitative adj\n\n\nCAT\n\n\nMAJ\nadjectival\nMIN\nadjective\nSUB\nqualitative\n\n\nMORPH\n\nSTEM\n“memnun”\nFORM\nlexical\n\n\nSYN\n\n\nMODIFIES\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\n\n\nSUBCAT\n\n\n\nconstraint1, constraint2,\nconstraint3, constraint4\n\n\n\n\n\nSEM\n\nCONCEPT\n#memnun-(pleased)\nGRADABLE\n+\n\n\nPHON\n“memnun”\n\n\nconstraint1\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nn\nnoun, pronoun\no\n\n\nMORPH\nh\nCASE\nabl\ni\n\n\nconstraint2\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nmak\n\n\nMORPH\n\nCASE\nabl\nPOSS\nnone\n\n\n\n\nconstraint3\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nma\n\n\nMORPH\n\nCASE\nabl\nPOSS\n¬none\n\n\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n41\nconstraint4\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nyı¸s\n\n\nMORPH\nh\nCASE\nabl\ni\n\n\nDerived\nSimilar to other categories in derived form, producing feature structures for derived\nqualitative adjectives requires computation of features.\nEach derived qualitative adjective has the following additional features:\nderived qualitative adj\n\n\nMORPH\n\nDERV-SUFFIX\nderv-suﬃx\nPOSS\nposs (default: none)\n\n\nSEM\nh\nROLES\nroles (default: none)\ni\n\n\nThe derivation suﬃx may take one of the following values: -lHk, -lH, -ki, -sHz, -sH, -yHcH, -yAn,\n-yAcAk, -dHk, -yAsH, and none. The feature MORPH | POSS is used to hold the possessive\nmarking of adjective derived from verb, as in bildiˇgim yemek (bil+dHk+P1SG yemek, dish that\nI know). Possible values for this feature are the six person suﬃxes. The last feature gives the\nsemantic roles of the verb which is involved in the derivation process.\nDuring the derivation process, since predicting the gradability of the qualitative adjective is\ndiﬃcult, its default value (i.e., it is −) is used. For example, adjective akılsız (stupid) is gradable,\nwhile kolsuz (without arm) is not, that is ¸cok akılsız (very stupid) vs. *¸cok kolsuz. However,\nthe following prediction about the constraints on the complements of the derived qualitative\nadjectives is generally correct: qualitative adjectives are generally modiﬁers of common nouns\nand do not constrain the agreement and countability features of the modiﬁed.\nThere are two possible derivations to qualitative adjectives:\n• Nominal derivation: This derivation uses suﬃxes -lHk, -lH, -ki, -sHz, -sH, as in akıllı\n(intelligent), evdeki (that is at home), and ¸cocuksu (childish).\nConsider the feature structure for the derived qualitative adjective, akıllı (intelligent), as\nused in the following sentence:\n(23)\nAkıllı\ninsanlar b¨oyle ¸seyler\nyapmazlar.\ninteligent people such thing+3PL do+NEG+ARST+3PL\n‘Intelligent people don’t do this kind of things.’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n42\nderived qualitative adj\n\n\nCAT\n\n\nMAJ\nadjectival\nMIN\nadjective\nSUB\nqualitative\n\n\nMORPH\n\n\nSTEM\n1\nFORM\nderived\nDERV-SUFFIX\n“lı”\n\n\nSYN\n\n\nSUBCAT\n2 none\nMODIFIES\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\n\n\n\n\nSEM\n\nCONCEPT\nflı( 3 )\nROLES\nnone\n\n\nPHON\n“akıllı”\n\n\n1\nlexical common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\nFORM\nlexical\nSTEM\n“akıl”\n\n\nSYN\nh\nSUBCAT\n2 none\ni\nSEM\nh\nCONCEPT\n3 #akıl-(intelligence)\ni\nPHON\n“akıl”\n\n\n• Verb derivation: This form of derivation uses the following suﬃxes: -yHcH, -yAn, -yAcAk,\n-dHk, -yAsH, and none. Verbal form that take suﬃxes -yAn, -yAcAk, -dHk, and -yAsH\nare, in fact, sentential heads of gapped sentences that dropped their subjects, objects,\nor oblique objects to modify these dropped constituents. These derivations produce two\ntypes of participles according to the grammatical function of the dropped constituent:\nsubject and object participles (see Underhill [15]).\nDerivations with -yAn and -yAsH may only produce subject participles, as illustrated\nin (24):\n(24) a. K¨o¸sede\nduran\nadamı\ntanıyor\nmusun?\ncorner+LOC stand+PART man+ACC know+PROG QUES+2SG\n‘Do you know the man standing at the corner?’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n43\nb. ¨ov¨ulesi\nadam\npraise+PART man\n‘man deserving praise’\nc. elleri\n¨op¨ulesi\nkadın\nhand+3PL+3SG kiss+PART woman\n‘woman whose hands worth kissing’\nDerivations using -yAcAk may produce both types of participles, whereas the ones with\n-dHk may only produce object participles. Consider example sentences in (25):\n(25) a. Paketi\nalacak\n¸cocuk hen¨uz gelmedi.\npacket+ACC take+PART boy\nyet\ncome+NEG+PAST+3SG\n‘The boy who will take the packet has not come yet.’\nb. G¨okhan’ın\nokuduˇgu\nkitabı\nben daha ¨once\nG¨okhan+GEN read+PART+3SG book+ACC I\nbefore\nokumu¸stum.\nread+NARR+PAST+1SG\n‘I read the book that G¨okhan is reading before.’\nOn the contrast, the qualitative adjectives derived form verbal with -yHcH are not heads of\ngapped sentences, e.g., yazıcı (printer). Note that as used in tanıdık ki¸si (known person),\nbildik biri (known person), and giyecek elbise (dress to wear) not all participles derived\nusing -dHk and yAcAk are heads of gapped sentences.8 These are the idiomatic usages\nof participles.\nDerivation without using a suﬃx is also possible, e.g.,\n(27)\n– bilir\n‘that cannot come’,\n– okur yazar\n‘that reads and writes’,\n– donmu¸s\n‘that is frozen’.\n8 Although the form predicative verb+dHk is not productive (i.e., only some of the verbs\nmay conform to it), its negated form is generally applicable to all predicative verbs, as used in\nthe following:\n(26) a.\nO\nkitap i¸cin sormadık\nd¨ukkan bırakmadık.\nThat book for ask+NEG+PART shop\nleave+NEG+PAST+1PL\n‘We didn’t left any shop that we didn’t ask that book.’\nb.\nC¸almadık\nkapı kalmadı.\nknock+NEG+PART door exist+NEG+PAST+3SG\n‘We consulted everyone.’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n44\nOnly object participles derived using -dHk and -yAcAk take possessive suﬃx, since the\nsubject may be missing in the subordinate clause (see the following example).\nConsider the feature structure for bilmediˇgim (that I don’t know), as used in (28):9\n(28)\nBilmediˇgim\nyemekleri\nhi¸cbir zaman yemem.\nknow+NEG+PART+P1SG dish+3PL+ACC never\neat+NEG+ARST+1SG\n‘I never eat dishes that I don’t know.’\nderived qualitative adj\n\n\nCAT\n\n\nMAJ\nadjectival\nMIN\nadjective\nSUB\nqualitative\n\n\nMORPH\n\n\nSTEM\n1\nFORM\nderived\nDERV-SUFFIX\n“dık”\nPOSS\n1sg\n\n\nSYN\n\n\nSUBCAT\n2\nMODIFIES\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\n\n\n\n\nSEM\n\nCONCEPT\nfdık( 4 )\nROLES\n3\n\n\nPHON\n“bilmediˇgim”\n\n\n9 The constraint structures of subcategorization information for the verb bil- are given on\npage 32.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n45\n1\nlexical predicative verb\n\n\nCAT\n\nMAJ\nverb\nMIN\npredivative\n\n\nMORPH\n\n\nSTEM\n“bil”\nFORM\nlexical\nSENSE\nneg\n\n\nSYN\n\n\nSUBCAT\n2\n*\n5\n\n\nSYN-ROLE\nsubject\nOCCURRENCE\noptional\nCONSTRAINTS\nn\nconstraint1\no\n\n,\n6\n\n\nSYN-ROLE\ndir-obj\nOCCURRENCE\noptional\nCONSTRAINTS\n\n\n\n\n\n\n\n\n\n\n\n\n\nconstraint2,\nconstraint3,\nconstraint4,\nconstraint5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n+\n\n\nSEM\n\n\nCONCEPT\n4 #bil-(to know something)\nROLES\n3\n\nAGENT\n5\nTHEME\n6\n\n\n\n\nPHON\n“bil”\n\n\n3.6\nAdverbials\nThis section describes the representation of adverbials in our lexicon. These are words that\nmodify or add to the meaning of verbs (and verbal forms), adjectives, and adverbials in various\nways, e.g., direction, manner, temporality, etc. (see Ediskun [3]). As depicted in Figure 3.17,\nadverbials are divided into ﬁve subcategories, whose details are given in Figure 3.18.\nadverbials\n✘✘✘✘✘✘✘✘✘✘✘✘\n✟✟✟✟✟✟\n❍\n❍\n❍\n❍\n❍\n❍\n❳\n❳\n❳\n❳\n❳\n❳\n❳\n❳\n❳\n❳\n❳\n❳\ndirection\ntemporal\nmanner\nquantitative\nsentential\nFigure 3.17: Subcategories of adverbials.\nEach adverb has the following additional feature, which describes whether the adverb in con-\nsideration is in questional form or not. For instance, adverbs neden (why) and nasıl (how) are\nin questional form.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n46\nmaj\nmin\nsub\nssub\nadverbial\ndirection\ntemporal\npoint-of-time\ntime-period\nfuzzy\nday-time\nseason\nmanner\nqualitative\nrepetition\nquantitative\napproximation\ncomparative\nsuperlative\nexcessiveness\nsentential\nFigure 3.18: Lexicon categories of adverbials.\nadverbial\n\u0014\nSEM\nh\nQUESTIONAL\n+/−(default: −)\ni\u0015\n3.6.1\nDirection Adverbs\nAs the name implies, direction adverbs modify verbs and verbal forms by specifying direction.\nThe following are examples of direction adverbs: dı¸sarı (out), beri (here), i¸ceri (in), geri (back),\nkar¸sı (opposite).\nConsider the feature structure of the direction adverb dı¸sarı (out), as used in (29):\n(29)\nDı¸sarı mı\n¸cıkıyorsun?\nout\nQUES get+PROG+1SG\n‘Are you getting out?’\ndirection adv\n\n\nCAT\n\nMAJ\nadverbial\nMIN\ndirection\n\n\nMORPH\nh\nSTEM\n“dı¸sarı”\ni\nSEM\nh\nCONCEPT\n#dı¸sarı-(out)\ni\nPHON\n“dı¸sarı”\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n47\n3.6.2\nTemporal Adverbs\nTemporal adverbs specify the point of time and limit the period of states, actions, and processes.\nAs shown in Figure 3.19 temporal adverbs comprise point-of-time and time-period adverbs.\ntemporal adverbs\n✟✟✟✟\n❍\n❍\n❍\n❍\npoint-of-time\ntime-period\nFigure 3.19: Subcategories of temporal adverbs.\nPoint-of-Time Adverbs\nThere are two forms of point-of-time adverbs: lexical and derived. The following two sections\ndescribe these with examples.\nLexical\nThe following are point-of-time adverbs in lexical form: d¨un (yesterday), bug¨un (to-\nday), ¸simdi (now), demin (a moment ago), ¨once (before), ¨onceden (beforehand).\nDerived\nThis form of adverbs are derived from verbs using suﬃxes -yHp and -yHncA. The\nderivation with -yHp produces adverbs that state a subordinate action that happens simulta-\nneously or in sequence with the main action in the sentence. The other type of adverbs state\nan action that happens in sequence with the main action. Consider the following examples:\n(30) a. Bu\nsoruyu,\nkonuyu\nanlayıp\n¸c¨ozmek\nlazım.\nthis question+ACC topic+ACC understand+ADV solve+INF needed+PRES+3SG\n‘It is ﬁrst needed to understand the topic and then to solve this question.’\nb. Bu\nak¸sam\nkitap okuyup\ndinlenecektim.10\nthis evening book read+ADV rest+FUT+PAST+1SG\n‘This evening I was going to read a book and rest.’\nIn the ﬁrst sentence, the adverb, anlayıp, states a subordinate action that is performed before\nthe main action. In the latter one, however, the two actions happen simultaneously.\nEach derived point-of-time adverb has the following additional features, which give the deriva-\ntion suﬃx, subcategorization information and thematic roles of the verb involved in the deriva-\ntion.\n10 This example is due to Underhill [15].\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n48\nderived point-of-time adv\n\n\nMORPH\nh\nDERV-SUFFIX\n“yınca”/“yıp”\ni\nSYN\nh\nSUBCAT\nsubcat\ni\nSEM\nh\nROLES\nroles\ni\n\n\nConsider the feature structure for bitince (when it ends), as used in (31):\n(31) a. Toplantı bitince, konu¸smacıya bu\nkonundaki\nmeeting end+ADV speaker+DAT this subject+LOC+REL\nﬁkrimi\na¸cıkladım.\nopinion+P1SG+ACC explain+PAST+1SG\n‘When the meeting ended, I explained my opinion about this subject to the speaker.’\nb. Odanı\ntoplaman\nbitince\nhemen\nroom+P2SG+ACC tidy up+INF+P2SG finish+ADV immediately\nyatmanı\nistiyorum.\ngo to bed+INF+P2SG+ACC want+PROG+1SG\n‘I want you to go to bed as soon as you ﬁnish tidying up your room.’\nderived point-of-time adv\n\n\nCAT\n\n\nMAJ\nadverbial\nMIN\ntemporal\nSUB\npoint-of-time\n\n\nMORPH\n\n\nSTEM\n1\nFORM\nderived\nDERV-SUFFIX\n“yınca”\n\n\nSYN\nh\nSUBCAT\n2\ni\nSEM\n\nCONCEPT\nfyınca( 4 )\nROLES\n3\n\n\nPHON\n“bitince”\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n49\n1\nlexical predicative verb\n\n\nCAT\n\nMAJ\nverb\nMIN\npredicative\n\n\nMORPH\n\nSTEM\n“bit”\nSENSE\npos\n\n\nSYN\n\n\nSUBCAT\n2\n*\n4\n\n\nSYN-ROLE\nsubject\nOCCURRENCE\noptional\nCONSTRAINTS\n\n\n\nconstraint1,\nconstraint2\n\n\n\n\n\n+\n\n\nSEM\n\n\nCONCEPT\n4 #bit-(to end)\nROLES\n3\nh\nAGENT\n5\ni\n\n\nPHON\n“bit”\n\n\nconstraint1\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nn\nnoun, pronoun\no\n\n\nMORPH\nh\nCASE\nnom\ni\n\n\nconstraint2\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nma\n\n\nMORPH\nh\nCASE\nnom\ni\n\n\nTime-Period Adverbs\nAs Figure 3.20 shows, time-period adverbs are subdivided into three categories: fuzzy, day-time,\nand season adverbs.\nFuzzy\nThere are two forms of fuzzy time-period adverbs: lexical and derived. In the following\ntwo sections we will describe these forms with examples.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n50\ntime-period adverbs\n✟✟✟✟✟\n❍\n❍\n❍\n❍\n❍\nfuzzy\nday-time\nseason\nFigure 3.20: Subcategories of time-period adverbs.\nLexical\nThe following are examples of this form of fuzzy time-period adverbs: dakikalarca\n(for minutes), saatlerce/saatlerdir (for hours).\nDerived\nThis form of adverbs are derived form verbs using the suﬃxes, -yAlH and -ken, as\nin\n(32)\n– sen geleli/gideli\n‘since the time you arrived/went’,\n– biz gelirken\n‘while we are coming’.\nEach derived fuzzy time-period adverb also has the following features. The derivation suﬃx\nis one of -yAlH and -ken. The other features give subcategorization information and semantic\nroles of the verb which are involved in the derivation process.\nderived fuzzy time-period adv\n\n\nMORPH\nh\nDERV-SUFFIX\n“yalı”/“ken”\ni\nSYN\nh\nSUBCAT\nsubcat\ni\nSEM\nh\nROLES\nroles\ni\n\n\nDay-time\nSabahleyin (in the morning), sabahları (in the mornings), ak¸samları (in the evenings),\ng¨und¨uz (in the daytime) and g¨und¨uzleyin (in the daytime) are examples of day-time time-period\nadverbs.\nSeason\nKı¸sın (in the winter) and yazın (in the summer) are two examples of season time-\nperiod adverbs.\n3.6.3\nManner Adverbs\nManner adverbs describe the way and how actions, processes, and states develop. As depicted\nin Figure 3.21 manner adverbs are divided into two subcategories as qualitative and repetition\nadverbs, which are described next in detail.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n51\nmanner adverbs\n✟✟✟\n❍\n❍\n❍\nqualitative\nrepetition\nFigure 3.21: Subcategories of manner adverbs.\nQualitative Manner Adverbs\nThere are two forms of qualitative manner adverbs: lexical and derived. In the next sections,\nwe will describe these forms in detail with examples.\nLexical\nThe following are examples of qualitative manner adverbs in lexical form: birden\n(suddenly), ¸cabuk (fast), ¸cabucak (fast), ¸s¨oyle (like that), nasıl (how).\nDerived\nEach derived qualitative manner adverb has the following additional features, in\nwhich derivation suﬃx, subcategorization information and semantic roles are present. Deriva-\ntion suﬃx feature may take one of the following values: -cAsHnA, -mAksHzHn, -mAdAn,\n-yAmAdAn, -yArAk, and -cA.\nderived qualitative adv\n\n\nMORPH\nh\nDERV-SUFFIX\nderv-suﬃx\ni\nSYN\nh\nSUBCAT\nsubcat (default: none)\ni\nSEM\nh\nROLES\nroles (default: none)\ni\n\n\nThere are two types of derivations to this form of adverbs:\n• Adjectival derivation: This derivation uses the suﬃx -cA, as in akıllıca (intelligently),\nhızlıca (fast), and aptalca (stupidly). Consider the feature structure for the qualitative\nadverb akıllıca as used in (33):11\n(33)\nBug¨un, olduk¸ca akıllıca\ndavrandın.\ntoday\nrather intelligently behave+PAST+2SG\n‘You behaved rather intelligently today.’\n11 SYN | SUBCAT feature is co-indexed with that of akıllı, which is shown in the section on\nqualitative adjectives on page 42.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n52\nderived qualitative adv\n\n\nCAT\n\n\nMAJ\nadverbial\nMIN\nmanner\nSUB\nqualitative\n\n\nMORPH\n\n\nSTEM\n“akıllı”\nFORM\nderived\nDERV-SUFFIX\n“ca”\n\n\nSYN\nh\nSUBCAT\nnone\ni\nSEM\n\nCONCEPT\nfca(flı(#akıl-(intelligence)))\nROLES\nnone\n\n\nPHON\n“akıllıca”\n\n\n• Verb derivation: This derivation uses the suﬃxes -cAsHnA, -mAksHzHn, -mAdAn, -\nyAmAdAn, and -yArAk, as in the examples below:\n(34)\n– ko¸sarcasına\n‘as if running’,\n– g¨ormeksizin\n‘without seeing’,\n– gelmeden\n‘without coming’,\n– g¨oremeden\n‘without seeing’,\n– gelerek\n‘by coming’.\nRepetition Manner Adverbs\nAs the name implies, this category of manner adverbs add repetition to the semantics of the\nverb and verbal forms. There are two forms of repetition manner adverbs, which are lexical\nand derived\nLexical\nTekrar (again), gene (again), sık (frequently) are some examples of this form.\nDerived\nThe derivation to this form is only from verbs and uses the suﬃx -dHk¸cA as in:\n(35)\n– sen geldik¸ce\n‘as you come’,\n– onlar konu¸stuk¸ca\n‘as they talk’.\nEach derived repetition adverb has the following additional feature structure, which has the\nderivation suﬃx, subcategorization information and thematic roles.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n53\nderived repetition adv\n\n\nMORPH\nh\nDERV-SUFFIX\n“dık¸ca”\ni\nSYN\nh\nSUBCAT\nsubcat\ni\nSEM\nh\nROLES\nroles\ni\n\n\n3.6.4\nQuantitative Adverbs\nQuantitative adverbs modify the semantics of adjectivals, adverbials, and verbs in quantity.\nAs shown in Figure 3.22, quantitative adverbs consist of four subcategories, for which many\nexamples are given in the next sections.\nquantitative adverbs\n✏✏✏✏✏✏✏✏✏✏✏\n\u0000\u0000\u0000\u0000❅\n❅\n❅\n❅\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\nP\napproximation\ncomparative\nsuperlative\nexcessiveness\nFigure 3.22: Subcategories of quantitative adverbs.\nApproximation\nA¸saˇgı yukarı (approximately) and hemen hemen (approximately) are two examples of adverbs\nthat are stating approximation.\nComparative\nDaha (more) is the only member of this category.\nSuperlative\nEn (most) is the unique example of this category.\nExcessiveness\nThe following are some examples of quantitative adverbs stating excessiveness: ¸cok (very),\npek/gayet (very), fazla (too much), az/biraz (little).\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n54\n3.6.5\nSentential Adverbs\nSentential adverbs can only modify verbs and verbal forms. The following are some examples of\nsentential adverbs: evet (yes), yok (no), ¨oyle (so), elbette (certainly), ger¸cekten (really), daima\n(always), neden (why).\n3.7\nVerbs\nThis section describes the representation of verbs in our lexicon with an emphasis on argument\nstructures and thematic roles. Verb is the head of sentence, hence it is the most important\nconstituent. It describes a state, action, or process [16]. As shown in Figure 3.23, verbs are\ndivided into three categories as predicative, existential, and attributive verbs.\nverbs\n✟✟✟✟✟✟\n❍\n❍\n❍\n❍\n❍\n❍\npredicative\nexistential\nattributive\nFigure 3.23: Subcategories of verbs.\nEach verb in the lexicon has the following additional features, which represent morhosyntactic,\nsyntactic, and semantic information. none is the default value for all of the features.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n55\nverb\n\n\nMORPH\n\n\nTAM2\ntam2\nCOPULA\n1/2\nAGR\nagr\n\n\nSYN\n\u0014\nSUBCAT\nD\nrole1, . . . , rolei, . . . , rolen\nE\u0015\nSEM\n\n\nROLES\n\n\nAGENT\nEXPERIENCER\nPATIENT\nTHEME\nRECIPIENT\nCAUSER\nACCOMPANIER\nSOURCE\nGOAL\nLOCATION\nINSTRUMENT\nBENEFICIARY\nVALUE-DES\n\n\n\n\n\n\nThere are four morphosyntactic features introduced (see Solak and Oﬂazer [13]). The MORPH | SENSE\nfeature speciﬁes whether the verb states a positive or negative predicate, attribute, etc. There\nare four possible tenses for attributive and existential verbs, which are also the possible second\ntenses for predicative verbs: present, deﬁnite past, narrative past, and conditional forms. This\ninformation is speciﬁed in MORPH | TAM2 feature. The feature MORPH | COPULA gives\nthe usage of the suﬃx, -dHr, which states probability or deﬁniteness. The last one represents\nthe person suﬃx, whose possible values are ﬁrst, second, and third person singular, and plural\npersons.\nThe subcategorization information, which we will describe later in detail, gives the valence of\nthe verb for the active voice.12\n12 There are cases, in which the passive or causative voice of the verb gives a diﬀerent sense\nthan the active voice. In those cases, representation is conﬁgured accordingly, e.g.,\n(36) a.\nKemal’i\nkapıya\nkadar ge¸cirdik.\nKemal+ACC door+DAT up to see off+PAST+1PL\n‘We see Kemal oﬀat the door.’\nb.\n˙Ibrahim Ay¸se’ye\nvuruldu.\nIbrahim Ay¸se+DAT fall in love+PAST+3SG\n‘˙Ibrahim fell in love with Ay¸se.’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n56\nThe feature SEM | ROLES describes the thematic roles of the arguments of the verb. These\nrole ﬁllers are the following (see Yılmaz [16]):\n• agent,\n• experiencer,\n• theme,\n• patient,\n• causer,\n• accompanier,\n• recipient,\n• goal,\n• source,\n• instrument,\n• value designator,\n• beneﬁciary,\n• location.\nThe subcategorization information is given as a list of elements, each one describing an argument\nof the verb in question. Each such description consists of three features:\nrolei\n\n\nSYN-ROLE\nsyn-role\nOCCURRENCE\nobligatory/optional\nCONSTRAINTS\nn\nconstraint1, . . . , constraintj, . . . , constraintm\no\n\n\nThe feature SYN-ROLE gives the argument type, which is one of the following:\n• subject,\n• direct object,\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n57\n• agentive object,\n• oblique objects (dative, ablative, locative)\n• instrumental object,\n• beneﬁciary object,\n• value designator.\nThe second feature describes whether the occurrence of the argument is obligatory or optional.\nThe last feature gives a list of constraints on the argument in consideration.\nElements in the subcategorization list are co-indexed with corresponding thematic role ﬁllers\naccording to the verb in consideration, i.e., there is a mapping from grammatical functions to\nthematic roles. For example, direct object is generally co-indexed with patient or theme.\nThe types of constraint structures are diﬀerent for subject and (direct, oblique, and agentive)\nobjects, instrumental object, value designator, and beneﬁciary object. Each structure will be\ndescribed in turn:\n• Constraint structures for subject, direct, oblique and agentive objects: The type of con-\nstraint structures for subject, direct, oblique, and agentive objects is given below. This\nfeature structure gives constraints on the category, which is nominal in the most general\ncase, a number of morphosyntactic and semantic properties of the argument.\nconstraintj\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nmin\nSUB\nsub\nSSUB\nssub\nSSSUB\nsssub\n\n\nMORPH\n\n\nSTEM\nstem\nCASE\ncase\nPOSS\nposs\nAGR\nagr\n\n\nSEM\n[]\n\n\nThe subject never takes a case marking, i.e., it is in nominative case. There are cases\nthat morphosyntactic features, other than the case, should be constrained, as well, as\nillustrated below:\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n58\n(37) a. ˙Istanbul’u\nsel aldı.\nIstanbul+ACC be flooded+PAST+3SG\n‘˙Istanbul is ﬂooded.’\nb. C¸ocuk kafayı yedi.\nboy\nget mentally deranged+PAST+3SG\n‘The boy got mentally deranged.’\nIn (37a), in addition to the case, the stem and the possessive marker are required to be\nsel and none, respectively. In the second sentence, however, the requirements are the\nfollowing: the stem of the direct object is kafa; it has accusative case and 3sg agreement\nmarkers, and it is not possessive-marked.\nSemantic constraints can also be posed in these structures. For example, the verb sense\nkafayı ye (to get metally deranged) requires the subject to be human.\nThe direct object may be in nominative or accusative cases, while oblique objects are in\ndative, ablative, and locative cases.\nThe agentive object is in ablative case, and its stem is taraf with a suitable possessive\nmarker. An example sentence is given in (38):\n(38)\nSorun\nbizim\ntarafımızdan ¸c¨oz¨uld¨u.\nproblem us+GEN by\nsolve+PASS+PAST+3SG\n‘The problem is solved by us.’\n• Constraint structrures for instrumental object: The following are the constraint structures\nfor the instrumental object. There are two possible types for this argument. The ﬁrst type\nis for nominals, which are instrumental case-marked. The second is for post-positional\nphrases, whose heads are the post-position ile:13\nconstraintj\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nmin\nSUB\nsub\nSSUB\nssub\nSSSUB\nsssub\n\n\nMORPH\nh\nCASE\nins\ni\nSEM\n[]\n\n\n13\nThere\nare\ntwo\nadditional\nforms\nwith\nthe\nnominals\nsaye+POSS+LOC\nand\naracılık+POSS+INS (aracılık+POSS ile). These can be represented with the structures in-\ntroduced above by imposing proper morphosyntactic constraints, e.g., MORPH | STEM =\n“saye”, MORPH | CASE = loc, MORPH | AGR = 3sg. But we will omit these forms.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n59\nconstraintj\n\n\nCAT\n\nMAJ\npost-position\nMIN\nins-subcat\n\n\nMORPH\nh\nSTEM\n“ile”\ni\nSEM\n[]\n\n\n• Constraint structures for value designator: There are two forms in a sentence to describe\na value designator. The ﬁrst form uses a nominal, which is dative case-marked. The\nsecond uses a post-positional phrase whose head is i¸cin, as used in (39):14\n(39)\nOralarda\n10 dolar i¸cin adam ¨old¨ur¨uler.\nthere+LOC 10 dolar for man\nkill+ARST+3PL\nThey will kill you for 10 dollars there.\nThus, the two feature structures that are introduced for instrumental object can be used\nfor the value designator by replacing the values of case, stem, and the minor category\nfeatures with dative, i¸cin, and nom-subcat respectively.\n• Constraint structures for beneﬁciary object: The feature structure below is for the bene-\nﬁciary object, which is a post-positional phrase whose head is the post-position, i¸cin:\nconstraintj\n\n\nCAT\n\nMAJ\npost-position\nMIN\nnom-subcat\n\n\nMORPH\nh\nSTEM\n“i¸cin”\ni\nSEM\n[]\n\n\nFurthermore, the oblique object case-marked as dative can be mapped to the beneﬁciary,\nas depicted in the following example:\n(40)\nAnnesi,\n¸cocuˇga\nuyumadan\n¨once\nkitap okudu.\nmother+P1SG boy+DAT sleep+INF+ABL before book read+PAST+3SG\n‘His mother read book for the boy before he slept.’\nAs mentioned above, the subcategorization information for verbs in lexical form is given as a\nlist, in which each element gives constraints on an argument of the verb in consideration. Since\nthe members of other categories in lexical form, such as common nouns, qualitative adjectives,\nand post-positions, cannot have more than one argument, just the constraint lists for one\ncomplement are given.\nIn the following sections we will describe the subcategories of verbs in detail.\n14 This example is due to Yılmaz [16].\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n60\n3.7.1\nPredicative Verbs\nPredicative verb category comprises the verbs that are not existential or attributive. There are\ntwo forms of predicative verbs, which are lexical and derived. These forms are described in the\nnext sections.\nEach predicative verb has the following additional morphosyntactic features:\npredicative verb\n\n\nMORPH\n\n\nSENSE\npos/neg\nTAM1\ntam1\n(default: none)\nCOMP\ncomp\n(default: none)\nPASSIVE\n+/−\n(default: −)\nRECIPROCAL\n+/−\n(default: −)\nREFLEXIVE\n+/−\n(default: −)\nCAUSATIVE\nn\n(default: 0)\n\n\n\n\nThe ﬁrst tense-aspect-mood marker is speciﬁed in MORPH | TAM1 feature, for which there are\nten possible values: present, deﬁnite past, narrative past, future, aorist, progressive, conditional,\noptative, necessitative, and imperative. If the verb is a compound one, the compounding suﬃx is\ngiven in MORPH | COMP feature, whose value is one of -yAbil, -yHver, -yAdur, -yAkoy, -yAkal,\nand -yAyaz. The last four features represent the voice of the verb. The value n represents a\npositive integer number, which denotes the level of causation (see Solak and Oﬂazer [13]).\nLexical\nThis form of predicative verbs are present in the lexicon as lexical entries mainly consisting of\nsubcategorization information and thematic roles. The following are example predicative verbs\nin lexical form:\n(41)\n– ye-\n‘eat’,\n– i¸c-\n‘drink’,\n– g¨or-\n‘see’,\n– hediye et-\n‘give present’,\n– kafayı ye-\n‘get mentally deranged’,\n– r¨u¸svet ye-\n‘receive bribe’.\nSome of the predicative verbs consist of more than one word, e.g., kafayı ye- (get mentally\nderanged), rezil et- (disgrace), rezil ol- (be disgraced), kavga et- (quarrel), some of which are\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n61\nconstructed with the auxiliary verbs et- and ol-. The verbs whose ﬁrst constituents are not\nnominals are taken as separate compound verbs, whereas there are two cases for the ones whose\nﬁrst constituents are nominals. In the ﬁrst case, such constituents are not subject to inﬂections\nas in (42a):\n(42) a. *Biz yine de hediyemizi\nederiz.\nwe\nanyway present+1PL+ACC do+ARST+1PL\nb. Biz gerekirse\nkavgamızı\nederiz.\nwe if needed fight+1PL+ACC do+ARST+1PL\n‘If needed, we will ﬁght.’\nThis type of verbs are taken separately as compound verbs. In the latter case, as in (42b), such\nconstituents are subject to inﬂection, which are taken as a diﬀerent sense of the main verb, and\nthe ﬁrst constituent is given as an object in the argument structure. For example, kavga et-\n(quarrel) is represented as a sense of et-, and kavga (quarrel) is the direct object of this sense.\nWe will give feature structures for four senses of the verb, ye-, which are the following:\n1. eat something,\n2. eat from something,\n3. get mentally deranged,\n4. be unfair.\nThe following is the feature structure for the ﬁrst sense, eat something, as used in (43):\n(43)\nAdam ¸catalla\npastayı\nyedi.\nman\nfork+INS pastry+ACC eat+PAST+3SG\n‘The man ate the pastry with fork.’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n62\nlexical predicative verb\n\n\nCAT\n\nMAJ\nverb\nMIN\npredicative\n\n\nMORPH\n\n\nSTEM\n“ye”\nFORM\nlexical\nSENSE\npos\nTAM1\npast\nAGR\n3sg\n\n\nSYN\n\n\nSUBCAT\n*\n1\n\n\nSYN-ROLE\nsubject\nOCCURRENCE\noptional\nCONSTRAINTS\nn\nconstaint1\no\n\n,\n2\n\n\nSYN-ROLE\ndir-obj\nOCCURRENCE\noptional\nCONSTRAINTS\n\n\n\nconstaint2,\nconstaint3\n\n\n\n\n\n,\n3\n\n\nSYN-ROLE\ninst-obj\nOCCURRENCE\noptional\nCONSTRAINTS\n\n\n\nconstaint4,\nconstaint5\n\n\n\n\n\n+\n\n\nSEM\n\n\nCONCEPT\n#ye-(to eat something)\nROLES\n\n\nAGENT\n1\nTHEME\n2\nINSTRUMENT\n3\n\n\n\n\nPHON\n“yedi”\n\n\nconstraint1\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nn\nnoun, pronoun\no\n\n\nMORPH\nh\nCASE\nnom\ni\nSEM\nh\nANIMATE +\ni\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n63\nconstraint2\n\n\nCAT\n\nMAJ\nnominal\nMIN\nnoun\n\n\nMORPH\n\u0014\nCASE\nn\nacc, nom\no\u0015\nSEM\nh\nEDIBLE +\ni\n\n\nconstraint3\n\n\nCAT\n\nMAJ\nnominal\nMIN\npronoun\n\n\nMORPH\nh\nCASE\nacc\ni\n\n\nconstraint4\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nn\nnoun, pronoun\no\n\n\nMORPH\nh\nCASE\nins\ni\nSEM\nh\nINSTRUMENT\n+\ni\n\n\nconstraint5\n\n\nHEAD\n\n\nCAT\n\nMAJ\npost-position\nMIN\nins-subcat\n\n\nMORPH\nh\nSTEM\n“ile”\ni\n\n\nSEM\nh\nINSTRUMENT\n+\ni\n\n\nThe following is the feature structure for the second sense, eat from something, as used in\n(44):15\n(44)\nAdam ¸catalla\npastadan\nyedi.\nman\nfork+INS pastry+ABL eat+PAST+3SG\n‘The man ate from the pastry with fork.’\nThe diﬀerence between the ﬁrst and the second senses is that the patient, pasta (pastry), is the\ndirect object in the former one, whereas, it is the oblique object in ablative case in the latter.\nNote that the second sense does not subcategorize for a direct object.\n15 The feature structure for subject and instrumental object are the same with those of\nprevious example.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n64\nlexical predicative verb\n\n\nCAT\n\nMAJ\nverb\nMIN\npredicative\n\n\nMORPH\n\n\nSTEM\n“ye”\nFORM\nlexical\nSENSE\npos\nTAM1\npast\nAGR\n3sg\n\n\nSYN\n\n\nSUBCAT\n*\n1\n\n\nSYN-ROLE\nsubject\nOCCURRENCE\noptional\nCONSTRAINTS\nn\nconstaint1\no\n\n,\n2\n\n\nSYN-ROLE\nobl-abl\nOCCURRENCE\noptional\nCONSTRAINTS\nn\nconstaint2\no\n\n,\n3\n\n\nSYN-ROLE\ninst-obj\nOCCURRENCE\noptional\nCONSTRAINTS\n\n\n\nconstaint3,\nconstaint4\n\n\n\n\n\n+\n\n\nSEM\n\n\nCONCEPT\n#ye-(to eat from something)\nROLES\n\n\nAGENT\n1\nTHEME\n2\nINSTRUMENT\n3\n\n\n\n\nPHON\n“yedi”\n\n\nconstraint2\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nn\nnoun, pronoun\no\n\n\nMORPH\nh\nCASE\nabl\ni\nSEM\nh\nEDIBLE\n+\ni\n\n\nThe following is the feature structure for the third sense of ye-, get mentally deranged, as shown\nin (45):\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n65\n(45)\nC¨uneyt, okulda\n¸cok\n¸calı¸smaktan\nC¨uneyt school+LOC too much working+ABL\nkafayı yedi.\nget mentally deranged+PAST+3SG\n‘C¨uneyt got mentally deranged from too much working at the school.’\nNote that the direct object has to be kafayı, and it is not a semantic role ﬁller.\nlexical predicative verb\n\n\nCAT\n\nMAJ\nverb\nMIN\npredicative\n\n\nMORPH\n\n\nSTEM\n“ye”\nFORM\nlexical\nSENSE\npos\nTAM1\npast\nAGR\n3sg\n\n\nSYN\n\n\nSUBCAT\n*\n1\n\n\nSYN-ROLE\nsubject\nOCCURRENCE\noptional\nCONSTRAINTS\nn\nconstaint1\no\n\n,\n\n\nSYN-ROLE\ndir-obj\nOCCURRENCE\nobligatory\nCONSTRAINTS\nn\nconstaint2\no\n\n\n+\n\n\nSEM\n\n\nCONCEPT\n#ye-(to get mentally deranged)\nROLES\nh\nEXPERIENCER\n1\ni\n\n\nPHON\n“yedi”\n\n\nconstraint1\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nn\nnoun, pronoun\no\n\n\nMORPH\nh\nCASE\nnom\ni\nSEM\nh\nHUMAN\n+\ni\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n66\nconstraint2\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\n\nSTEM\n“kafa”\nCASE\nacc\nAGR\n3sg\nPOSS\nnone\n\n\n\n\nThe feature structure for the fourth sense of ye- is given below, in which the direct object, hak,\nis optionally accusative case-marked, as below:\n(46) a. Oˇguz hep\nhak yiyor.\nOˇguz always be unfair+PROG+3SG\n‘Oˇguz is always unfair.’\nb. Oˇguz ba¸skalarının da\nhaklarını yedi.\nOˇguz others+GEN too be unfair+PAST+3SG\n‘Oˇguz was unfair to the others, too.’\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n67\nlexical predicative verb\n\n\nCAT\n\nMAJ\nverb\nMIN\npredicative\n\n\nMORPH\n\n\nSTEM\n“ye”\nFORM\nlexical\nSENSE\npos\nTAM1\npast\nAGR\n3sg\n\n\nSYN\n\n\nSUBCAT\n*\n1\n\n\nSYN-ROLE\nsubject\nOCCURRENCE\noptional\nCONSTRAINTS\nn\nconstaint1\no\n\n,\n2\n\n\nSYN-ROLE\ndir-obj\nOCCURRENCE\nobligatory\nCONSTRAINTS\nn\nconstaint2\no\n\n\n+\n\n\nSEM\n\n\nCONCEPT\n#ye-(to be unfair)\nROLES\n\nAGENT\n1\nTHEME\n2\n\n\n\n\nPHON\n“yedi”\n\n\nconstraint1\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nn\nnoun, pronoun\no\n\n\nMORPH\nh\nCASE\nnom\ni\n\n\nconstraint2\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\n\nSTEM\n“hak”\nCASE\nn\nacc, nom\no\n\n\n\n\nDerived\nThis form of verbs are derived from nominals and adjectivals using the suﬃxes -lAn and -lA¸s.\nEach derived predicative verb has the following additional feature, which gives the derivation\nsuﬃx.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n68\nderived verbal\n\u0014\nMORPH\nh\nDERV-SUFFIX\n“lan”/“la¸s”\ni\u0015\nThere are two types of derivations to predicative verbs:\n• Nominal derivation: This derivation uses the suﬃxes -lAn and -lA¸s. The following are\nsome examples of predicative verbs derived form nominals:\n(47)\n– ta¸sla¸s-\n‘turn into stone’,\n– aˇga¸clandır-\n‘plant trees in an area’,\n– sinirlen-\n‘get nervous’.\nConsider the feature structure for sinirlen-, as used in (48):\n(48)\nTembellik etmen\nbeni\n¸cok\nsinirlendiriyor!\nlaziness do+INF+P2SG me+ACC very make angry+PROG+3SG\n‘Your laziness is making me very angry!’\nderived predicative verb\n\n\nCAT\n\nMAJ\nverb\nMIN\npredicative\n\n\nMORPH\n\n\nSTEM\n1\nFORM\nderived\nDERV-SUFFIX\n“lan”\nSENSE\npos\nTAM1\nprog1\nCAUSATIVE\n1\n\n\nSYN\nh\nSUBCAT\n2 none\ni\nSEM\n\nCONCEPT\nflan( 3 )\nROLES\nnone\n\n\nPHON\n“sinirlendiriyor”\n\n\n1\nlexical common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\nSTEM\n“sinir”\nFORM\nlexical\n\n\nSYN\nh\nSUBCAT\n2 none\ni\nSEM\nh\nCONCEPT\n3 #sinir-(anger)\ni\nPHON\n“sinir”\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n69\n• Adjectival derivation: This derivation uses the same suﬃxes. The following are some\nexamples of predicative verbs derived from adjectivals: iyile¸s- (recover from illness), uza-\nkla¸s-, (go away from), yaralan- (be hurted).\n3.7.2\nExistential Verbs\nThis category of verbs consists of only var (existent) and yok (nonexistent), which state existence\nand non-existence in sentences, respectively. Two example sentences are given in (49):\n(49) a. Masamda\nkaˇgıt\nve\nkalem\nvar.\ntable+P1SG+LOC paper and pencil existent+PRES+3SG\n‘There are paper and pencil on my table.’\nb. Bug¨un yapacak fazla i¸sim\nyok.\ntoday do+PART much work+P1SG nonexistent+PRES+3SG\n‘I don’t have much work to do today.’\n3.7.3\nAttributive Verbs\nAttributive verbs state properties of entities. This category consists of verbs in lexical and\nderived forms, which are described in the next sections.\nLexical\nThe only attributive verb that is in lexical form is deˇgil (not). This verb makes the sentences\nnegative whose heads, otherwise, are existential or derived attributive verbs, as shown in (50):\n(50) a. Onun bisikleti\nkırmızıydı.\nhis\nbicycle+P3SG red+PAST+3SG\n‘His bicycle was red.’\nb. Onun bisikleti\nkırmızı deˇgildi.\nhis\nbicycle+P3SG red\nNOT+PAST+3SG\n‘His bicycle was not red.’\nDerived\nThere are three ways to derive attributive verbs: from nominals, adjectivals, and post-positions.\nAttributive verbs in derived form have the following additional feature giving the derivation\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n70\nsuﬃx, whose value is none, since none of the three derivations uses a suﬃx:\nderived attributive verb\n\u0014\nMORPH\nh\nDERV-SUFFIX\nnone\ni\u0015\nThere are three types of derivations to attributive verbs:\n• Nominal derivation: The sentences below use this type of verb forms:\n(51) a. O\nyediˇgin\nbenim elmamdı.\nthat eat+PART+P2SG my\napple+P1SG+PAST+3SG\n‘It was my apple that you ate.’\nb. Bu\ns¨ut¨un\nson\nkullanma\ntarihi d¨unm¨u¸s.\nthis milk+GEN last usage+P3SG date yesterday+NARR+3SG\n‘The expiry date of this milk was yesterday.’\n• Adjectival derivation: The sentences below give some examples of attributive verbs de-\nrived from adjectivals:\n(52) a. Hızlı yazmakta\nolduk¸ca becerikliyim.\nfast write+INF+LOC very\nskillful+PRES+1SG\n‘I am very skillful in writing fast.’\nb. Sen ka¸cıncısın?\nyou in what rank+PRES+2SG\n‘What is your rank?’\nConsider the following feature structure for bor¸cluyum, as used in (53), which is derived\nfrom the qualitative adjective bor¸clu (that owing debt). Note that bor¸clu is also derived\nfrom the common noun, bor¸c (debt):16\n(53)\nBa¸sarımı\n¸cok\n¸calı¸smama\nbor¸cluyum.\nsuccess+P1SG+ACC very much work+INF+DAT debtor+PRES+1SG\n‘It was my hard working that brought my success.’\n16 This example derivation considers only one sense of bor¸c. This process is repeated for all\nof the senses of this noun regardless of the semantics of the derivation with the suﬃxes used.\nFurthermore, if the morphological processor allows a derivation starting from the adjective\nbor¸clu, this path is followed, as well.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n71\nderived attributive verb\n\n\nCAT\n\nMAJ\nverb\nMIN\nattributive\n\n\nMORPH\n\n\nSTEM\n1\nFORM\nderived\nAGR\n1sg\nTAM2\npres\nDERV-SUFFIX\nnone\n\n\nSYN\nh\nSUBCAT\n2\ni\nSEM\nh\nCONCEPT\nfnone( 3 )\ni\nPHON\n“bor¸cluyum”\n\n\n1\nderived qualitative adj\n\n\nCAT\n\n\nMAJ\nadjectival\nMIN\nadjective\nSUB\nqualitative\n\n\nMORPH\n\n\nSTEM\n4\nFORM\nderived\nDERV-SUFFIX\n“lı”\n\n\nSYN\n\n\nSUBCAT\n2\nMODIFIES\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\n\n\n\n\nSEM\nh\nCONCEPT\n3 flı( 5 )\ni\nPHON\n“bor¸c+lı”\n\n\n4\nlexical common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\nSTEM\n“bor¸c”\nFORM\nlexical\n\n\nSYN\n\u0014\nSUBCAT\n2\nn\nconstraint1, constraint2, constraint3\no\u0015\nSEM\nh\nCONCEPT\n5 #bor¸c-(debt)\ni\nPHON\n“bor¸c”\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n72\nconstraint1\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nn\nnoun, pronoun\no\n\n\nMORPH\nh\nCASE\ndat\ni\n\n\nconstraint2\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nma\n\n\nMORPH\nh\nCASE\ndat\ni\n\n\nconstraint3\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nyı¸s\n\n\nMORPH\n\nCASE\ndat\nPOSS\n¬none\n\n\n\n\n• Post-position derivation: The following example demonstrates the derivation from post-\nposition sonra:\n(54)\nSen benden sonrasın.\nyou me+ABL after+PRES+2SG\n‘You are after me.’\n3.8\nConjunctions\nThis section describes the representation of conjunctions in our lexicon.\nConjunctions are\nfunction words, i.e., they do not convey meaning when used alone. They are used to conjoin\nwords, phrases, and sentences both syntactically and semantically (see Ediskun [3]). As shown\nin Figure 3.24, conjunctions are divided into three subcategories: coordinating, bracketing and\nsentential conjunctions.\nThe next three sections describe the subcategories of conjunctions with examples.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n73\nconjunctions\n✟✟✟✟✟✟✟\n❍\n❍\n❍\n❍\n❍\n❍\n❍\ncoordinating\nbracketing\nsentential\nFigure 3.24: Subcategories of conjunctions.\n3.8.1\nCoordinating Conjunctions\nThe following are examples of coordinating conjunctions: ile (and), ve (and), veya (or), ila\n(between . . . and).\nConsider the feature structure of the coordinating conjunction ve (and), as used in the example\nbelow:\n(55)\nBug¨un ve\nyarın\nhava\nbulutlu olacakmı¸s.\ntoday and tomorrow weather cloudy be+FUT+NARR+3SG\n‘They say, today and tomorrow the weather will be cloudy.’\ncoordinating\n\n\nCAT\n\nMAJ\nconjunction\nMIN\ncoordinating\n\n\nMORPH\nh\nSTEM\n“ve”\ni\nSEM\nh\nCONCEPT\n#ve-(and)\ni\nPHON\nve”\n\n\n3.8.2\nBracketing Conjunctions\nBracketing conjunctions are used in pairs. These have the following two semantic features. The\nﬁrst gives the polarity of the conjunction, e.g., the polarity of ne . . .\nne (neither . . . nor) is\nnegative, while it is positive for hem . . . hem (both . . . and). The second speciﬁes how the two\nelements bracketed are connected.\nbracketing\n\nSEM\n\nPOLARITY\n+/−(default: +)\nCONNECTION\nand/or (default: and)\n\n\n\n\nThe following are some examples of bracketing conjunctions: gerek . . . gerek(se) (both . . . and),\nne . . . ne (neither . . . nor), hem . . . hem (both . . . and), ya . . . ya (either . . . or).\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n74\nThe following is the feature structure of the bracketing conjunction, gerek . . . gerek (both\n. . . and), as used in (56):\n(56)\nGerek Y¨ucel gerek Uˇgur bug¨un ¸cok\nhızlı ko¸stular.\nboth\nY¨ucel and\nUˇgur today very fast run+PAST+3PL\n‘Both Y¨ucel and Uˇgur ran very fast today.’\nbracketing\n\n\nCAT\n\nMAJ\nconjunction\nMIN\nbracketing\n\n\nMORPH\nh\nSTEM\n“gerek . . . gerek”\ni\nSEM\nh\nCONCEPT\n#gerek . . . gerek-(both . . . and)\ni\nPHON\n“gerek . . . gerek”\n\n\n3.8.3\nSentential Conjunctions\nSentential conjunctions conjoin sentences.\nAncak (but), ¸c¨unk¨u (because), hatta (even), ama\n(but), nitekim (just as), eˇger (if), yani (that is to say), and ¨ustelik (furthermore) are some\nexamples of sentential conjunctions.\n3.9\nPost-positions\nThis section describes the representation of post-positions in our lexicon. Like conjunctions,\npost-positions are function words, i.e., they do not have meaning, unless they are used with\nnominals in order to construct post-positional phrases (see Ediskun [3]). As shown in Fig-\nure 3.25, post-positions are subdivided into six categories according to their subcategorization\ntypes (speciﬁcally, the case of the complement).\npost-positions\ninstrumental\naccusative\nnominative\ndative\nablative\ngenitive\nsubcat\nsubcat\nsubcat\nsubcat\nsubcat\nsubcat\nFigure 3.25: Subcategories of post-positions.\nEach post-position also has the following feature, which gives the subcategorization information\nfor only one argument, in contrast to the case in verbs, which accept a number of arguments,\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n75\nsuch as subject, direct object, etc. For this reason the subcategorization information of post-\npositions consists of just a list of constraints for only one argument.\npost-position\n\u0014\nSYN\nh\nSUBCAT\nsubcat\ni\u0015\nIn the next sections we will describe the subcategories and give examples for each of them.\n3.9.1\nPost-positions with Nominative Subcategorization\nPost-positions belonging to this subcategory accept nominals in nominative case as comple-\nments. Boyunca (along/during), takdirde (if), diye (named), i¸cin (for) are examples of post-\npositions with nominative subcategorization.\nThe feature structure of the post-position, i¸cin (for/because/in order to), as used in (57), is\ngiven below, though the case of the complement is genitive for pronouns:\n(57) a. Almayı\nunuttuˇgum\nkitaplar\ni¸cin odama\ntake+INF+ACC forget+PART+P1SG book+3PL for room+P1SG+DAT\ntekrar\ngittim.\nagain\ngo+PAST+1SG\n‘I went to my room again for the books that I forgot to take.’\nb. Ba¸sarılı\nolabilmesi\ni¸cin ¸cok\n¸calı¸sması\nsuccesfull be+ABIL+INF+P3SG for much work+INF+P3SG\ngerekiyor.\nneeded+PROG+3SG\n‘In order to be successful, he should work hard.’\nnom-subcat\n\n\nCAT\n\nMAJ\npost-position\nMIN\nnom-subcat\n\n\nMORPH\nh\nSTEM\n“i¸cin”\ni\nSYN\n\nSUBCAT\n\n\n\nconstraint1, constraint2, constraint3,\nconstraint4, constraint5, constraint6\n\n\n\n\n\nSEM\nh\nCONCEPT\n#i¸cin-(for/because/in order to)\ni\nPHON\n“i¸cin”\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n76\nconstraint1\n\n\nCAT\n\nMAJ\nnominal\nMIN\nnoun\n\n\nMORPH\nh\nCASE\nnom\ni\n\n\nconstraint2\n\n\nCAT\n\nMAJ\nnominal\nMIN\npronoun\n\n\nMORPH\nh\nCASE\ngen\ni\n\n\nconstraint3\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nmak\n\n\nMORPH\n\nCASE\nnom\nPOSS\nnone\n\n\n\n\nconstraint4\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nma\n\n\nMORPH\n\nCASE\nnom\nPOSS\n¬none\n\n\n\n\nconstraint5\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nyı¸s\n\n\nMORPH\nh\nCASE\nnom\ni\n\n\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n77\nconstraint6\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nsentential\nSUB\nact\nSSUB\nparticiple\n\n\nMORPH\n\nCASE\nnom\nPOSS\n¬none\n\n\n\n\n3.9.2\nPost-positions with Accusative Subcategorization\nPost-positions belonging to this subcategory accept nominals in accusative case as complements.\nThe following examples are post-positions belonging to this category: a¸skın (over), takiben\n(following), m¨uteakiben (following).\n3.9.3\nPost-positions with Dative Subcategorization\nPost-positions belonging to this subcategory accept nominals in dative case as complements.\nThe following examples are post-positions belonging to this category: ait (belonging to), g¨ore\n(according to), dek (until), kar¸sın (in spite of), y¨onelik (aimed at), doˇgru (towards), ili¸skin\n(related to).\n3.9.4\nPost-positions with Ablative Subcategorization\nPost-positions belonging to this subcategory accept nominals in ablative case as complements.\nDolayı (due to), ¨ot¨ur¨u (due to), itibaren (starting from), sonra (after), and ¨once (before) are\nexamples of post-positions with ablative subcategorization.\n3.9.5\nPost-positions with Genitive Subcategorization\nPost-positions belonging to this subcategory accept nominals (speciﬁcally, pronouns) in genitive\ncase as complements. ˙Ile (with) is an example of this type of post-positions.\nCHAPTER 3. A LEXICON DESIGN FOR TURKISH\n78\n3.9.6\nPost-positions with Instrumental Subcategorization\nPost-positions belonging to this subcategory accept nominals in instrumental case as comple-\nments. The following post-positions are examples of this category: birlikte (together), beraber\n(together).\nChapter 4\nOperational Aspects of the\nLexicon\nOur lexicon provides necessary morphosyntactic, syntactic, and semantic information to NLP\nsubsystems performing syntactic analysis, tagging, semantic disambiguation, etc.\nThe whole system consists of three main parts:\n1. a morphological processor/analyzer,\n2. a static lexicon, and\n3. a module ﬁltering the output according to the user’s restrictions.\nAs depicted in Figure 4.1, the system receives a query form, which includes, at least, a surface\nform and other information acting as the restrictions on the output feature structures. The\nsurface form is ﬁrst directed to the morphological processor, which generates all possible in-\nterpretations (i.e., parses or lexical forms) and forwards these to the static lexicon. The static\nlexicon accesses feature structure database and retrieves syntactic and semantic information for\nthe root words involved in the interpretations. Having uniﬁed the morphosyntactic information\nprovided with corresponding syntactic and semantic information retrieved, the static lexicon\noutputs a list of feature structures. The ﬁnal step in the process is the elimination of the feature\nstructures which do not satisfy the user’s restrictions.\nIn this way, the NLP subsystems using the lexicon do not need to interface with the morpholog-\nical processor to obtain interpretations, rather they just provide the surface form and receive\nthe corresponding feature structures containing morphosyntactic, syntactic, and semantic in-\nformation.\n79\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n80\nIn this chapter, we will ﬁrst describe the interface to the lexicon. Section 4.2 describes how the\nsystem produces feature structures step by step by giving examples, and Section 4.3 mentions\nproblems and limitations related with this task.\n4.1\nInterfacing with the Lexicon\nWe presented many examples of feature structures in Chapter 3 and will describe the method\nof producing those feature structures in the next section.\nIn this section, we will mainly\nconcentrate on how NLP subsystems can use our lexicon.\nOur lexicon is a front end for a morphological analyzer. Given a surface form with restriction\nfeatures, it generates all the morphosyntactic, syntactic, and semantic information for this\nsurface form, that is it abstracts morphological analysis and associates syntactic and semantic\ninformation with each interpretation (see Figure 4.2).\nThe interface described above can be used by a syntactic analyzer for Turkish. Additionally,\ntaggers and word sense disambiguators can employ our lexicon. Taggers need to set necessary\nconstraints, which are generally on category and morphosyntactic features, in the query form.\nConsider the following example:\n(58) a. evin\nkapısı\nhouse+GEN door+P3SG\n‘door of the house’\nb. senin\nevin\nyou+GEN house+P2SG\n‘your house’\nIn the two noun phrases above, the surface form evin exists with two diﬀerent interpretations:\nin the ﬁrst one, it is genitive case-marked and singular with no possessive marking, whereas in\nthe second one it is nominative case-marked with 2sg possessive marking. The ambiguity can\nbe resolved with the help of morphological features, i.e., case or possessive markings.\nWord sense disambiguation is also possible by making use of semantic features in the feature\nstructures. For example, the two senses of the root word kazma (stupid person and pickaxe) can\nbe resolved by setting the SEM | ANIMATE feature in the query form properly. Adding seman-\ntic features increases the accuracy of word sense disambiguation process. However, rather than\nadding arbitrary semantic features on demand, constructing an ontology describing concepts\nvia a semantic network would be more useful.\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n81\nApplication of\nrestrictions\nMorphological\nprocessor\nmorphological\nparse(s)\nlist of \nfeature structures\nlist of \nfeature structures\nNLP subsystems\nStatic lexicon\nrestriction feature(s)\nsurface form\nquery form\nsatisfying restrictions\nFigure 4.1: Data ﬂow in the lexicon.\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n82\nMorphological\nanalyzer\nsurface\nform\nmorphological\nparse(s)\nGenerator, etc.\nSyntactic analyzer\nTagger,\nfeature \nstructure(s)\nStatic lexicon\nLexicon\nquery form\nFigure 4.2: NLP subsystems interfacing with the lexicon.\nText generators for Turkish or transfer units to Turkish in machine translation systems can also\nmake use of our lexicon to obtain information about root words. However, the SEM | CON-\nCEPT feature may not be directly usable by transfer units, since the English deﬁnition in this\nfeature is mostly human oriented.\nThe input query form is basically a feature structure, which contains two types of information:\na surface form and a set of other features. The surface form guides the system in producing\nthe feature structures, that is it is the actual input for the output of the lexicon. It is speciﬁed\nas the phonology information (the PHON feature) in the query form. The rest of the features\nare optional and act as restrictions on the output structures. In fact, the query form subsumes\neach of the actual output feature structures. Any set of features can be speciﬁed in the query\nform provided that they are consistent and appropriate for the intended structure.\nThe process of eliminating or ﬁltering the output feature structures that do not satisfy the\nrestrictions in the query form is the last step in the whole process.\nConsider the following query form placing morphosyntactic and semantic restrictions on the\nsurface form ekimde, that is the root word should not be possessive-marked, and its semantics\nshould state temporality.\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n83\nquery form\n\n\nMORPH\nh\nPOSS\nnone\ni\nSEM\nh\nTEMPORAL\n+\ni\nPHON\n“ekimde”\n\n\nAccording to the morphological processor, there are two interpretations of ekimde:\n1. Ekimde (in October): The ﬁrst interpretation is a lexical common noun representing a\nmonth of the year, as used in the following sentence:\n(59) a. Bu\ni¸si\nEkim’de\nbitirmeliydik.\nthis job October+LOC finish+NECS+PAST+1PL\n‘We should have ﬁnished this job in October.’\nRegarding this interpretation the system produces the following feature structure:\nlexical common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\n\nSTEM\n“ekim”\nAGR\n3sg\nPOSS\nnone\nCASE\nloc\n\n\nSYN\nh\n. . .\ni\nSEM\n\nTEMPORAL\n+\n. . .\n\n\nPHON\n“ekimde”\n\n\nThe query form subsumes the structure above, hence it satisﬁes the restrictions.\n2. ekimde (in my appendix/suﬃx): The second interpretation is also a lexical common noun,\nfor which there are two senses in the static lexicon: appendix and suﬃx. Feature structures\nfor both of the senses are similar, so we will consider only the ﬁrst one, appendix, which\nis used in the following sentence:\n(60) a. O\n¸sekil\nbenim ekimde\nolmalıydı.\nthat figure my\nappendix+P1SG+LOC be+NECS+PAST+3SG\n‘That ﬁgure should have been in my appendix.’\nThe full feature structure for the second interpretation, in my appendix, is the following:\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n84\nlexical common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\n\nSTEM\n“ek”\nAGR\n3sg\nPOSS\n1sg\nCASE\nloc\n\n\nSYN\nh\n. . .\ni\nSEM\n\nTEMPORAL\n−\n. . .\n\n\nPHON\n“ekimde”\n\n\nDue to the −value of SEM | TEMPORAL and 1sg value of MORPH | POSS features,\nthe subsumption of the feature structure above with the query form will fail, and it will\nbe eliminated. Note that both of the restriction features are appropriate for the feature\nstructures above.\n4.2\nProducing Feature Structures\nWe will describe the processing in the lexicon as consisting of three main steps:\n1. morphological analysis,\n2. retrieval of syntactic and semantic information and uniﬁcation with morphosyntactic\ninformation,\n3. application of restrictions.\nThe ﬁrst step is external to the system, so we will consider only its input/output interface.\nThe second step consists of transformation of morphological parses to feature structure syn-\ntax, category mapping, retrieval from static lexicon, and computing features according to the\nmorphological parses. The ﬁnal step is relatively simple; it just tests the sumbsumtion of input\nquery form with each of the produced structures.\nIn the next sections, we will examine each step and provide details with examples.\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n85\n4.2.1\nMorphological Analysis\nMorphological processor provides possible interpretations of a surface form. Due to the rich set\nof inﬂectional and derivational suﬃxes in Turkish, it is highly probable that the surface form\nwill have more than one interpretation. Consider the possible interpretations of the surface\nform kazma, for which the morphological processor output is given in Figure 4.3, as used in the\nfollowing examples:\n(61) a. D¨un\nburada bir kazma\ng¨ord¨un\nm¨u?\nyesterday here\na\npickaxe see+PAST+2SG QUES\n‘Did you see a pickaxe here yesterday?’\nb. Orayı sakın kazma!\nthere never dig+NEG+2SG\n‘Do not dig there!’\nc. Kazma\ni¸sini\nsanırım\nbug¨un\ndig+INF job+P3SG+ACC guess+ARST+1SG today\nbitiririz.\nfinish+ARST+1PL\n‘I guess we will ﬁnish digging today.’\n1. [[CAT=NOUN][ROOT=kazma][AGR=3SG][POSS=NONE][CASE=NOM]]\n2. [[CAT=VERB][ROOT=kaz][SENSE=NEG][TAM1=IMP][AGR=2SG]]\n3. [[CAT=VERB][ROOT=kaz][SENSE=POS]\n[CONV=NOUN=MA][TYPE=INFINITIVE][AGR=3SG][POSS=NONE][CASE=NOM]]\nFigure 4.3: Interpretations of the surface form kazma.\nThe ﬁrst interpretation contains the noun reading, pickaxe. The second and third interpreta-\ntions consider the verb kaz- (dig). In the second interpretation, the suﬃx ma is an inﬂectional\nsuﬃx and negates the predicate, as opposed to the other one, which is a derivational suﬃx and\nused to derive the inﬁnitive kazma (digging).\nAs seen in the example above, the rich set of inﬂectional and derivational suﬃxes causes many\ninterpretations, which increase in number when the multiple senses are incorporated.\nFor\nexample, the predicative verb ye has at least four senses, which we mentioned in Section 3.7.1.\nThe morphological processor output must be transformed to feature structure syntax, moreover,\ndue to the comprehensive categorization introduced in Chapter 3, category mapping will take\nplace. The following section describes this transformation and retrieving information in the\nstatic lexicon.\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n86\n4.2.2\nRetrieving Information in the Static Lexicon\nThe static lexicon follows the interpretations produced by the morphological processor. In-\nterpretations include category information, the root words, and a number of inﬂectional and\nderivational suﬃxes, such as case and possessive markers. The retrieval step mainly consists of\nthe following phases:\n• transformation of interpretations into feature structure syntax, and correct mapping from\nthe morphological processor category to the static lexicon category,\n• accessing the feature structures of the root words involved in the morphological parses,\nand computing features accordingly.\nDuring the processing, the system accesses two tables and two databases. The tables are used\nto map category information, and the databases are used to access feature structures of the root\nwords containing syntactic and semantic information (i.e., lexical database), and the template\nstructures.\nThe retrieval process starts with transformation of parses into feature structure syntax, since the\nsyntactic and semantic information is stored in the form of feature structures in the static lexi-\ncon. As seen in the interpretations of kazma in the previous section, derivations exist in morpho-\nlogical parses and may go to arbitrary depth, such as C¸ekoslovakyalıla¸stıramadıklarımızdanmı¸ssınız.\nAs another example for the interpretations containing derivations, consider the one in Fig-\nure 4.4. It starts with the noun akıl (intelligence), which is used to derive the adjective akıllı\n(intelligent). The derivations end with the manner adverb akıllıca (intelligently). The deriva-\ntions in the processor output are highlighted with the CONV item in the string below, which\ngives the category and derivational suﬃx. Thus, in the following example, there are two deriva-\ntions and three categories traversed, that is there are three levels: the ﬁrst is the lexical level\nand the other two are the derivational levels. Each level is transformed into a feature structure\ncontaining category and morphosyntactic information. So, the interpretation above would be\ntransformed into a list of levels with three elements.\n[[CAT=NOUN][ROOT=akIl][CONV=ADJ=LI][CONV=ADVERB=CA][TYPE=MANNER]]\nFigure 4.4: The derivation path to the manner adverb akıllıca.\nWhile transforming the interpretations, the system maps the category information in the mor-\nphological processor output to correct lexicon category for all levels, which is due to the ﬁner-\ngrained categorization of the lexicon. For this purpose, two tables are maintained for root words\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n87\nand derivations, respectively. For the ﬁrst one, processor category and root word uniquely de-\ntermine the lexicon category. For each root word represented in the feature structure database,\nan entry in this table must be present. A portion of such a table for nouns is depicted in Fig-\nure 4.5. For the second table, processor category and derivational suﬃx uniquely determine\nthe lexicon category. This mapping is given in Table 4.1.\nProcessor category\nRoot word\nLexicon category\n. . .\n. . .\n. . .\nnoun\nkazıntı\ncommon noun\nnoun\nkazma\ncommon noun\nnoun\nkazmanoˇglu\nproper noun\nnoun\nket¸cap\ncommon noun\nnoun\n. . .\n. . .\nnoun\nkurtulu¸s\nproper noun\n. . .\n. . .\n. . .\nFigure 4.5: A portion of the table used for category mapping for root words.\nThis step is applied to all of the morphological parses, and at the end of this step, for each\nparse there is a list of levels, each of which contains the correct lexicon category and a set of\nfeatures representing morphosyntactic information of interpretations.\nThe next phase in the processing is the retrieval of the syntactic and semantic information and\nproducing feature structures. The syntactic and semantic information about the root words is\nstored in the feature structure database, which is indexed with the category and the root word\ninformation. For the root words in the lexical levels of each parse, the feature structure database\nis accessed and matching entries are retrieved. However, the entries contain only syntactic and\nsemantic information for the non-derived forms, thus morphosyntactic information needs to be\nuniﬁed and by following the derivation information of parses new feature structures should be\nconstructured. Many examples of this phenomenon are presented in the Chapter 3.\nSince the morphological parses are previously transformed into feature structure syntax, uniﬁ-\ncation of morphosyntactic information is simple. Having uniﬁed all the information, the pro-\ncessing for the lexical level is completed. If the morphological parses do not contain a derivation\nto another category, the process above is suﬃcient to produce the result. However, as we have\nalready mentioned, the cases in which derivations exist are not rare.\nFor each derivation in the parses, a new feature structure is constructed. For this purpose, using\nthe category information in the derivational levels, the template feature structure database is\naccessed and corresponding template feature structures are retrieved. These structures do not\ncontain feature values, but they will be computed by the system.\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n88\nMorphological Processor Output\nLexicon Category\nCategory\nSuﬃx\nMAJ\nMIN\nSUB\nSSUB\nSSSUB\nnoun\ncı, lık, cık, og,\nnominal\nnoun\ncommon\nyıcı, mazlık,\nyamazlık, maca,\nyası, none\nmak\nsentential\nact\ninﬁnitive\nmak\nma\nma\nyı¸s\nyı¸s\ndık\nfact\nparticiple\ndık\nyacak\nyacak\nrpronoun\nnone\nnoinal\npronoun\nquantitative\nadj\nlık, lı, ki, sız, sı,\nmodiﬁer\nadjective\nqualitative\nik, yıcı, yan, yacak,\ndık, yası\nadverb\nyınca, yıp\nadverbial\ntemporal\npoint-of-time\nyalı, ken\ntime-period\nfuzzy\ncasına, maksızın,\nmanner\nqualitative\nmadan, yamadan,\nyerek, ca\ndık¸ca\nrepetition\nverb\nlan, la¸s\nverb\npredicative\nnone\nverb\nattributive\nTable 4.1: The table used for category mapping for derived words.\nStarting from the leftmost derivational level, the derivation path is followed: for each derivation\na new feature structure is constructed; feature values are computed. The result is a nested\nfeature structure, in which the previous structures are stored in MORPH | STEM feature as\nshown in Figure 4.6.\nHaving retrieved the template feature structure, the feature values are to be computed by the\nsystem. Morphosyntactic information is already produced by the morphological processor, and\nuniﬁed with the information in the template structures. A feature structure belonging to any\ncategory should has the following minimum information: category, phonology, stem, concept,\nand form. Among them the category information and the form (i.e., it is derived) are already\nknown. The feature MORPH | STEM holds the feature structures of the previous words, as\ndescribed above. The phonology information is valid only in the last feature structure in the\nderivation, whose value is the surface form given as the input to the morphological processor.1\nThe concept feature is computed by means of a function according to the target derivation\ncategory and suﬃx.\n1 In other structures, this value is undeﬁned, although computation is possible by means of\nmorphological generation.\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n89\nderived . . .\n\n\nCAT\n. . .\nMORPH\n\n\nSTEM\nderived . . .\n\n\nCAT\n. . .\nMORPH\n\n\nSTEM\nh\n. . .\ni\nFORM\nderived\nCASE\n. . . .\n. . .\n\n\nSYN\n. . .\nSEM\n. . .\n\n\nFORM\nderived\nCASE\n. . .\n. . .\n\n\nSYN\n. . .\nSEM\n. . .\nPHON\n. . .\n\n\nFigure 4.6: Nested feature structures.\nThere are other features to be computed other than the common ones, among which subcate-\ngorization information and thematic roles are the most important ones. These are co-indexed\nwith the those of the previous derivational level. Furthermore, a number of features speciﬁc\nto some categories exist, e.g., semantic properties of common nouns or the constraints on the\nmodiﬁed of qualitative adjectives. About the second one, for example, the following prediction\ncan be made: qualitative adjectives modify the common nouns, and do not constrain the agree-\nment and countability features. However, predicting the semantic properties is diﬃcult, and\nfor this reason, the default values are used, which may not always give the correct description.\nIn the next section we will clarify the procedure above by giving examples.\nExamples\nIn summary, the process of producing feature structures follows the following steps:\n1: For each parse in the morphological processor output do the following:\n1.1: Find the lexicon category of the initial root word (see the table in Figure 4.5),\n1.2: Find the lexicon entries of all senses of the root word by matching the root word\ninformation,\n1.3: Unify morphosyntactic information with the information in the lexicon entry/entries,\n1.4: While there is derivation in the parse do the following:\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n90\n1.4.1: Find the lexicon category and retrieve the corresponding template feature struc-\nture (see Table 4.1),\n1.4.2: Compute feature values and unify morphosyntactic information,\n1.5: Output the feature structure(s)\nWe will describe the process with the input surface form kazma, which has three interpretations,\none of which includes a derivation (see example (61) and Figure 4.3 for morphological processor\noutput):\n1. Kazma (common noun): This interpretation is due to the common noun kazma (pickaxe),\nand does not contain a derivation, so the result can be easily produced by combining\nmorphosyntactic, syntactic, and semantic information.\nAs we already described, the process starts with determining the lexicon category. The\nmorphological processor categorizes kazma just as a noun, however, it is represented as\na common noun in the static lexicon. Then, the corresponding feature structure in the\nlexicon is searched by matching the ROOT information of morphological processor with\nMORPH | STEM feature of lexicon entries.\nThe matching feature structure is given\nbelow. Note that there is only one sense of kazma (pickaxe) in our lexicon.\nlexical common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\nSTEM\n“kazma”\nFORM\nlexical\n\n\nSYN\nh\nSUBCAT\nnone\ni\nSEM\n\nCONCEPT\n#kazma-(pickaxe)\nCOUNTABLE\n+\n\n\n\n\nThen, information about inﬂectional suﬃxes are uniﬁed with the lexicon entry, which\nproduces the result:\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n91\nlexical common\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nnoun\nSUB\ncommon\n\n\nMORPH\n\n\nSTEM\n“kazma”\nFORM\nlexical\nCASE\nnom\nAGR\n3pl\nPOSS\n1sg\n\n\nSYN\nh\nSUBCAT\nnone\ni\nSEM\n\nCONCEPT\n#kazma-(pickaxe)\nCOUNTABLE\n+\n\n\nPHON\n“kazma”\n\n\nNote that the phonology information is the same as surface form given as an input to the\nsystem.\n2. Kazma (verb): This interpretation comes from the verbal root kaz- (dig). The suﬃx ma\nis an inﬂectional suﬃx, which negates the meaning (see Figure 4.3 for the parse). Since\nno derivation step is involved, the process is similar to that of the common noun reading.\nThe lexicon entry is given below with the morphosyntactic information uniﬁed:\nlexical predicative verb\n\n\nCAT\n\nMAJ\nverb\nMIN\npredicative\n\n\nMORPH\n\n\nSTEM\n“kaz”\nFORM\nlexical\nSENSE\nneg\nTAM1\nimp\nAGR\n2sg\n\n\nSYN\nh\nSUBCAT\n. . .\ni\nSEM\n\nCONCEPT\n#kaz-(to dig)\nROLES\n. . .\n\n\nPHON\n“kazma”\n\n\n3. Kazma (inﬁnitive): This interpretation involves a derivation from the verb kaz- (dig) to\nthe inﬁnitive kazma (digging). The steps up to the derivation is similar to that of the\nprevious two examples. The derivation step starts with the determination of the target\ncategory using the Table 4.1, and retrieval of the template feature structure. The table\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n92\nlookup results in the inﬁnitive category, and corresponding template feature structure is\nretrieved.\nThe next step involves the computation of features, which includes subcategorization\ninformation, thematic roles, and concept. These features, except the concept, are co-\nindexed with the corresponding entries in the lexicon entry of kaz-. The concept feature\nis computed via a function. The rest of the features can be easily found, since category\nis already known and morphosyntactic information is received from the morphological\nprocessor. The phonology feature takes the input surface form, kazma.\nThe feature structure for the inﬁnitive kazma is given below, with some of the features\nco-indexed with those of the lexical entry of kaz-:\nma\n\n\nCAT\n\n\nMAJ\nnominal\nMIN\nderived\nSUB\nact\nSSUB\ninﬁnitive\nSSSUB\nma\n\n\nMORPH\n\n\nSTEM\n1\nDERV-SUFFIX\n“ma”\nFORM\nderived\nCASE\nnom\nAGR\n3sg\nPOSS\nnone\n\n\nSYN\nh\nSUBCAT\n2\ni\nSEM\n\nCONCEPT\nfma(#kaz-(dig))\nROLES\n3\n\n\nPHON\n“kazma”\n\n\n1\nlexical predicative verb\n\n\nCAT\n\nMAJ\nverb\nMIN\npredicative\n\n\nMORPH\n\n\nSTEM\n“kaz”\nFORM\nlexical\nSENSE\npos\n\n\nSYN\nh\nSUBCAT\n2 . . .\ni\nSEM\n\nCONCEPT\n#kaz-(dig)\nROLES\n3 . . .\n\n\nPHON\nnone\n\n\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n93\n4.2.3\nApplication of Restrictions\nThe ﬁnal step in the process is the elimination of the feature structures that do not satisfy the\nrestrictions.\nThe input to this phase is a list of feature structures and the user’s query form. Each structure\nis tested against the query form for subsumtion relation, that is all of the features in the query\nform must be present in the output structures and the feature values must be the same. The\nones that fail to satisfy this relation are eliminated.\nThe process is relatively simple, thus we will not decribe it any further (see the example in\nSection 4.1).\n4.3\nProblems and Limitations\nA limitation with the representation of the entries in the static lexicon is related with the\nSEM | CONCEPT feature, which gives a brief English description of the object, event, etc.\nthat the root word represents.\nThe description is mostly human-oriented and not directly\nusable by NLP subsystems, such as transfer units (from Turkish to English and vice versa) in\nmachine translation systems. For example, this feature may take the value throw a physical\nobject for the verb at-. Using an ontological component in the lexicon eliminates this problem,\nin which concepts would be described via a semantic network.\nAnother problem that the ontological component would eliminate is the following: the subcate-\ngorization information for verbs, common nouns, etc. may places some semantic constraints on\nthe complements, such as the agent of the verb ye- (eat something) must be animate (SEM | AN-\nIMATE is +). This constraint would be tested with the semantic feature in the feature structure\nof the subject during syntactic analysis. This test, however, may fail due to the absence of the\nfeature SEM | ANIMATE, but this structure may describe a human, such as ¨oˇgrenci student\nhaving SEM | HUMAN:+, so satisfying animateness constraint. This syntactic mismatch of the\nfeatures would be eliminated easily, since a human object would inherit animateness property\n(see Yılmaz [16] for such a component in a verb lexicon).\nOne of the problems with producing feature structures, especially with the derivations involved,\nis predicting semantic properties of common nouns and qualitative adjectives. In the other\ncategories either semantic properties are not introduced or they do not receive derivation.\nSince the new word generated as a result of the derivation process does not have a lexicon entry,\nthe process should predict some feature values. However, the semantics of the object or the\nquality that the derivation process produces is not clear. For example, consider the derivation\nthat takes a common noun and the suﬃx cı, and produces a common noun. Both ak¸samcı and\nCHAPTER 4. OPERATIONAL ASPECTS OF THE LEXICON\n94\n¨oˇglenci are produced in this way, however, the semantic properties of the resultant entities are\nnot predictable. This is the case in yazıcı (yaz- (write)+cı), which has two senses: printer and\nthe person who writes. The two senses have diﬀerent properties, e.g., animateness.\nA similar situation occurs for the qualitative adjectives. For instance, as we stated previously,\nthe gradability of derived forms are not quite predictable: ¸cok akılsız vs. *¸cok kolsuz.\nChapter 5\nImplementation\nThe processing in the lexicon consists of four main steps each carried out by a separate module:\n1. morphological analysis,\n2. transformation of morphological processor output to static lexicon the syntax (i.e., feature\nstructure syntax), and category mapping,\n3. retrieval from feature structure databases and producing feature structures,\n4. application of restrictions.\nExcept the morphological processor component,1 which is previously implemented, all the com-\nponents are implemented in SICStus Prolog release 3 #5 [14]. Since we described the procedural\naspects of the lexicon in Chapter 4, we will not go into the details of this process, however, there\nis one point to be made here: in the implementation, the query form can contain features only\nfrom CAT and MORPH, since the lexicon interface does not gain much by adding the capabil-\nity of restricting SYN and SEM features, as well. On the other hand, NLP subsystems using\nthis interface can impose any restriction externally, because access to all features is allowed.\nSo, rather than applying restrictions to eliminate unwanted feature structures as the ﬁnal step,\nthe system applies restrictions to parses right after the transformation phase (i.e., when the\nCAT and MORPH features are computed). Thus, unnecessary retrievals and computations are\navoided.\nWe provided a procedural interface for the lexicon, rather than implementing a graphical one,\nsince the interface will be open to NLP subsystems in practical applications.\n1 The morphological processor that our lexicon employs is implemented by Oﬂazer (see\nOﬂazer [11] for the two level description of Turkish morphology) using a ﬁnite-state lexicon\ncompiler by Karttunen [7].\n95\nCHAPTER 5. IMPLEMENTATION\n96\nIn this chapter, we will ﬁrst describe an important component of the system, the feature\nstructure database (i.e., the root word lexicon). Then, we will give outputs from sample runs\nof the system.\n5.1\nFeature Structure Database\nThe feature structure database consists of a list of feature structures indexed with category and\nroot word. Each word and sense is a separate entry in the database, so given a category and\nroot word more than one entry may match, that is the key is not unique. Each entry is a unit\nProlog clause with seven arguments, the ﬁrst ﬁve ones giving the category, and the other two\ngiving the root word and the corresponding feature structure (see Figure 5.1). In this way, the\ndatabase can be stored in the main memory and allows fast access.\nfsdb(verb, existential, none, none, none, var,\n[cat:[maj:verb, ...], syn:[...], ...]).\nFigure 5.1: The entry for the existential verb var in the feature structure database.\nFeature structures are represented as a list of <feature name:feature value> pairs (see Gazdar\nand Mellish [4]).\nFor example, the following feature structure with abstract representation\nwould be represented in Prolog as in Figure 5.2:\n\n\nMORPH\n\n\nSTEM\n\u0014\nCAT\nh\nMAJ\nnominal\ni\u0015\nCASE\ndat\n\n\nSEM\n\nANIMATE\n−\nCOUNTABLE\n−\n\n\n\n\n[morph:[stem:[cat:[maj:nominal | ] | ], case:dat | ],\nsem:[animate:-, countable:- | ] | ]\nFigure 5.2: Prolog representation of a feature structure.\nCurrently, our feature structure database contains about 50 entries, which consists of samples\nfrom the closed-class words, such as post-positions, conjunctions, and from other categories\nshowing some special property. More entries will be added to the system later. In order to\nmaintain the database, the system provides a number of predicates to add, delete, and browse\nentries.\nCHAPTER 5. IMPLEMENTATION\n97\n5.2\nSample Runs\nIn this section we will present three sample runs that will demonstrate features of our lexicon,\nand will clarify the algorithms presented in Chapter 4.\nThe input to the system is a query form in the form of a feature structure. At least the PHON\nfeature, which holds the surface form, must be present in the query form. Other features are\noptional, and if present they act as restrictions on the ﬁnal output feature structures. The user\ncan test presence of a feature or a speciﬁc value for that feature. If the feature restricted is in the\noutput feature structure, the restriction value, which may be unspeciﬁed to test the presence,\nis uniﬁed with the one in the output structure. If the uniﬁcation fails, the output structure is\neliminated. If such a feature is not in the output structure, the restriction feature would not be\nappropriate for this structure, so it is again eliminated; for example MORPH | TAM1 feature\nis not appropriate for a conjunction’s feature structure.\nAs previously mentioned, the process is divided into four phases in the implementation. All\nfour phases inform the user about the state of the processing. The ﬁnal output is a list of\nfeature structures which satisfy all the constraints.\n5.2.1\nExample 1\nThe ﬁrst example submits only the surface form atım and does not constrain any other features.\nAccording to the morphological processor, atım has three parses, as illustrated by the following\nexamples:\n(62) a. Benim bir atım\nvar.\nmy\na\nhorse+P1SG existent\n‘I have a horse.’\nb. K¨uheylan ben bir atım\ndedi.\nK¨uheylan I\na\nhorse+PRES+1SG say+PAST+3SG\n‘K¨uheylan said that it was a horse.’\nc. Tilki bir atım mesafedeydi.\nfox\none shot distance+PAST+3SG\n‘The fox was in one shot distance.’\nThe category of the surface form atım is common noun and attributive verb, respectively, in\nthe ﬁrst two parses, and they are due to the common noun at (horse). The third parse comes\nfrom the common noun atım (shot), and does not derive to another category. Since query form\nCHAPTER 5. IMPLEMENTATION\n98\ndoes not place any constraint, the system will generate output for all of the parses, as far as\nthe feature structure database contains corresponding entries.\nThe user input and the lexicon’s output follow:\nInput query form:2\n[phon:atIm]\nOutput:\nParsing surface form started...\nReading Turkish binary file...\n0%>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>100%\nRead Turkish binary file.\nParsing: atIm\nNumber of parses: 3\n1: [[CAT=NOUN][ROOT=at][AGR=3SG][POSS=1SG][CASE=NOM]]\n2: [[CAT=NOUN][ROOT=at][AGR=3SG][POSS=NONE][CASE=NOM]\n[CONV=VERB=NONE][TAM2=PRES][AGR=1SG]]\n3: [[CAT=NOUN][ROOT=atIm][AGR=3SG][POSS=NONE][CASE=NOM]]\nParsing surface form ended...\nTransformation phase started...\nCategory mapping from:\nnoun, none and at\nto:\nnominal, noun, common, none, none\nCategory mapping from:\nnoun, none and at\nto:\nnominal, noun, common, none, none\nCategory mapping from:\n2 In our system, Turkish words consist of all lowercase letters, and ı, ¸c, ˇg, ¸s, ¨o, and ¨u are\nrepresented as the capital of the nearest letter.\nCHAPTER 5. IMPLEMENTATION\n99\nverb, none and none\nto:\nverb, attributive, none, none, none\nException: Entry not found in LCMT: Skipping parse...\nnoun\nnone\natIm\nTransformation phase ended...\nTransformed parses:\n-------------------\nParse information:\nNumber of parses: 2\n1: 1 level(s)\n2: 2 level(s)\nApplication of restrictions phase started...\nApplication of restrictions phase ended...\nSatisfying parses:\n------------------\nParse information:\nNumber of parses: 2\n1: 1 level(s)\n2: 2 level(s)\nRetrieval phase started...\nAccess to FSDB with:\nnominal, noun, common, none, none and at\nfor:\n1 entry/entries\nAccess to FSDB with:\nnominal, noun, common, none, none and at\nfor:\n1 entry/entries\nAccess to TFSDB with:\nCHAPTER 5. IMPLEMENTATION\n100\nverb, attributive, none, none, none\nRetrieval phase ended...\nFinal result:\n-------------\nNumber of feature structures: 2\nFeature sturucture(s):\n[sem:\n[countable: +\nanimate: +\nconcept: at-(horse)\nmaterial: -\nunit: -\ncontainer: -\nspatial: -\ntemporal: -]\ncat:\n[maj: nominal\nmin: noun\nsub: common\nssub: none\nsssub: none]\nmorph:\n[stem: at\nform: lexical\ncase: nom\nposs: 1sg\nagr: 3sg]\nsyn:\n[subcat: none]\nphon: atIm]\n,\n[cat:\n[maj: verb\nmin: attributive\nsub: none\nssub: none\nsssub: none]\nmorph:\n[stem:\nCHAPTER 5. IMPLEMENTATION\n101\n[sem:\n[countable: +\nanimate: +\nconcept: at-(horse)\nmaterial: -\nunit: -\ncontainer: -\nspatial: -\ntemporal: -]\ncat:\n[maj: nominal\nmin: noun\nsub: common\nssub: none\nsssub: none]\nmorph:\n[stem: at\nform: lexical\ncase: nom\nposs: none\nagr: 3sg]\nsyn:\n[subcat: none]\nphon: none]\nform: derived\nderv_suffix: none\ntam2: pres\ncopula: none\nagr: 1sg]\nsyn:\n[subcat: none]\nsem:\n[concept: none(at-(horse))\nroles: none]\nphon: atIm]\nThe output is a trace of the four phases. The ﬁrst part is the morphological parsing, and\ndisplays parses. The second part is the transformation of parses into static lexicon syntax\n(i.e., feature structure syntax), and category mapping. The ﬁrst item in the output of this\nphase shows the mapping of the morphological processor category noun to the lexicon category\ncommon noun for the root word at. The next two output items illustrate category mapping of\nCHAPTER 5. IMPLEMENTATION\n102\nthe second parse. The last item shows that the category mapping table for root words does not\nhave an entry for atım, that is the system does not have information about atım, so this parse\nis omitted, and will not be processed in the following phases.\nAfter the transformation phase, two parses remain, and since no restriction is imposed by the\nuser, these parses will pass to the next phase. The retrieval part acknowledges the user that\nit accessed the feature structure database entry of the common noun at two times, and the\ntemplate feature structure for attributive verbs, which is due to the derivation in the second\nparse.\nEach parse produces only one feature structure, because the common noun at has only one en-\ntry/sense in the database. The ﬁnal output is these feature structures. The processing including\ninterfacing with the morphological processor, producing feature structures, and pretty-printing\ntakes approximately 30 msec. of running time for compiled Prolog code, so it is rather fast. As\nwe mentioned in Chapter 2, the number of lexical items in a lexicon of a system with acceptable\ncoverage (e.g., The Core Language Engine) will not exceed a few thousand, so whole database\ncan be stored in the main memory. Thus, as the size of our lexical database gets larger, the\nprocessing time will not exceed acceptable limits.\n5.2.2\nExample 2\nThis example run submits the surface form memnunum to the system and constraints the\noutput to be of category verb. Given this surface form, morphological processor gives three\nparses as used in the following examples:3\n(63) a. Senden\nmemnunum.\nyou+GEN happy+PRES+1SG\n‘I am happy with you.’\nb. Memnunum\nbenim!\nhappy one+P1SG my\nc. Ben Memnun’um.\nI\nMemnun+PRES+1SG\n‘I am Memnun.’\nThe ﬁrst two parses are due to the qualitative adjective memnun (satisﬁed/happy), and contain\nderivations to attributive verb and common noun, respectively. The last one is due to the\n3 The usage in the second sentence is like in g¨uzelim benim, that is the qualitative adjective\ng¨uzel (beautiful) is subject to a derivation to common noun, and becomes the one that is beautiful.\nThis usage of Memnun is syntacticly correct, though semantically it does not make sense.\nCHAPTER 5. IMPLEMENTATION\n103\nproper noun Memnun and contains a derivation to attributive verb. The only restriction in\nthe query form is that the output feature structures must be of type verb, which will cause the\nsecond parse to be eliminated in the third phase.\nThe input and corresponding output follow:\nInput query form:\n[phon:memnunum, cat:[maj:verb]]\nOutput:\nParsing surface form started...\nParsing: memnunum\nNumber of parses: 3\n1: [[CAT=ADJ][ROOT=memnun][CONV=VERB=NONE][TAM2=PRES][AGR=1SG]]\n2: [[CAT=ADJ][ROOT=memnun][CONV=NOUN=NONE][AGR=3SG][POSS=1SG][CASE=NOM]]\n3: [[CAT=NOUN][ROOT=memnun][TYPE=RPROPER][AGR=3SG][POSS=NONE][CASE=NOM]\n[CONV=VERB=NONE][TAM2=PRES][AGR=1SG]]\nParsing surface form ended...\nTransformation phase started...\nCategory mapping from:\nadj, none and memnun\nto:\nadjectival, adjective, qualitative, none, none\nCategory mapping from:\nverb, none and none\nto:\nverb, attributive, none, none, none\nCategory mapping from:\nadj, none and memnun\nto:\nadjectival, adjective, qualitative, none, none\nCategory mapping from:\nnoun, none and none\nCHAPTER 5. IMPLEMENTATION\n104\nto:\nnominal, noun, common, none, none\nException: Entry not found in LCMT: Skipping parse...\nnoun\nrproper\nmemnun\nTransformation phase ended...\nTransformed parses:\n-------------------\nParse information:\nNumber of parses: 2\n1: 2 level(s)\n2: 2 level(s)\nApplication of restrictions phase started...\nParse eliminated: Printing only the last level...\n[cat:\n[maj: nominal\nmin: noun\nsub: common\nssub: none\nsssub: none]\nmorph:\n[derv_suffix: none\nagr: 3sg\nposs: 1sg\ncase: nom]\nphon: memnunum]\nApplication of restrictions phase ended...\nSatisfying parses:\n------------------\nParse information:\nNumber of parses: 1\n1: 2 level(s)\nCHAPTER 5. IMPLEMENTATION\n105\nRetrieval phase started...\nAccess to FSDB with:\nadjectival, adjective, qualitative, none, none and memnun\nfor:\n1 entry/entries\nAccess to TFSDB with:\nverb, attributive, none, none, none\nRetrieval phase ended...\nFinal result:\n-------------\nNumber of feature structures: 1\nFeature sturucture(s):\n[cat:\n[maj: verb\nmin: attributive\nsub: none\nssub: none\nsssub: none]\nmorph:\n[stem:\n[syn:\n[subcat: ...\nmodifies: ...]\ncat:\n[maj: adjectival\nmin: adjective\nsub: qualitative\nssub: none\nsssub: none]\nmorph:\n[stem: memnun\nform: lexical]\nsem:\n[concept: memnun-(satisfied)\ngradable: -\nquestional: -]\nphon: none]\nCHAPTER 5. IMPLEMENTATION\n106\nform: derived\nderv_suffix: none\ntam2: pres\ncopula: none\nagr: 1sg]\nsyn:\n[subcat: ...]\nsem:\n[concept: none(memnun-(satisfied))\nroles: none]\nphon: memnunum]\nIn the transformation of parses, no entry regarding the proper noun Memnun is found in the\ncategory mapping table, so this parse is eliminated, leaving two parses to the third phase, which\ndiscards the second parse, since it fails to satisfy the restriction, that is the value of CAT | MAJ\nmust be verb. Finally, there is only one parse left, which is the ﬁrst one, as an input to the\nretrieval phase. As seen in the output, there is only one entry for the qualitative adjective\nmemnun, thus only one feature structure is generated. The processing takes approximately 50\nmsec. of running time. The values of SUBCAT and MODIFIES features are omitted to save\nspace (see the full feature structure of memnun on page 40).\n5.2.3\nExample 3\nOur last example will demonstrate multiple senses in the database. The surface form is ekim,\nand the restriction is on MORPH | POSS feature, whose value must be 1sg. The interpretations\nare similar to those in the previous examples, so we will not give detailed descriptions.\nAccording to the morphological processor, there are three parses, which are due to the common\nnoun ek (appendix/suﬃx) and Ekim (October). Both root words are in the database, but the\nlast two parses are eliminated in the third phase. As a result, there is only one parse as an\ninput to the last step. There are two entries regarding the common noun ek, which cause the\nsystem to generate two feature structures for the single parse. The processing takes about 40\nmsec.\nThe input and corresponding output follow:\nInput query form:\n[phon:ekim, morph:[poss:’1sg’]].\nCHAPTER 5. IMPLEMENTATION\n107\nOutput:\nParsing surface form started...\nParsing: ekim\nNumber of parses: 3\n1: [[CAT=NOUN][ROOT=eK][AGR=3SG][POSS=1SG][CASE=NOM]]\n2: [[CAT=NOUN][ROOT=eK][AGR=3SG][POSS=NONE][CASE=NOM]\n[CONV=VERB=NONE][TAM2=PRES][AGR=1SG]]\n3: [[CAT=NOUN][ROOT=ekim][TYPE=TEMP1][AGR=3SG][POSS=NONE][CASE=NOM]]\nParsing surface form ended...\nTransformation phase started...\nCategory mapping from:\nnoun, none and ek\nto:\nnominal, noun, common, none, none\nCategory mapping from:\nnoun, none and ek\nto:\nnominal, noun, common, none, none\nCategory mapping from:\nverb, none and none\nto:\nverb, attributive, none, none, none\nCategory mapping from:\nnoun, temp1 and ekim\nto:\nnominal, noun, common, none, none\nTransformation phase ended...\nTransformed parses:\n-------------------\nParse information:\nNumber of parses: 3\n1: 1 level(s)\nCHAPTER 5. IMPLEMENTATION\n108\n2: 2 level(s)\n3: 1 level(s)\nApplication of restrictions phase started...\nParse eliminated: Printing only the last level...\n[cat:\n[maj: verb\nmin: attributive\nsub: none\nssub: none\nsssub: none]\nmorph:\n[suffix: none\ntam2: pres\nagr: 1sg]\nphon: ekim]\nParse eliminated: Printing only the last level...\n[cat:\n[maj: nominal\nmin: noun\nsub: common\nssub: none\nsssub: none]\nmorph:\n[stem: ekim\nagr: 3sg\nposs: none\ncase: nom]\nphon: ekim]\nApplication of restrictions phase ended...\nSatisfying parses:\n------------------\nParse information:\nNumber of parses: 1\n1: 1 level(s)\nCHAPTER 5. IMPLEMENTATION\n109\nRetrieval phase started...\nAccess to FSDB with:\nnominal, noun, common, none, none and ek\nfor:\n2 entry/entries\nRetrieval phase ended...\nFinal result:\n-------------\nNumber of feature structures: 2\nFeature sturucture(s):\n[sem:\n[countable: +\nconcept: ek-(suffix)\nmaterial: -\nunit: -\ncontainer: -\nspatial: -\ntemporal: -\nanimate: -]\ncat:\n[maj: nominal\nmin: noun\nsub: common\nssub: none\nsssub: none]\nmorph:\n[stem: ek\nform: lexical\ncase: nom\nposs: 1sg\nagr: 3sg]\nsyn:\n[subcat: none]\nphon: ekim]\n,\n[sem:\n[countable: +\nconcept: ek-(appendix)\nCHAPTER 5. IMPLEMENTATION\n110\nmaterial: -\nunit: -\ncontainer: -\nspatial: -\ntemporal: -\nanimate: -]\ncat:\n[maj: nominal\nmin: noun\nsub: common\nssub: none\nsssub: none]\nmorph:\n[stem: ek\nform: lexical\ncase: nom\nposs: 1sg\nagr: 3sg]\nsyn:\n[subcat: none]\nphon: ekim]\nChapter 6\nConclusions and Suggestions\nIn this thesis, we present a lexicon for Turkish. Our work includes determination of the lexical\nspeciﬁcation to be encoded for all lexical types of Turkish, encoding of this speciﬁcation, and\nconstructing a standalone system as an information repository for the NLP systems.\nThe level of lexical speciﬁcation for morphosyntactic and syntactic information is adequate, but,\nas the semantic information is added in an ad hoc manner, it may not satisfy all the requirements\nof NLP systems on semantic information. Including a knowledge-base/ontology into the system,\nin which concepts are described through a semantic network, would be useful. This would\nsolve the problem related with the satisfying the semantic constraints in the subcategorization\ninformation of lexical entries. For example, the constraint posing SEM | ANIMATE:+ will not\nbe uniﬁed with SEM | HUMAN:+, though this is semantically satisﬁable.\nIn order for our lexical database to be computationally useful, more entries would be added\ndepending on the requirements of the NLP systems interfacing with our lexicon. Currently,\nthe database contains about 50 entries consisting of samples from closed and open-class words\nhaving some special property. We are planning to add more entries to cover all the closed-class\nwords and enrich the content for the open-class words of Turkish. A graphical user interface\nwill be provided to help insertion, deletetion, and update operations to lexicon.\n111\nBibliography\n[1] T. Briscoe. Natural Language and Speech, chapter Lexical Issues in Natural Language\nProcessing. Springer-Verlag, 1991.\n[2] D. Carter. The Core Language Engine, chapter Lexical Acquisition. The MIT Press, 1992.\n[3] H. Ediskun. T¨urk Dilbilgisi. Remzi Kitabevi, ˙Istanbul, 4. edition, 1993.\n[4] G. Gazdar and C. Mellish. Natural Language Processing in Prolog, chapter 7, pages 217–\n278. Addison-Wesley Publishing Company, 1989.\n[5] K. Goodman and S. Nirenburg. KBMT-89: A Case Study in Knowledge-Based Machine\nTranslation. San Mateo: Morgan Kaufmann, 1991.\n[6] R.\nGrishman\nand\nN.\nCalzolari.\nLexicons.\nIn\nSurvey\nof\nthe\nState\nof\nthe\nArt in Human Language Technology,\nchapter Language Resources.\nAvailable at\nhttp://www.cse.ogi.edu/CSLU/HLTsurvey/.\n[7] L. Karttunen. Finite-state lexicon compiler. Technical report, XEROX Palo Alto Research\nCenter, April 1993.\n[8] N. Ko¸c. Yeni Dilbilgisi. ˙Inkılap Kitabevi, ˙Istanbul, 1. edition, 1990.\n[9] M. Monachini and N. Calzolari. Synopsis and Comparison of Morphosyntactic Phenomena\nEncoded in Lexicons and Corpora. A Common Proposal and Applicatios to European\nLanguages. Draft version, October 1994.\n[10] S. Nirenburg.\nLexicon Acquisition for NLP: A Consumer Report.\nTechnical report,\nCarnegie Mellon University, Center for Machine Translation, 1989.\n[11] K. Oﬂazer. Two-level Description of Turkish Morphology. Literary and Linguistic Com-\nputing, 9(2), 1994. Oxford University Press.\n[12] S. M. Shieber. An Introduction to Uniﬁcation-Based Approaches to Grammar. Stanford\nUniversity, Center for the Study of Language and Information, 1986. CSLI Lecture Notes.\n112\nBIBLIOGRAPHY\n113\n[13] A. Solak and K. Oﬂazer. Design and Implemetation of of a Spelling Checker for Turkish.\nLiterary and Linguistic Computing, 8(3), 1993. Oxford University Press.\n[14] Swedish Instute of Computer Science, The Intelligent Systems Laboratory. SICStus Prolog\nUser’s Manual Release 3 Patchlevel 5, October 1996.\n[15] R. Underhill. Turkish Grammar. The MIT Press, 4. edition, 1985.\n[16] O. Yılmaz. Design and implementation of a verb lexicon and a verb sense disambiguator\nfor Turkish. Master’s thesis, Bilkent University, Department of Computer Engineering and\nInformation Science, September 1994.\n[17] A. Zaenen and H. Uszkoreit.\nOverview.\nIn Survey of the State of the Art in Hu-\nman Language Technology, chapter Language Analysis and Understanding. Available at\nhttp://www.cse.ogi.edu/CSLU/HLTsurvey/.\nAppendix A\nThe Lexicon Categories\nmaj\nmin\nsub\nssub\nsssub\nnominal\nnoun\ncommon\nproper\npronoun\npersonal\ndemonstrative\nreﬂexive\nindeﬁnite\nquantiﬁcation\nquestion\nsentential\nact\ninﬁnitive\nma\nmak\nyı¸s\nfact\nparticiple\ndık\nyacak\nadjectival\ndeterminer\narticle\ndemonstrative\nquantiﬁer\nadjective\nquantitative\ncardinal\nordinal\nfraction\ndistributive\nqualitative\nTable A.1: The lexicon categories (nominals and adjectivals)\n114\nAPPENDIX A. THE LEXICON CATEGORIES\n115\nmaj\nmin\nsub\nssub\nsssub\nadverbial\ndirection\ntemporal\npoint-of-time\ntime-period\nfuzzy\nday-time\nseason\nmanner\nqualitative\nrepetition\nquantitative\napproximation\ncomparative\nsuperlative\nexcessiveness\nverb\npredicative\nexistential\nattributive\nconjunction\ncoordinating\nbracketing\nsentential\npost-position\nnom-subcat\nacc-subcat\ndat-subcat\nabl-subcat\ngen-subcat\nins-subcat\nTable A.2: The lexicon categories (adverbials, verbs, conjunctions, and post-positions)\n",
  "categories": [
    "cmp-lg",
    "cs.CL"
  ],
  "published": "1997-02-19",
  "updated": "1997-02-19"
}