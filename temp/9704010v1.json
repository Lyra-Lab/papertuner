{
  "id": "http://arxiv.org/abs/cmp-lg/9704010v1",
  "title": "The Theoretical Status of Ontologies in Natural Language Processing",
  "authors": [
    "John A. Bateman"
  ],
  "abstract": "This paper discusses the use of `ontologies' in Natural Language Processing.\nIt classifies various kinds of ontologies that have been employed in NLP and\ndiscusses various benefits and problems with those designs. Particular focus is\nthen placed on experiences gained in the use of the Upper Model, a\nlinguistically-motivated `ontology' originally designed for use with the Penman\ntext generation system. Some proposals for further NLP ontology design criteria\nare then made.",
  "text": "arXiv:cmp-lg/9704010v1  25 Apr 1997\nThe Theoretical Status of Ontologies in Natural Language Processing\nJohn A. Bateman1\nProjekt komet and Penman Project\nGMD/IPSI and USC/ISI\ne-mail: bateman@gmd.de\nMarch 5, 1992\nNote: This paper appears in the Proceedings of the workshop on ‘Text Representation and Domain\nModelling – Ideas from Linguistics and AI’, held at the Technical University Berlin, October 9th - 11th,\n1991. KIT Report 97, edited by Susanne Preuß and Birte Schmitz.\nCmp-lg Paper No: cmp-lg/9704010\n1Most of the background for this paper is drawn from experiences with the development of the Penman Upper\nModel: an ontology for supporting natural language generation. The Upper Model has been under development\nsince 1985, and many have and continue to contribute to it. The ideas I report on here would not have been possible\nwithout that development. Those responsible for the present form of the Upper Model include: William Mann,\nChristian Matthiessen, Robert Kasper, Richard Whitney, Johanna Moore, Eduard Hovy, Yigal Arens, and myself.\n1\n1\nIntroduction\nThe development of natural language process-\ning (henceforth, nlp) systems has reached\nthe stage where concentrated eﬀorts are nec-\nessary in the area of representing more ‘ab-\nstract’, more ‘knowledge’-related bodies of in-\nformation.\nIt has been accepted that with-\nout substantial bodies of background infor-\nmation concerning commonsense, everyday\nknowledge about the world or detailed in-\nformation concerning particular domains of\napplication, it will not be possible to con-\nstruct systems that can support the use of\nnatural language.\nSystems need to repre-\nsent concrete details of the ‘worlds’ that their\ntexts describe: for example, the resolution of\nanaphors, the induction of text coherence by\nrecognizing regularities present in the world\nand not in the text, the recognition of plans\nby knowing what kinds of plans make sense for\nspeakers and hearers in real situations, etc. all\nrequire world modelling to various depths.\nThis need creates two interrelated problem\nareas.\nThe ﬁrst problem is how knowledge\nof the world — be it general, commonsense\nknowledge or specialized knowledge concern-\ning some particular domain — is to be rep-\nresented.\nThe second problem is how such\norganizations of knowledge are to be related\nto linguistic system levels of organization such\nas grammar and lexis. For both problem ar-\neas the concept of ontologies for nlp has\nbeen suggested to be of potential value. Very\ngenerally, an ontology oﬀers a ‘conceptual’\nframework for the representation of informa-\ntion — a framework that is suﬃciently gen-\neral, but also suﬃciently detailed, to provide\na rich supportive scaﬀolding for the construc-\ntion of models of the world.\nThe design of\nsuch ontologies constitutes an area of concern\nthat is coming to be known as ontological en-\ngineering (e.g., [Nirenburg and Raskin, 1987,\nLenat and Guha, 1988, Simmons, 1991].\nAs\nwe shall see below, most systems that deal\ncurrently with nlp already adopt some kind\nof ontology for their more abstract levels of\ninformation. However, theoretical principles\nfor the design and development of ontologies\nmeeting the goals of generality and detail re-\nmain weak.\nThis is due not only to a lack\nof theoretical accounts at these more rariﬁed\nabstract levels of information, but also to the\nco-existence of a range of, sometimes poorly\ndiﬀerentiated, functions such bodies of infor-\nmation are expected to fulﬁll.\nThe following list gives an idea of the range\nof functions adopted in nlp. Ontologies are\noften expected to fulﬁll at least one (and often\nmore) of:\n• organizing ‘world knowledge’,\n• organizing the world itself,\n• organizing ‘meaning’ or ‘semantics’ of\nnatural language expressions,\n• providing an interface between system\nexternal components,\ndomain models,\netc. and nlp linguistic components,\n• ensuring expressability of input expres-\nsions,\n• oﬀering an interlingua for machine trans-\nlation,\n• supporting the construction of ‘concep-\ntual dictionaries’.\nMoreover, an ontology is seen as a very gen-\neral organizational device: i.e., one that pro-\nvides a classiﬁcation system for whatever area\nof application the ontology is applied to. The\norganizational resource oﬀered by an ontology\nhas to be re-usable. But it is an open issue as\nto what extent the kinds of organization listed\nhere overlap. It cannot be taken for granted\nthat they all refer to the same level of ab-\nstract description. It can also not be taken\nfor granted that there is unity concerning the\ntasks that are involved in such descriptions.\nThis can be seen in the following statement\nfrom Hobbs.\n‘Semantics is the attempted speciﬁca-\ntion of the relation between language\nand the world. However, this requires\na theory of the world. There is a spec-\ntrum of choices one can make in this\nregard. At one end of the spectrum —\nlet’s say the right end — one can adopt\nthe “correct” theory of the world, the\none given by quantum mechanics and\nthe other sciences. If one does this, se-\nmantics becomes impossible because it\nis no less than all of science. . . There’s\ntoo much of a mismatch between the\nway we view the world and the way\nthe world really is.\nAt the left end,\none can assume a theory of the world\n2\nthat is isomorphic to the way we talk\nabout it.\n. . . Most activity in seman-\ntics today is slightly to the right of\nthe extreme left end of this spectrum.\n. . . it fails to move far enough away\nfrom language to represent signiﬁcant\nprogress towards the right end of the\nspectrum.’ [Hobbs, 1985, p68]\nIt probably does not make sense, therefore,\nto talk of a generalized classiﬁcation system\nwithout ﬁrst ﬁxing more precisely the nature\nof its intended function. A further problem is\nthat the ﬁrst of the desired functions above,\norganizing world knowledge, is often taken to\nbe deﬁnitional for an ontology.2 However, the\nworld — i.e., psychological, logical, or philo-\nsophical views of the world — has not proved\nto be very constraining as to what knowledge\norganizations it requires. ‘Ontologies’ built on\nthe basis of such constraints are, as we shall\nsee below, underconstrained and there has ac-\ncordingly been no achievement of the large\nscale resources necessary for re-use across nlp\nsystems.\nThe main purpose of this paper is to add\na further round of discussion to that con-\ncerning the design and construction of ontolo-\ngies for nlp. The paper is explicitly explo-\nrative, building on experience in the deﬁnition\nand use of such ontologies for text generation.\nThe paper is intended to stimulate discussion,\nrather than present solutions — although I\ndo conclude with suggestions for certain lines\nof theoretically motivated methodological de-\nvelopment for future ontologies.\nThe basic\npath taken in the paper will be to diﬀerenti-\nate among the distinct functions that ontolo-\ngies may serve in order to be better able to set\nout principles and constraints for the design of\nabstract levels of knowledge organization that\ncan serve as ontologies appropriate for nlp.\nSeen in more detail, the paper is organized as\nfollows.\nFirst, I discuss the role of language as a pos-\nsible motivating force for designing and pop-\nulating ontologies. Second, I introduce sev-\neral of the most extensive ontologies that are\ncurrently to be found in nlp systems, char-\nacterizing their precise function and motiva-\ntion within their respective systems. Third,\nI relate the distinct types of ontology discov-\n2Or the second may be claimed to be the real task\n— however, as Hobbs points out, this actually comes\ncloser to the ﬁrst position.\nered to possible general linguistic theories that\nwould support them. It is my contention that\nmany principles of organization follow directly\nfrom the position of suggested bodies of infor-\nmation in the linguistic system as a whole and\nthat recognizing this allows eﬀorts in the def-\ninition and construction of such bodies of or-\nganization to be directed more appropriately\nthan has hitherto been the case. For any on-\ntology that is proposed, therefore, it should\nbe possible to relate its properties back to a\nmotivating linguistic theory. I argue that the\nevidence that we now have from the more ex-\ntensive attempts at ontology construction sug-\ngests strongly that a richly stratiﬁed model\nof the linguistic system is required in order\nto achieve the degree of constraint that we\nneed for attacking large-scale, re-usable on-\ntology construction. Fourth, I show how the\nontology of the Penman text generation sys-\ntem — that has been developed largely as\nan instantiation of the highly stratiﬁed the-\nory of systemic-functional linguistics — al-\nready answers many of the criticisms that\nhave been raised against other ontologies. I\nargue that although these criticisms are of-\nten based on largely post hoc, methodological\ngrounds, the vast majority of them also fol-\nlow directly from the properties of the linguis-\ntic system and so could (and arguably should)\nhave been made prior to attempting ontology\nconstruction. This can be seen in the proper-\nties of the Penman ontology, whose very de-\nsign avoids signiﬁcant criticisms levelled else-\nwhere.\nFinally, I suggest how ontology de-\nsign could be improved yet further by taking\ninto consideration more input from linguistic\ntheory. The Penman ontology, for example,\nis only a partial instantiation of the theoret-\nical principles underlying it and it is possible\nto show that problems enter into the account\nprecisely where the ontology falls short of the\ntheoretical speciﬁcation.\nIn general, then, this paper is intended not\nonly to improve our understanding of what\nkinds of bodies of information can stand as\nontologies of various kinds and how such bod-\nies of information relate to other resources in\nthe computational representation of the lin-\nguistic system, but also to make the point that\nappropriate views of the rich dimensions of or-\nganization exhibited by the linguistic system\ncan go a long way to improving our initial\ndesign speciﬁcations for nlp systems. They\n3\nshould, therefore, always be considered very\nearly on in system construction and computa-\ntional theory development.\n2\nThe role of language in\nontology justiﬁcation\nAs mentioned above, the move to consider nlp\nsystems that require information over and be-\nyond that attributable to surface syntax has\nraised two problems: how to organize that in-\nformation and how to relate that information\nwith the less abstract levels of the linguistic\nsystem. The ﬁrst problem is typically consid-\nered in more detail in approaches where the\noperation of a system in some speciﬁed do-\nmain is the central goal; the second usually\narises in systems which attempt to model the\nlinguistic system itself, focusing less closely on\nthe embedding in any particular speciﬁed do-\nmain of application.\nOne common source for knowledge con-\nstruction and representation that is found in\napproaches to the ﬁrst problem is earlier work\nin artiﬁcial intelligence (ai).\nEven early ai\nreasoning programs needed to represent the\nstate of the world in which the programs were\nto operate.\nThis has given rise to the ar-\neas of domain modelling and common-\nsense reasoning which are responsible for\nrepresenting concrete details of aspects of the\nworld.\nThe enterprise of world modelling\nclearly has many similarities with the require-\nments of sophisticated nlp systems and there\nhas naturally been an inﬂux of techniques and\nattitudes concerning ontology design from the\nai context.\nThis has proved most successful in the\ncross-over of techniques of knowledge rep-\nresentation in ai to techniques for repre-\nsenting linguistic information.\nThe simi-\nlarity between structured inheritance knowl-\nedge representation languages such as kl-\none [Brachman and Schmolze, 1985] and its\ndescendents and current typed feature logics\n(e.g.,\n[Smolka, 1989,\nSmolka and A¨it-Kaci, 1989,\nNebel et al., 1991]) is an active area of re-\nsearch. A basic model for the representation\nof ontologies can now assume minimally that\na subsumption lattice over sorts is deﬁned,\nprobably with some mechanism correspond-\ning to the structured inheritance of role in-\nformation associated with the sorts, and pos-\nsibly additional axioms, or particular infer-\nences, licenced by speciﬁed combinations of\nsorts. This will be the representational basis\nfor ontologies of all kinds that I will assume\nthroughout this paper.\nIn contrast to this concensus, attempts to\ndecide exactly which sorts make sense for\nan ontology based on ai ‘knowledge engi-\nneering’ principles have been less successful.\nAlthough the eﬀort-intensive nature of do-\nmain modelling naturally calls for consider-\nation of the re-usability of components of\nthe knowledge represented across distinct do-\nmains, the ability of ai-centered approaches\nto come up with such general organiza-\ntions has been limited.\nSome of the ear-\nliest work in this area was that on ‘naive\nphysics’ (e.g., [Hayes, 1979, Hayes, 1985]):\nhere the aim was to capture the under-\nlying ‘general knowledge’ that people have\nabout physical objects and substances in\nthe world; similar investigations are reported\nin,\nfor\nexample,\n[Hobbs and Moore, 1985,\nHobbs et al., 1987], and there are naturally\nalso connections to be drawn with other work\nin semantic and ‘conceptual’ representation in\nai, e.g., [Schank and Abelson, 1977]. Further\ngood examples of systems that require de-\ntailed real ‘knowledge’ in particular domains\nare expert systems; here also there is still lit-\ntle shareability across domain models.\nThe\ndetailed organization of such systems’ knowl-\nedge is typically unique to particular applica-\ntion domains and shows relatively little cross-\ndomain re-usability.\nWe can in part explain this by consider-\ning the relative importance assigned to the\ndistinct functions that such domain models\nin ai are to fulﬁll. For example, when con-\nstructing a knowledge source whose primary\nfunction is to support the particular inferences\nthat a given system needs to draw, it is log-\nical that the organization of that knowledge\nbe tailored with this goal in mind. This usu-\nally leads, however, to nongeneralizeable rep-\nresentational requirements because the infer-\nences that distinct systems are to draw have\nnot been related. The relatively small scale of\nmost of this work to date has furthermore lim-\nited the eﬀectiveness and urgency of investiga-\ntions into re-usability: the cost of construct-\ning domain models from scratch has not been\n4\nprohibitively high. This cost-equation quickly\nchanges once more realistically sized bodies\nof information are considered. It quickly be-\ncomes much more important that detailed or-\nganizations of general knowledge applicable to\nmany domains are available so as to reduce the\nwork involved when moving to new domains.\nThe\nmost\nextensive\nattempt\nto\ncre-\nate\na\ngeneral\nscaﬀolding\nfor\nrepresent-\ning general, background knowledge of the\nworld based on ai techniques is the cyc\nproject [Lenat and Guha, 1988]. The size of\nthis project (initial projections were for a base\nlevel of 10,000,000 entries) of necessity forces\na sharp awareness of the need to have an or-\nganization for knowledge that is detailed and\ngeneral enough to provide suﬃcient scaﬀold-\ning for supporting large-scale bodies of infor-\nmation in accessible and usable ways. With-\nout clear principles both for the organiza-\ntion of such knowledge and for the selection\nof the information to be represented, the re-\nsult would be disastrous:\npoorly organized\nknowledge will be inadequate both theoreti-\ncally, in that it fails to capture signiﬁcant gen-\neralizations, and practically, in that it fails\nto be usable as a resource.\nThe procedure\nfollowed in cyc is to divide up types of en-\ntities into categories that appear to behave\ndiﬀerently, i.e., concepts are classiﬁed accord-\ning to the kinds of inferences that they al-\nlow to be drawn about themselves. Problem-\natic here, therefore, is precisely which kinds\nof inferences are to be taken as deﬁnitional.\nThis does not appear to have been made ex-\nplicit and so the procedure does not provide a\nparticularly sound methodology. The result-\ning domain-independent, and hence re-usable,\nportion of the cyc ontology is accordingly not\nvery deep, somewhat tangled, and supports\nlimited inferences. It then becomes increas-\ningly necessary to raise questions concerning\nthe consistency of distinct areas of knowledge\nrepresented and, consequently, how one can\nuse that knowledge.\nIt needs to be recognized that it is essen-\ntial to deﬁne the purpose for which a body of\ninformation is to be used in order to deﬁne ap-\npropriate organizations for that information.\nAs long as the purposes are unclear, or too\nvaried, consistent organizations will be diﬃ-\ncult to achieve. The statement that a general\nontology of real-world knowledge should sim-\nply ‘represent’ that knowledge is underspec-\niﬁed. It does not provide suﬃcient guidance\nfor ﬁnding useful organizations for that knowl-\nedge. Given that we need a general organiza-\ntion and that that organization will be deter-\nmined by purpose, we clearly need a very gen-\neral (but still formally speciﬁable) task that\nrequires particular inferences to be performed.\nIf it were possible to ﬁnd such a task, then\nit would be possible to use it as a guiding\nmethodology for constructing general organi-\nzations of knowledge. Precisely one such gen-\neral task is, of course, the expression of knowl-\nedge in natural language: whatever the knowl-\nedge that is represented, i.e., whatever do-\nmain and however general/speciﬁc, it should\nbe possible to express that knowledge linguis-\ntically.3 One additional set of constraints that\none can apply in the construction of organiza-\ntions of knowledge that attempt maximal ap-\nplicability across domains is then that oﬀered\nby language.\nThis must be speciﬁed further.\nFor ex-\nample, the acceptance of ‘ways of talking’\nabout categories as evidence for the existence\nof those categories in an ontology is a very old\nstrategy (e.g., Aristotle) and is present even in\ncyc. This method of justiﬁcation is, however,\nlimited to seeing what one can say and still\nmake sense about a category rather than any\nmore technical analysis of linguistic proper-\nties. The precise ‘inferences’ that are being re-\nlied upon to shape the organization are, there-\nfore, still not being given. Thus, there are ex-\namples of ontologies that are constructed in\nnlp systems, where there is a speciﬁed rela-\ntionship between concepts and linguistic ex-\npression, but the relationship is suﬃciently\nnon-general so as not to provide strong con-\nstraints on ontology design.\nOne such case is the ontology of kbmt\nprojects [Carbonell and Tomita, 1987] such as\ntranslator\n[Nirenburg and Raskin, 1987].\nWork of this kind seeks a level of represen-\ntation that is minimally diﬀerent across dis-\ntinct languages.\nMoreover, the value of or-\nganizations of information that are relevant\nacross distinct domains is clearly recognized\n3This is overstated to the extent that some in-\nformation/knowledge is often maintained to be inex-\npressible linguistically — even if this is so, it is still the\ncase that by far the widest and most generally appli-\ncable form of expression that we know is language. In\nany case, whether or not there exists knowledge that\nis inexpressible linguistically will not aﬀect the ﬁnal\noutcome of the discussion below.\n5\nand re-usable ontology portions are actively\nsought.\nHowever, although the link to lan-\nguage ensured by the machine translation\ntask increases the likelihood that this can be\nachieved on a larger scale, the re-usable por-\ntions of the ontologies proposed until now re-\nmain small. This can in part be attributed\nto the fact that the appeal made to language\nas a constraining force on ontology design is\nundervalued.4 The ‘external-to-language’ at-\ntitude towards ontological constructs assumed\nfrom ai promises to capture abstract models\nof the world (or of conceptions of the world —\na diﬀerence that is not criterial at this point)\nand its organization independent of particu-\nlar languages.\nThis appears a tempting di-\nrection for achieving interlinguality. But then\nwe ﬁnd ‘motivations’ such as the following for\nthe categories that are to be adopted within\nan interlingual ontology:\n‘Russian has no word that corresponds\nexactly to the English word aﬀord (as\nin I can’t aﬀord X or I can’t aﬀord to\nY). In a multilingual processing envi-\nroment, there might be a concept cor-\nresponding to a sense of the English\nword aﬀord.\nA Russian sentence Ja\nne mogu sebe etogo pozvolit’ (I can’t\nallow myself this), uttered in a con-\ntext of acquisition . . . should involve the\nconcept that represents aﬀord.\nThis\nmeans that if the units of the repre-\nsentation language are chosen so that\nthey are based on Russian lexis, the\nmeaning of aﬀord will be missing. But\nthis meaning seems suﬃciently ba-\nsic to be included in an ontology.’\n[Nirenburg and Levin, 1991] [bold: my\nemphasis].\nIt is clear that this kind of argumentation\nneeds to be sharpened considerably; it is also\nclear that this can only be done when it has\nbeen established exactly what function the\n‘ontology’ is to serve.\nIn general, the more\ndetailed the linguistic constraints adopted on\nontology design are, the more detailed and\nexplicitly justiﬁable that ontology design be-\n4This is also made problematic by the very mul-\ntilinguality of possible linguistic constraints inherent\nin machine translation system — without appropri-\nate ways of achieving linguistic generalizations across\nlanguages (cf., e.g., [Bateman et al., 1991] for discus-\nsion), the application of linguistic constraints is very\nmuch more diﬃcult.\ncomes.5\nHowever, the relationship between\nontologies and nlp is interestingly reﬂexive.6\nOntologies appear necessary for the organiza-\ntion of knowledge appropriately for use by nlp\nsystems, and simultaneously the explicitness\nof the necessary inferences that constitute an\nnlp system provide an until now unrivalled\nsource of constraint for deciding on ontology\ndesigns.\nThis connection is described well in the fol-\nlowing citation from Ewald Lang:\n‘. . . the structure of language plays a\ndual role.\nIt is, properly allocated to\nthe parsing and generating components,\na constitutive part of the object to be\nmodeled (that is, the system which is to\nintegrate linguistic and non-linguistic\nknowledge).\nBut at the same time it\nis also part of the device by means\nof which this object is accessed, that\nis, the categorization of lexical items\ninto nouns, verbs, etc., provides an ap-\nparently natural grid for establishing\ncorresponding sorts of entities in the\nontology, which, by deﬁnition, is to\nrepresent non-linguistic common sense\nknowledge. Given this, the risk of con-\nfusing linguistic and non-linguistic cat-\negories is latent; moreover, it is practi-\ncally unavoidable as long as we are con-\nﬁned (or conﬁne ourselves) to looking at\ncommon sense knowledge through the\nwindow of language only, i.e., without\na chance to draw on independent ev-\nidence from non-linguistic (say, visual\nor kinasthetic) ways of accessing the\nstructure and contents of common sense\nknowledge.’ [Lang, 1991, p464]\n5This\nwas\nalso one result of an extensive study of proposed on-\ntologies reported upon in [Skuce and Monarch, 1990].\nAlthough there has also been at least one example of\ndevelopment that has attempted movement in the op-\nposite direction. The abstraction structure of BBN’s\nnatural language and understanding project janus\nwas redesigned away from a linguistically oriented de-\nscription in order to ﬁnd a ‘more general ontological\nstyle’ [Weischedel, 1989, 200] that was not so strongly\nconnected with the linguistic realization of the con-\ncepts deﬁned.\nHowever, this very move was proba-\nbly one contributing factor to the less than successful\noutcome of the subsequent attempt to use the Long-\nman Dictionary of Contempory English as the ba-\nsis for deﬁning a domain-independent taxonomy for\njanus [Reinhardt and Whipple, 1988]. The most sig-\nniﬁcant generalizations that would have helped orga-\nnize the taxonomy for the purposes of natural lan-\nguage processing had probably already been lost.\n6Or even circular: as I shall mention below.\n6\nThus, while linguistic patterns are probably\nthe richest source of organizational criteria\nthat are available to ontology design, their use\nis certainly not unproblematic. Consequences\nof this can be seen in the fact that although\nthe majority of recent and currently planned\nnatural language processing systems recognize\nthe necessity of some level of abstract ‘seman-\ntic’ organization similar to an ontology that\nclassiﬁes knowledge explicitly according to its\npossibility for linguistic expression,7 very few\nhave achieved ontologies of any size and mo-\ntivations for inclusion of particular concepts\nand distinctions in ontologies remain limited\nor underspeciﬁed. Thus, the decision to use\nlinguistic evidence by itself is still, unless fur-\nther restricted, underspeciﬁed and leaves open\na range of positions. These give rise to diﬀer-\ning functionalities that the ontologies are to\nserve, which hence impacts on ontology de-\nsign. The positions and functionalities need\nto be characterized more precisely and this I\nattempt in the following section.\n3\nThree kinds of ontologies\nAlthough I have concentrated until now on\npreliminaries to the ﬁrst problem area men-\ntioned in the introduction — how knowledge\nof the world is to be represented — the ap-\nparent value of applying linguistic constraints\nto this task renders the second problem area\n— how that knowledge is related to language\n— crucial. If the ontology cannot be related\nto language in an explicit, formalized fash-\nion, then the structures (and functions) of\nlanguage will be prevented from having a di-\nrect constraining inﬂuence on what gets rep-\nresented in the ontology, what not, and how\nthe entire ontology is to be organized.\n7Including,\nfor example:\nthe Functional Sen-\ntence\nStructure\nof\nxtra:\n[Allgayer et al., 1989];\n[Dahlgren et al., 1989]; [Emele, 1989]; the polygloss\nproject:\n[Emele et al., 1990]; certain of the domain\nand\ntext structure objects of spokesman: [Meteer, 1989];\ntranslator:\n[Nirenburg et al., 1987]; the Semantic\nRelations of eurotra-d:\n[Steiner et al., 1987]; the\njanus project: [Weischedel, 1989]; and the ontologi-\ncal types of the acord project: [Moens et al., 1989].\nMoreover, ontology-like organizations of informations\nhave also been found useful for parsing applications\nby, e.g.,\n[Calder et al., 1989, Chen and Cha, 1988,\nHinrichs et al., 1987, Zajac, 1989].\nThere are no\ndoubt many other places where this kind of construct\nnow appears.\nThere are at least two theoretically distinct\nstandpoints from which this second problem\narea has been addressed in nlp systems. One\npossibility is to assume that real-world do-\nmain knowledge is more or less directly linked\nto grammatical and lexical forms of expres-\nsion. The organization of the world knowledge\nontology should then, ideally, also be support-\nive of the use of that knowledge for linguistic\nexpression or for interpreting linguistic dis-\ntinctions: the problem of relating knowledge\nto language is thus subordinated to the world\nknowledge ontology design. A second possibil-\nity is to assume that the relationship between\nreal-world domain knowledge and grammar\nand lexis is itself complexly structured. This\nstructuring may lean for its organization to-\nwards the world knowledge ontology, in which\ncase this would blend into the ﬁrst possibility,\nor towards the grammar and lexicon, or al-\nternatively could rely on its own principles of\norganization. Each of these variants has been\nadopted in some system where a concrete on-\ntology has been attempted. This gives rise to\nthree distinct kinds of ontology that can be\nfound in nlp work. An ontology can be\n• an abstract semantico-conceptual repre-\nsentation of real-world knowledge that\nalso functions as a semantics for use of\ngrammar and lexis — this type I will term\na mixed ontology: Om;\n• an abstract organization underlying our\nuse of grammar and lexis that is separate\nfrom the conceptual, world knowlege on-\ntology, but which acts as an interface be-\ntween grammar and lexis and that ontol-\nogy — this type I will term an interface\nontology: Oi;\n• an abstract organization of real-world\nknowledge (commonsense or otherwise)\nthat is essentially non-linguistic — this\ntype I will term a conceptual ontology:\nOc.\nThe relationship involved here, their embed-\nding in general architectures, and the sub-\ntypes of interface ontologies mentioned above\nare depicted graphically in Figure 1.\n3.1\nConceptual ontologies\nMost of the ai designed ontologies — includ-\ning\n7\nlexicogrammar\nsemantics\nconceptual\n\u0006\u0012\u0017\u0013\u0010\u0013\u000e\u001a\u0000\u0007\u001a\u0014\r\u0000 \u0004\n\u0006\u0012\u0017\u0013\u0010\u0013\u000e\u001a\u0000 \u0007\u001a\u0014\r\u0000 \u0005\n\u0006\u0012\u0017\u0013\u0010\u0013\u000e\u001a\u0000 \u0007\u001a\u0014\r\u0000 \u0003\n\u0004\t\u0005\u0007\b\n\u0006\u0005\n\u000b\t\u0006\u0000 \u0003\nlexicogrammar\nsemantico–conceptual\n\u0004\t\u0005\u0007\b\n\u0006\u0005\n\u000b\t\u0006\u0000 \u0002\n\u0010\r\u0019\u000f\u000b\u0013\u000e\u0015\t\u0011\u0011\t\u0017\u000f\u000b\t\u0010\u0010\u001a\u0000\n\u000f\t\u0016\r\f\n\u000b\u0013\u0012\u000b\r\u0014\u0017\u0018\t\u0010\u0010\u001a\u0000\n\u000f\t\u0016\r\f\n\b\u000f\u0012\f\r\u0014\r\u0012\f\r\u0012\u0017\u0002\nFigure 1: Three kinds of ontology in nlp\nthose of cyc, tacitus [Hobbs et al., 1987],\njanus [Weischedel, 1989], ‘the naive seman-\ntics’ of [Dahlgren et al., 1989], and even some\naspects\nof\nthe\nkbmt\nontology, e.g., [Nirenburg and Raskin, 1987,\nNirenburg and Levin, 1991] — are attempts\nto construct ontologies of the third type: pure\nmaximally language independent ontologies\nreﬂecting the structure of the world. I have\nalready discussed some of the diﬃculties of\ndesigning such ontologies without building up\nthrough an account of language. Psycholog-\nical research might oﬀer another source of\nevidence for such ontologies; as would de-\ntailed sociological work on the commonsense\nworld.\nIt is, however, unclear whether any\nsuch methodology will be able to avoid the\nrelationship to language observed above and\nso I will now concentrate on ontologies which\nare at least intended to be related explicitly\nto language.\n3.2\nMixed ontologies\nAn example of a mixed ontology — i.e., one\nwhere there is no extensive treatment of the\nrelation between the world knowledge ontol-\nogy and grammar and lexis maintained sepa-\nrate to the ontology itself — is the approach\ntaken in the lilog natural language under-\nstand-\ning project [Herzog and Rollinger, 1991]; de-\ntails of the ontology are given in, for exam-\nple, [Klose and von Luck, 1991, Pirlein, 1991,\nKlose et al., 1991], and details of the rela-\ntion between linguistic forms and concep-\ntual representations are given in, for exam-\nple, [Gust, 1991, Bosch, 1991]. It may at ﬁrst\nglance appear strange to classify lilog here,\nsince the approach to the relation between\nlinguistic form and world knowledge draws\nheavily on [Bierwisch, 1982]’s theory of se-\nmantics where, to cite [Gust, 1991]’s state-\nment of Bierwisch’s position:\n‘. . . semantic\nforms and conceptual structures belong to\ndiﬀerent and strictly discriminated levels’.\n[Bosch, 1991] also makes it very clear that\nhe holds this distinction to be crucial for\nmaking progress in semantics and knowledge\nrepresentation.\nHowever, when the mod-\nelling of the approach is examined, we ﬁnd\nthat this distinction of levels comes under\nattack.\nFor example, both semantic forms,\nwhich are derivable from the lexicon and from\ngrammatical analysis, and conceptual forms\nare represented in a single language (the se-\n8\nmantic language being a subset of the con-\nceptual language: [Bosch, 1991, p248]) and\nare freely combinable; moreover [Gust, 1991,\np133] maintains that: ‘there are continuous\nvariations between semantic forms and con-\nceptual structures.’\nThis gives rise to lexi-\ncal entries which directly contain categories of\nan ontology which also contains categories of\nreal-world knowledge. The relation between\nconceptual knowledge and grammatical and\nlexical form is thus handled by logically ma-\nnipulating categories from a single ontology\nuntil categories are found that possess links to\ngrammatical or lexical entries — this is pre-\ncisely the architecture consistent with a mixed\nontology as shown in Figure 1.\nAn illustration of the nonseparation of of\n‘linguistic’ information and ‘conceptual’ infor-\nmation typical of ontologies of this type can be\nseen in the following taken from [Bosch, 1991,\np251]. In order to ﬁnd the interpretation in\ncontext of the lexeme “school” as it is used,\narguably diﬀerently, in examples such as:\na. The school made a major donation.\nb. The school has a ﬂat roof.\nA general ‘lexical semantic entry’ for the lex-\neme is retrieved thus:\nSEM(‘‘school’’) = λX [PURPOSE X\nW]\nwhere\nW =\nPROCESSES OF LEARNING AND TEACHING\nThis is then interpreted by applying a given\n‘contextualizing function’ selected depending\non the basis of the semantic interpretation of\nthe predicate in the lexicogrammatical repre-\nsentation.\nThose for the example sentences\nwould be:\na.\nλX [INSTITUTION X & SEM X]\nb.\nλX [BUILDING X & SEM X]\nCombining the semantic entry and the con-\ntextualizing function gives the required ‘con-\nceptual’ concept that is the referent of the lex-\neme in context — i.e., that “school” is inter-\npreted as either an institution or a building.\nAll of the undeﬁned predicates found in these\nlogical expressions (e.g., institution, pur-\npose, etc.) are sorts deﬁned in the ontology.\nA direct link is therefore constructed from lex-\nicogrammatical information and chunks of in-\nformation appropriate for the conceptual level\nof organization. As we shall see in Section 4.2,\nthis direct linking is a common property of\nnlp systems based on the common notion of\n‘semantics’ and arises out of a view of the lin-\nguistic system that collapses together several\nimportant distinctions.\n3.3\nInterface ontologies\nThe second and third types of ontology —\nthe interface and conceptual types — usu-\nally occur,\nat least theoretically,\nin the\nsame architecture.\nAlthough\nit\nis also\nthe case that some systems address them-\nselves to the organization of the interface on-\ntology without specifying how the concep-\ntual ontology will look.\nThis latter po-\nsition is common for systems that are in-\ntended as general purpose nlp systems re-\nusable across diﬀerent domains and appli-\ncations.\nExamples of such systems include\nboth parsers and generators such as the Pen-\nman\nsystem\n[Mann and Matthiessen, 1985,\nPenman Project, 1989]\nand\nMumble-\n86 [Meteer et al., 1987]. Here the problem of\nhow to organize the interface with external\napplications, where those applications are not\nknown in advance, has naturally focused at-\ntention on organizations of information appro-\npriate for interfacing. The approach to this\ndeveloped within the Penman project in terms\nof the Upper Model has become more or less\ntypical of how this is achieved — although to\nwhat extent this architecture has arisen inde-\npendently across systems is unclear. The ini-\ntial formulation of the Upper Model was based\non work by M.A.K. Halliday [Halliday, 1982],\nWilliam Mann and Christian Matthiessen.8\nThe general statement of the interface prob-\nlem for nlp systems is that machine-internal\ninformation needs to be related to strategies\nfor expressing that information in some natu-\n8The development of the Upper Model ontology,\nfrom its inception as the Upper structure of the\njanus project of ISI and BBN, up to its inclu-\nsion as a standard component of the current Pen-\nman text generation system is covered by the follow-\ning research reports: [Mann, 1985, Mann et al., 1985,\nMoore and Arens, 1985, Bateman et al., 1990].\nThe\nﬁrst detailed theoretical precursor to the ontology was\nset out in 1985 by Halliday and Matthiessen as a gen-\neral organization for an experiential semantics: this\nwas called the Bloomington Lattice.\nThe sub-\nsequent development of the Upper Model has devi-\nated somewhat from the purely linguistically moti-\nvated work; this will be discussed in more detail below.\n9\nral language. This could be done in a domain-\nspeciﬁc way by coding how the application do-\nmain requires its information to appear. This\nis clearly problematic, however: it requires de-\ntailed knowledge on the part of the system\nbuilder both of how the generator controls\nits output forms and the kinds of information\nthat the application domain contains. A more\ngeneral solution to the problem of deﬁning a\nmapping between knowledge and its linguis-\ntic expression is to provide a classiﬁcation of\nany particular instances of facts, states of af-\nfairs, situations, etc. that occur in terms of a\nset of general objects and relations of speciﬁed\ntypes that behave systematically with respect\nto their possible linguistic realizations. This\nclassiﬁcation has itself many of the properties\nof an ontology, e.g., it is a hierachical organi-\nzation of sorts and roles — although by virtue\nof its motivation in linguistic realization, it\nmust be seen as a strictly linguistically mo-\ntivated ontology. Examples here include as-\npects of [Meteer, 1989]’s Text Structure Ob-\njects in the spokesman text generator:\n‘[i]t is important to remember that Text\nStructure objects reﬂect the semantic\ntype of the expression of the informa-\ntion in an object, not some intrinsic\ntype of the object itself.’[Meteer, 1989,\np21];\nalso the ontology of the acord system:\n‘. . . the aim of the sort system is not\nto reﬂect the characteristics of real\nworld objects and events referred to\nby linguistic expressions, but rather\nto systematize the ontological struc-\nture evidenced by linguistic expres-\nsions’ [Moens et al., 1989, p178];\nand, of course, the Upper Model of the Pen-\nman system that I will describe in more detail\nbelow.\nThe position that such an interface ontology\nholds between surface details of a language\nand more abstract knowledge is, however, an\nuneasy one. As suggested above, it is possi-\nble to diﬀerentiate among such ontologies ac-\ncording to whether they orientate themselves\nmore towards less abstract or towards more\nabstract levels of representation. This brings\nwith it two potential problems in ontology de-\nsign:\n• the ontology can be too shallow, in that\nit’s categories are a too direct recoding of\nlinguistic distinctions that do not achieve\na qualitative increase in abstraction;\n• the ontology can be too deep, in that\nit is no longer possible to draw any for-\nmally speciﬁable connection between the\nconstructs posited and the linguistic evi-\ndence taken as motivating them.\nBoth extreme situations occur and both re-\nduce the value of the ontology as an eﬀec-\ntive interface medium. The former problem\nwill be accompanied by an increased diﬃculty\nin linking the ontology to information of par-\nticular domains — regardless of whether this\ninformation is considered as a separate kind\nof information or as more speciﬁc details of\nthe same kind of information; and the sec-\nond problem will be accompanied both by an\nincreased diﬃculty in linking with grammar\nand lexis and by the problems induced by\npoorer linguistic constraints mentioned above.\nThe latter situation then often places a heav-\nier reliance on ‘internal’ or formal constraints\non organization (cf., e.g., [Weischedel, 1989,\nHoracek, 1989] and what [Lang, 1991, p468]\nterms ‘sortal’ restictions) which, while impor-\ntant, do not provide suﬃcient grounds for de-\nducing very much detailed actual content by\nthemselves.\n3.3.1\nInterface ontologies that are not\nabstract enough\nInterface ontologies exhibiting the former\nproblem are very common and so it is worth-\nwhile giving a slightly more detailed exam-\nple of the problems that arise.\nOne such\nontology is that constituted by the seman-\ntic relations used within the german compo-\nnent of the eurotra project [Steiner, 1987,\nSteiner et al., 1987,\nSteiner and Reuther, 1989].\nThese relations\nare a further development of earlier work by\nFawcett — particularly his work on transitiv-\nity in English (e.g., [Fawcett, 1987]). Fawcett\nproposes a semantically motivated taxonomy\nof process types, analogously to the approach\ntaken in [Halliday, 1985] but diﬀering in the\nactual categories adopted. Each process type\nhas some distinctive set of possible partici-\npants — the approach thus diﬀers from early\naccounts of semantic participants, such as\nCase Grammar [Fillmore, 1968], where the\nparticipant relationships were often deﬁned\n10\nseparately from the processes in which they\nparticipate, and further articulates concep-\ntions of ‘thematic’ relations such as those\nfound in Lexical-functional grammar (cf.,\n[Hale and Keyser, 1986,\nLevin, 1987]) and Government and Binding\ntheory [Jackendoﬀ, 1987].\nThe eurotra-d\nwork has made reﬁnements to the proposed\ntaxonomy on the basis of multi-lingual ev-\nidence, particularly from German, so as to\nprovide explicit syntactic tests for the assign-\nment of processes to each of the various pro-\ncess types.\nIt is then explicitly stated that\nthe resulting process types described are no\nlonger primarily semantic since their classiﬁ-\ncation is based exclusively on diﬀerentiation\nby syntactic criteria. Therefore, although this\nhas produced a framework within which pro-\ncesses can be classiﬁed according to the given\ntaxonomy with a high degree of inter-coder\nconsistency, which is an important criterion\nin large distributed projects such as euro-\ntra, its eﬀectiveness as a step towards a\nhigher level of abstract information has been\nrestricted.\nThis can be seen in the follow-\ning example of process classiﬁcation given in\n[Steiner and Reuther, 1989]. For the clause\nThat she gave no answer means that she\nagrees with the proposal.\nboth subject and object are realized by that-\nclauses and the only possible classiﬁcation ac-\ncording to the syntactic tests is then one of\na mental process with two phenomena. How-\never, semantically the process also has strong\nelements of a relation between the proposi-\ntions involved. Similar examples in German\nare the following: the verb retten . . . vor:\nDaß er gut schwimmen konnte, rettete\nihn vor dem Ertrinken.\nThat he could swim well saved him from\ndrowning.\nagain resembles a relational process but has to\nbe assigned to mental according to the crite-\nria formulated; the process ‘reden’ (to speak,\ntalk), which would intuitively seem to be some\nkind of communication verb, cannot enter into\nconstructions of the form:\n* Peter redet: Karl kommt morgen\nPeter speaks: Karl is coming tomorrow\nand so does not receive a communication verb\nclassiﬁcation: and the form:\n* Peter redet, daß Karl kommt\nPeter speaks that Karl is coming\ncannot occur so it may not even receive a men-\ntal reading — the only acceptable forms pos-\nsible, e.g.:\nPeter redet Unsinn\nPeter speaks nonsense\nPeter redet mit Paul Peter speaks with Paul\nrequire an action classiﬁcation, just as the cor-\nresponding English processes would.\nThese\nproblems provide evidence that the syntactic\ntests need to be made more subtle or more\nelaborate in order to be able to reveal se-\nmantic distinctions more reliably. In addition,\nthere is no account suggested of how this level\nof representation can link to more abstract\nlevels of representation such as a conceptual\nontology.\nA similar case of this probably contributes\nto some of the diﬃculties that arise with\nthe use of ‘Lexical Semantic Structures’ (lss)\nand [Jackendoﬀ, 1983]’s ‘Lexical Conceptual\nStructures’ (lcs) for translation — the for-\nmer as described by [Dorr, 1991], the lat-\nter by [Nirenburg and Levin, 1991].\nBoth\nstructures are tightly bound to possible sur-\nface forms by formally speciﬁed linking rules\n(e.g., [Levin, 1987]). These rules partition the\nlss or lcs into classes reﬂecting the diﬀerent\nrealizational behaviour of their categories. Al-\nthough it is also then sometimes possible to\nassign to these classes particular ‘semantic’\nfeatures this has still not yet been found to\nbe suﬃciently abstract to support a motivated\nconstruction of the corresponding conceptual\nontology — as the example of the motivation\nfor including the concept aﬀord for Russian\nthat I cited above shows. The ﬁnal selection of\nconceptual ontological sorts in this case then\nshows similarities both with that described for\nlilog: i.e., by applying a mixture of lexical,\ngrammatical, and domain knowledge criteria,\nand with the pure ai techniques of cyc and\nothers. In the longer term, therefore, similar\nproblems will occur.\nAs a ﬁnal example of the problems of lack\nof abstraction, I will mention some that have\narisen in our development and use of the the\nPenman Upper Model.\nThe Upper Model,\nfor reasons that I will describe below, does\nsucceed in being more abstract than the se-\nmantic relations adopted, for example, within\n11\neurotra-d.\nThe organization of an Upper\nModel achieves greater semantic coherence,\ngrouping together distinctions that may be\nused by a variety of distinct grammatical re-\nsources in a grammar. For example, the re-\nlationships between process and participants\nmay drive the organization of clauses, but\nthey may equally drive the organization of\nhead and modiﬁers in nominal groups. The\nnature of the process-participant relationships\nis not, arguably, altered by their realizational\nform.\nUpper Model generalizations might\nthen express the commonality that unites the\nfollowing area of variation:\nA shoots B\nB was shot at T\nthe shooting of B by A\nA’s shooting of B\nB’s shooting\nthe shooting at P\nthe P shooting\nthe T shooting\netc.\nunder a single speciﬁcation:9\nprocess:\nshoot(murderer:A,murdered:B,time:T,place:P).\nCategories in the Upper Model are then cap-\nturing generalizations which are not appropri-\nately expressed within the grammar. A fur-\nther example drawn from the 1989 version of\nthe Upper Model is the possible grammati-\ncal realizations of the concept of generalized\npossession.\nThis concept should be seen as\nbeing realized by possible selections from all\nthe grammatical systems to do with ‘posses-\nsion’.\nThus the semantics of the following\nforms all make reference to this single Upper\nModel concept.\nthe door’s handle\nthe handle of the door\nthe handle that the door has\nthe door handle\nthe handle is part of the door\netc.\nFor a more extensive sets of examples\nof\nthe\nlexico-grammatical\nvariation\nthat\nthe Upper Model is intended to support,\nsee [Bateman, 1989, Bateman, 1990a].\n9Although the actual representation used in the\nUpper Model reiﬁes both predicates and the re-\nlations holding between\npredicates and their ar-\nguments; cf. [Mann et al., 1985, Hobbs et al., 1987,\nBateman et al., 1990].\nThis means that the Upper Model does suc-\nceed in achieving a suﬃciently high degree\nof abstraction as to be useful as an inter-\nface medium.\nThis increase in abstraction\nalso makes the ontology better suited to link-\ning with more abstract levels of information.10\nThe Penman system has been successfully in-\nterfaced with a number of applications —\nmostly expert systems, but also text planners\n— where domain knowledge is represented. It\nis then an example of an ontology that medi-\nates the relationship between lexico-grammar\nand world knowledge without losing the neces-\nsary formal connection with the grammar and\nlexis.\nMoreover, it moves beyond problems\nsuch as that recognized for the eurotra-d\nclassiﬁcation of process types that11\n‘The classiﬁcation system proposed by\neurotra-d proceeds in a strictly syn-\ntactic way.\n. . . From the standpoint\nof generation this solution is problem-\natic:\nit would be preferable to have\na semantic classiﬁcation that general-\nizes across such surface syntactic sub-\ntleties.” [Heid et al., 1988, p158]\nTo the extent that it is successful, this is pre-\ncisely what the Upper Model provides.\nIt\nachieves this by being based very closely not\nonly on a particular, speciﬁed grammar — no\nconcepts are admitted into the Upper Model,\nfor example, unless they have a direct and\nspeciﬁable consequence for the operation of the\ngrammar — but also on a grammar which is it-\nself already more abstract than a constituency\ngrammar. I shall describe this in more detail\nbelow.\nThe Upper Model thus stands as a signif-\nicant step forward in dealing with the prob-\nlem of interfacing with a general nlp system.\nThe Upper Model decomposes the mapping\nproblem inherent in relating domain knowl-\nedge with its possibilities for linguistic expres-\nsion by establishing a level of linguistically\nmotivated knowledge organization speciﬁcally\nconstructed as a reponse to the task of con-\nstraining linguistic realizations. While it may\n10So much so that it has sometimes been our ex-\nperience that the domain model of some application\ndomains has been altered in the light of the consistent\norganization that the Upper Model brings to bear.\n11This problem arose while attempting to interface\nthe level of input speciﬁcation for an existing genera-\ntor of German (semsyn, cf.: [R¨osner, 1988]) with the\neurotra-d semantic relations.\n12\nnot be reasonable to insist that application do-\nmains organize their knowledge in terms that\nrespect linguistic realizations — as this may\nnot provide suitable organizations for, e.g.,\ndomain-internal reasoning — we have found\nthat it is reasonable, indeed essential, that do-\nmain knowledge be so organized if it is also\nto support expression in natural language re-\nlying on general natural language processing\ncapabilities.\nThe general types constructed within the\nUpper Model necessarily respect generaliza-\ntions concerning how distinct semantic types\ncan be realized. We then achieve the neces-\nsary link between particular domain knowl-\nedge and the Upper model by having an ap-\nplication classify its knowledge organization\nin terms of the general semantic categories\nthat the Upper Model provides. This should\nnot require any expertise in grammar or in\nthe mapping between Upper Model and gram-\nmar. An application needs only to concern it-\nself with the ‘meaning’ of its own knowledge,\nand not with ﬁne details of linguistic form.\nThis classiﬁcation functions solely as an in-\nterface between domain knowledge and Up-\nper Model; it does not interfere with domain-\ninternal organization.\nThe text generation\nsystem is then responsible for realizing the\nsemantic types of the level of meaning with\nappropriate grammatical forms.12\nFurther,\nwhen this classiﬁcation has been established\nfor a given application, application concepts\ncan be used freely in input speciﬁcations since\ntheir possibilities for linguistic realization are\nthen known. Interfacing with such a system\nis thus radically simpliﬁed on two counts:\n• much of the information speciﬁc to lan-\nguage processing is factored out of the\ninput speciﬁcations required and into the\nrelationship between Upper Model and\nlinguistic resources;\n• the need for domain-speciﬁc linguistic\nprocessing rules is greatly reduced since\nthe Upper Model provides a domain-\nindependent, general and reusable con-\nceptual organization that may be used\nto classify all domain-speciﬁc knowledge\n12This\nis\nhandled\nin\nthe\npenman system by the grammar’s inquiry semantics,\nwhich has been described and illustrated extensively\nelsewhere (cf., [Penman Project, 1989]) and see Sec-\ntion 4.2 below.\nwhen linguistic processing is to be per-\nformed.\nAn example of the simpliﬁcation that use\nof the Upper Model oﬀers for a text gener-\nation system interface language can be seen\nby contrasting the input speciﬁcation re-\nquired for generators that work with realiza-\ntion classes that are less abstract than those\nof the Upper Model — such as, e.g., mumble-\n86 [Meteer et al., 1987], or uniﬁcation-based\nframeworks,\nsuch as [McKeown and Paris, 1987] and the\nLexical Functional Grammar (LFG) approach\nof [Momma and D¨orre, 1987] — with the in-\nput required for Penman.13\nFigure 2 shows\ncorresponding inputs for the generation of\nthe simple clause:\nFluﬀy is chasing little\nmice.\nThe appropriate classiﬁcation of do-\nmain knowledge concepts such as chase, dog,\nmouse, and little in terms of the general se-\nmantic types of the Upper Model (in this case,\ndirected-action, object, object, and size respec-\ntively — cf. [Bateman et al., 1990]) automati-\ncally provides information about syntactic re-\nalization that needs to be explicitly stated in\nthe\nmumble-\n86 input (e.g., S-V-O two-explicit-args,\nnp-common-noun,\nrestrictive-modifier,\nadjective).\nThus, for example, the classi-\nﬁcation of a concept mouse as an object in the\nUpper Model is suﬃcient for the grammar to\nconsider a realization such as, in mumble-\n86 terms, a general-np with a particular\nnp-common-noun and accessories of gender\nneuter. Similarly, the classiﬁcation of chase\nas a directed-action opens up linguistic re-\nalization possibilities including clauses with\na certain class of transitive verbs and char-\nacteristic possibilities for participants, cor-\nresponding nominalizations, etc.\nSuch low-\nlevel syntactic information is redundant for\nthe penman input.14 Similar, illustrative in-\n13Note that this is not intended to single out these\napproaches at all, the problem is quite general and oc-\ncurs whenever there is no ontology available for orga-\nnizing information at a more abstract level than that\nimposed by the grammar. Further, as already noted,\nmost current nlp developments are moving in a direc-\ntion analogous to that taken in our work on the Upper\nModel.\n14Moreover,\nwhen additional information is re-\nquired, that information is supplied in semantic terms\nrather than in terms of morphosyntactic labeling such\nas :number plural — in this case this is represented\n13\nputs forms can easily be imagined for other\ntypes of syntactically oriented grammar and\nlexis components.\nThe further domain-independence of the\nUpper Model is shown in the following ex-\nample of text generation control.\nConsider\ntwo rather diﬀerent domains: a navy database\nof ships and an expert system for digital\ncircuit diagnosis.15\nThe navy data base\ncontains information concerning ships, sub-\nmarines, ports, geographical regions, etc. and\nthe kinds of activities that ships, submarines,\netc.\ncan take part in.\nThe digital circuit\ndiagnosis expert system contains information\nabout subcomponents of digital circuits, the\nkinds of connections between those subcom-\nponents, their possible functions, etc. A typi-\ncal sentence from each domain might be:\ncircuit domain: The faulty system is\nconnected to the input.\nnavy domain: The ship which was\ninoperative is sailing to Sasebo.\nThe input speciﬁcations for both of these sen-\ntences are shown in Figure 3.\nThese spec-\niﬁcations freely intermix Upper Model roles\nand concepts (e.g., domain, range, property-\nascription) and the respective domain roles\nand concepts (e.g., system, faulty, input, des-\ntination, sail, ship, inoperative). Both forms\nare rendered interpretable by the subordi-\nnation of the domain concepts to the sin-\ngle generalized hierarchy of the Upper Model.\nThis is illustrated graphically in Figure 4.\nHere we see the single hierarchy of the Up-\nper Model being used to subordinate concepts\nfrom the two domains. The domain concept\nsystem, for example, is subordinated to the\nUpper Model concept object, domain concept\ninoperative to Upper Model concept qual-\nity, etc.\nBy virtue of these subordinations,\nthe grammar and semantics of the generator\ncan interpret the input speciﬁcations in order\nto produce appropriate linguistic realizations:\nthe Upper Model concept object licenses a par-\nticular set of realizations, as do the concepts\nin inquiry semantics by the inquiry response pairs\n{:multiplicity-q multiple} and {:singularity-q nonsin-\ngular}.\nThis is also the case for ‘tense’ but I have\nabbreviated the semantic speciﬁcation here. For de-\nscriptions of all these distinctions in detail, see the\npenman documentation [Penman Project, 1989].\n15These are, in fact, two domains with which we\nhave had experience generating texts using the Upper\nModel.\nquality, material-process, etc.16\nDespite the progress that has been made\nwith the Upper Model as a potential interface\nontology, it is still the case that the mappings\nbetween grammatical forms and the categories\nof the Upper Model ontology are not yet rich\nenough to ensure entirely appropriate seman-\ntic classiﬁcations — entirely anologously to\nthe case with the explicitly syntactically ori-\nented categories of the eurotra-d semantic\nrelations. In an attempt to make the deﬁni-\ntions of the Upper Model concepts more acces-\nsible to users of the Penman system, these def-\ninitions have been pushed towards an intepre-\ntation of the Upper Model as predominantly a\nhierarchy of generalizations about possible lin-\nguistic realizations in English. This approach\npermits a very straightforward control of the\ngrammar but compromises some of the seman-\ntic integrity.\nSome simple examples of this\nmay be seen in the following.\nIn the then current version of the gram-\nmar, the following clause, which is an ex-\nample that arose during development of Jo-\nhanna Moore’s Program Enhancer Advisor\n(pea) system [Moore, 1989]:17\nX is deﬁned as Y\nhad to be constructed from a process deﬁne\nand an adjunct of ‘role-playing’ to produce\nthe prepositional phrase as Y. This contrasts\nwith a more semantically oriented discrimina-\ntion of process types which could take, per-\nhaps, a process of ‘deﬁning’ with three neces-\nsary participants, a deﬁner, a deﬁned, and a\ndeﬁnition, and state how these are realized di-\nrectly. In the realization class view as we have\nit now, the process of deﬁning has to be ex-\nplicitly decomposed semantically at the level\nof the Upper Model into a process and a rela-\ntionship of role-playing. This is not intuitively\nobvious: indeed, a user has to know how the\ngrammar generates as-prepositional phrases in\norder to arrive at the ‘correct’ Upper Model\nclassiﬁcation in order to be able to generate\nthe clause. This is dangerously close to the\namount of low-level syntactic detail that needs\nto be provided for a Functional Uniﬁcation\nGrammar or Mumble-86.\n16For further discussion of this simpliﬁcation in the\nsemantic input speciﬁcation for the sentence genera-\ntor, see [Bateman, 1990b].\n17All the PEA examples were provided in work by\nJohanna Moore and Richard Whitney.\n14\n(general-clause\n:head (CHASES/S-V-O_two-explicit-args\n(general-np\n:head (np-proper-name \"Fluffy\")\n:accessories (:number singular\n:gender masculine\n:person third\n:determiner-policy no-determiner))\n(general-np\n:head (np-common-noun \"mouse\")\n:accessories (:number plural\n:gender neuter\n:person third\n:determiner-policy initially indefinite)\n:further-specifications\n((:attachment-function restrictive-modifier\n:specification (predication-to-be *self*\n(adjective \"little\"))) )) )\n:accessories (:tense-modal present :progressive\n:unmarked) )\nInput to mumble-86 for the clause: Fluﬀy is chasing little mice\nfrom:\n[Meteer et al., 1987]\n(e / chase\n:actor (e / dog :name Fluffy)\n:actee (m / mouse\n:size-ascription (s / little)\n:multiplicity-q multiple :singularity-q nonsingular)\n:tense present-progressive)\nCorresponding input to penman\nFigure 2: Comparison of input requirements for mumble-86 and penman\n15\n(v1 / connects\n:domain (v2 / system\n:relations (v3 / property-ascription\n:domain v2\n:range (v4 / faulty)))\n:range (v5 / input)\n:tense present)\nInput for digital circuit example sentence:\nThe faulty system is connected to the input\n(v1 / sail\n:actor (v2 / ship\n:relations (v3 / property-ascription\n:domain v2\n:range (v4 / inoperative)\n:tense past)\n:destination (sasebo / port)\n:tense present-progressive)\nInput for navy example sentence:\nThe ship which was inoperative is sailing to Sasebo\nFigure 3: Input speciﬁcations from navy and digital circuit domains\nThis is not an isolated case. Other problem-\natic assignments in the pea domain include:\n• The process call, as in “The boy is called\nJohn”.\nPresently call is classiﬁed as a\ndispositive-material-action from UM-89,\nboy becomes the actee, and the name,\n‘John’, becomes a recipient.\nNo actor\nis speciﬁed and so a passive construction\nappears (due to a then current shortcut\ndeﬁned for the textual reasoning that the\ngrammar initiates for selection of active-\npassive clauses).\n• The process generalize to, as in “The re-\nsult can be generalized to other cases”.\nHere generalize is again a straightforward\nnondirected-action and to other cases is\nspeciﬁed as a destination spatio-temporal\ncircumstance in UM-89 in order to gen-\nerate the preposition.\nIn all of these cases, the role assignments\nare only being used in order to achieve the\nrequired syntactic pattern given by the par-\nticular state of the grammar of the Penman\nsystem: the Nigel grammar of English. In the\nﬁrst example, the model for the clause being\nused is that of give since this class of verbs\nis bitransitive; in the second, the technique\nadopted is as with the case of deﬁne as above,\nwhere a circumstantial role is selected purely\nin order to guarantee the desired preposition.\nAlthough in these cases it is reasonably clear\nthat both grammar and Upper Model would\nneed to be extended to include the desired\nprocess types, in general the theoretical sta-\ntus of using arbitrary assignments of concepts\nto the Upper Model and selections of roles to\nbe expressed has not been made suﬃciently\nclear.\nThis technique is (or rather should)\nonly be employed when it is not possible to\nextend the grammar and ontology appropri-\nately: only when the grammar has to be taken\nas ‘ﬁxed’, e.g., because it is being applied by\na user that does not have access to the inter-\nnal organization of the grammar, is this kind\nof strategy defensible. As a general technique,\nthe strategy has to be strongly rejected on the-\noretical grounds. However, note that without\na commitment to semantic coherence, there\nis little reason not to use the Upper Model\nin this way; we have already seen the similar\nsituation in the use of the eurotra-d sys-\ntem of semantic relations where commitment\n16\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇÇ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉÉ\nsystem\ninput\nfaulty\nship\nport\ninoperative\nsail\nconnects\nTHING\nQUALITY\nOBJECT\nPROCESS\nRELATIONAL–PROCESS\nMATERIAL –PROCESS\nUPPER MODEL\nDOMAIN MODELS\nFigure 4: Upper Model organization reuse with diﬀering domains\n17\nto semantic coherence has been explicitly re-\njected in favor of more readily operationalize-\nable grammatical critera.\nAnother set of related problems arises when\nsemantically similar processes have diﬀerent\nsyntactic realization. Consider, for example,\nthe two clause types:\nx is like y\nx resembles y\nAlthough a user might wish to place these\nsimilarly in the Upper Model, grammatically\nthey are rather diﬀerent. The former requires\nthe grammatical features:\n{circumstantial-\nattribute, manner-participant, be-intensive};\nthe\nlatter\nhas features:\n{circumstantial-\nascription, circumstantial-process}.\nIn the\npresent\nNigel\ngrammar,\nthese\nare\ndis-\ntinguished\nby the\ninquiry circumstantial-\nascription-q, which would need to examine the\nUpper Model. Therefore, in order to obtain\nthe diﬀering syntactic structures a further dis-\ntinction would need to be set up at the Upper\nModel level.\nThe realization class view therefore makes\nit diﬃcult for users to formulate their input\nspeciﬁcation to the system unless they know\nprecisely the form of linguistic expression that\nthey require. Since the realizational link be-\ntween Upper Model categories and Nigel has\nbeen made so tight for the very purposes\nof achieving readily describable criteria, it is\nsometimes (and increasingly once more users\nattempt more varied modelling) necessary to\nsubordinate a concept in a counter-intuitive\nposition simply in order for the language re-\nquired to result.\nThis certainly undermines\nthe semantic integrity of the Upper Model as\nan interface ontology and moves the entire\nclassiﬁcation towards a less abstract level of\ninformation. It needs to be remembered, how-\never, that only when the grammar is ﬁxed, is\na speciﬁc, determinate Upper Model required\n— furthermore, that Upper Model is even par-\ntially determined by the particular grammar\nthat is speciﬁed.\nFinally, one further problem with the in-\nterface ontology instantiated by the Penman\nUpper Model lies precisely in the simplicity of\nthe relationship constructed betweeen domain\nmodel and Upper Model. We have seen that\nthis is achieved by literally classifying (in the\nformal sense of adding into the subsumption\nlattice) domain model concepts in terms of the\ncategories from the Upper Model. Following\nthis operation, the Upper Model and the do-\nmain model form a single inheritance hierar-\nchy and the domain concepts directly inherit\nthe possibilities for surface realization deﬁned\nfor the Upper Model concepts. This opera-\ntion is currently performed only once for each\ndomain and, while simplifying input expres-\nsions, it means that the relationship between\ndomain and Upper Model is not being han-\ndled particularly ﬂexibly.\nIn fact, once the\nclassiﬁcation is complete, the complete ontol-\nogy can be interpreted as having collapsed\ninto a mixed ontology of the type described\nfor lilog: both particular domain concepts\nand general linguistically motivated concepts\noccur in the same subsumption lattice. This\ntreatment of the relationship between a po-\ntential conceptual ontology, containing detail\nknowledge of a domain, and the interface on-\ntology, containing a semantic classiﬁcation of\npossibilities for linguistic expression, needs to\nbe made considerably more ﬂexible to avoid\nthe problems of mixed ontologies described\nboth above and below.\n3.3.2\nInterface ontologies that are too\nabstract\nInterface ontologies exhibiting the problem of\nbeing too abstract are more commonly found\nin small scale systems: the problem of not be-\ning able to specify the mapping down to gram-\nmar and lexis in a convenient and expandable\nform often prevents large-scale development\nfrom getting very far.\nSuch projects (e.g.,\npolygloss, acord and many others) begin\nby adopting classes of categories developed,\nfor example, in analytical philosophy or nat-\nural language semantics — such as the event\ntypes of [Vendler, 1967], temporal categories\nsuch as those of [Moens and Steedman, 1988],\nthe semantico-‘conceptual’ predicates pro-\nposed by [Jackendoﬀ, 1983, Jackendoﬀ, 1990],\nevent structures of [Pustejovsky, 1988], and\nmany others. As long as restricted grammat-\nical possibilities are entertained, for example\nto enable research on particular focused areas\nof semantics-syntax, then such ontologies are\nadequate — even useful, since the focusing al-\nlows greater depth in the semantic account to\nbe achieved. It should also be the case, how-\never, that this work then feeds back into more\ngeneral and broader ontology work, and this\n18\nhappens much too rarely. It is also sometimes\nunclear what the relationship of these ontolo-\ngies would be to a more abstract conceptual\nontology — this may be expressed formally,\nfor example, in terms of a model-semantic the-\nory but the details are often left for future\nwork.\n3.3.3\nBrief discussion\nIt is clear that ontologies of the interface\ntype that are more closely bound to lan-\nguage are nevertheless most useful for nlp\nsystems that want to deal with a wider va-\nriety of actual language phenomena. The in-\ncrease in abstraction may not be so very great\nin comparison to a desired conceptual ontol-\nogy, but it is nevertheless better than work-\ning with grammar and lexis directly.\nSuch\nwork is also much more likely to be sta-\nble in the face of changing theoretical posi-\ntions and more justiﬁable with respect to ac-\ntual linguistic data. It is, then, natural that\none further type of nlp projects attacking\nthe problem of large-scale ontology construc-\ntion is that of ‘dictionary’-oriented projects,\nsuch as edr [Matsukawa and Yokota, 1991]\nand acquilex [Calzolari, 1991].\nThe edr\nproject aims at producing a ‘concept dictio-\nnary’ containing 400,000 ‘word senses’ for En-\nglish and Japanese, and acquilex is con-\ncerned with producing a re-usable ‘lexical\nknowledge base’ that classiﬁes entries accord-\ning to taxonomies of semantic categories and\nrelations between those categories.\nBoth\nprojects have constructed sizeable semantic\ntaxonomies relying strongly on diﬀerences in\nlexico-grammatical realization for the cate-\ngories adopted. The taxonomy organization\nand categories found in acquilex have simi-\nlarities to the view of lexical semantics pro-\nposed by [Pustejovsky, 1991] where, again,\noppositions in linguistic behavior are an es-\nsential motivating criterion.\nAnother large\nproject partly leading up to this work, and\nnow related to the kbmt work mentioned\nabove, was the MIT Lexicon Project where\nextensive classiﬁcation of lexemes was under-\ntaken on the basis of the diﬀering grammatical\npatterns that the lexemes may enter into.\nAlthough the construction of large knowl-\nedge bases at this level of abstraction is bound\nto oﬀer a deﬁnite improvement in our abil-\nity to rely on linguistic motivations in future\nontology design, their availability will not of\nitself bring about that design. It is still neces-\nsary to consider methodologies for using such\ninformation so that appropriate ontologies for\ngeneral nlp use can be constructed. There-\nfore, in the next section I will relate the kinds\nof ontologies that we have seen in this section\nto compatible linguistic theories. Without a\nbroader view of what is being done linguisti-\ncally when categories for a particular kind of\nontology are proposed, I believe it is unlikely\nthat progress will be made. As long as the\ncategories developed are suﬃciently close to\nthe surface details of language to remain ob-\njectively veriﬁable, i.e., remain in the realms\nof syntax and lexico-grammatically oriented\ninterface ontologies, useful classiﬁcations can\nbe constructed. For more abstract levels, how-\never, the support of theory become crucial for\ndeﬁning methodologies, questions, and possi-\nble solutions.\n4\nLinguistic\nsupport\n(or\notherwise) for the ontol-\nogy types\nIn this section, I will follow the ordering of the\ndiscussion of ontology types of the previous\nsection: i.e., ﬁrst linguistic theories compat-\nible with the design of mixed ontologies will\nbe mentioned, followed by the kind of linguis-\ntic theory that is more supportive of distinct\ninterface and conceptual ontologies. I will not\nraise the issue here of the relationship between\n‘conceptual ontologies’ and possible linguistic\ntheories, since one of the deﬁning phrases that\nis often used about this level of abstraction is\nits very extra-linguisticness. This does, how-\never, depend on the view of the linguistic sys-\ntem that is adopted and I will mention some-\nthing about this later. Finally in this section,\nI discuss some disadvantages of the former ap-\nproaches when considered as a methodology\nfor developing the kinds of resources neces-\nsary for nlp systems.\nBefore beginning the discussion, I should\nhowever brieﬂy note the motivation for an\nexclusion of forms of semantics such as sit-\nuation semantics, model-theoretic semantics\nof various kinds, etc. below. Such accounts\nare not immediately relevant to the discus-\nsion at hand precisely because they have not\n19\nbeen concerned with the construction of rep-\nresentations that are directly supportive of\nontologies.\nThat is, regardless of whether\nthe formal account of semantics proposed\nin some particular framework contains sets\nof predicates that are of mixed ontological\nstatus, or are purely conceptual, or purely\n(linguistically) semantic, we ﬁnd one crucial\ncomponent of ontological engineering miss-\ning. Those categories are not typically built\nup into subsumption lattices of sorts shar-\ning various general properties of use for fur-\nther domain classiﬁcation.\nIt is clear that\nmany of these theoretical approaches could\neasily move in this direction, and with the\nincreased use of sorts in linguistic theory at\nall levels of description some ﬁrst steps have\nbeen taken (e.g.,\n[Sag and Pollard, 1991,\np78], [Nerbonne, 1992]). However, as pointed\nout by [Onyshvekych and Nirenburg, 1991]:\n‘The crucial point is that in order to\nhave an explanatory power, the atoms\nof [a] meaning representation language\nmust be interpreted in terms of an in-\ndependently motivated model of the\nworld.\nMoreover, if any realistic ex-\nperiments have to be performed with\nsuch an nlp system, this world model\n(sometimes called an ontology) must be\nactually built, not only deﬁned alge-\nbraically.’\nTherefore, until the problem of ontology con-\nstruction on a realistic scale itself becomes an\nissue for an account, that account remains of\nless central concern for the current discussion.\n4.1\nMixed\nontologies\nand\nlin-\nguistic theory\nThe closest linguistic approaches to support\nmixed ontology design such as that found in\nlilog are, perhaps surprisingly, those com-\npatible with the work of [Jackendoﬀ, 1983,\nJackendoﬀ, 1990]. Jackendoﬀadopts the po-\nsition that the semantic level of representa-\ntion with which he is concerned is also con-\nceptual, i.e., common to modalities such as\nlanguage and vision [Jackendoﬀ, 1983].\nAs\npointed out by [Herweg, 1991], approaches\nthat directly link syntax with conceptual in-\nterpretation now occupy a rather standard po-\nsition in mainstream linguistics and so there\nare many approaches that could be described.\nThat of Jackendoﬀis probably one of the\nmost developed and well known in this di-\nrection, although there are also similarities\nto be drawn with work in Cognitive Linguis-\ntics [Langacker, 1987, Talmy, 1987] and direc-\ntions such as that of [Wierzbicka, 1988]. All\nof these approaches share an orientation to\nlanguage as an instrument for revealing facets\nof conceptual organization.\nThis is stated\nmost clearly by Jackendoﬀin terms of what\nhe terms the Grammatical Constraint:\n‘. . . it would be perverse not to take as\na working assumption that language is\na relatively eﬃcient and accurate en-\ncoding of the information it conveys.\nTo give up this assumption is to refuse\nto look for systematicity in the rela-\ntionship between syntax and semantics.\nA theory’s deviations from eﬃcient en-\ncoding must be rigorously justiﬁed, for\nwhat appears to be an irregular rela-\ntionship between syntax and semantics\nmay turn out merely to be a bad theory\nof one or the other.’ [Jackendoﬀ, 1983,\np404]\nGiven his equation of semantic structure and\nconceptual structure, this becomes largely\nequivalent to statements such as the follow-\ning describing the basic claim of of cognitive\nlinguistics:\n“... across the spectrum of languages,\nthe grammatical elements that are en-\ncountered, taken together, specify a\ncrucial set of concepts.\nThis set is\nhighly restricted: only certain concepts\nappear in it, and not others. . . [This]\nset of grammatically speciﬁed notions\ncollectively constitutes the fundamental\nconceptual structuring system of lan-\nguage. That is, this cross-linguistically\nselect set of grammatically speciﬁed\nconcepts provides the basic schematic\nframework for conceptual organization\nwithin the cognitive domain of lan-\nguage.” [Talmy, 1987, p165/6]\nThis position also appears in the approach\nof Pustejovsky to the relation between lex-\nemes and their interpretation in context; as\nhe writes,\n‘The meaning of words should somehow\nreﬂect the deeper, conceptual struc-\ntures in the system and the domain it\noperates in. This is tantamount to stat-\ning that the semantics of natural lan-\n20\nguage should be the image of nonlin-\nguistic conceptual principles (whatever\ntheir\nstructure).’\n[Pustejovsky, 1991,\np410]\nThese approaches are all described by the ﬁrst\narchitecture depicted in the diagram of Fig-\nure 1. Each suggests that there is a portion\nof the conceptual ontology that has a direct\nlinguistic connection and that that portion\nshould have just the same kind of organization\nas the rest of the conceptual ontology. A spec-\niﬁcation of the semantics of some expression\nis simultaneously a (possibly partial) speciﬁ-\ncation of a conceptual speciﬁcation.\nAgain,\nthis state of aﬀairs receives a very explicit de-\nscription from Jackendoﬀ:\n‘This account of the syntax-semantics\ncorrespondence gives a principled ac-\ncount of the level of “argument struc-\nture” found in various versions of GB\nand LFG ... - a level of linguistic rep-\nresentation that lists the arguments of\na verb, with or without their θ-roles.\nSuch a list can now be simply con-\nstructed from the set of indices in the\nconceptual structure of the verb, and\nthere is one index per syntactically ex-\npressed argument...\nIn short, “argu-\nment structure” can be thought of as\nan abbreviation for the part of concep-\ntual structure that is “visible” to the\nsyntax.’ [Jackendoﬀ, 1983, p404/5]\nBy virtue of the Grammatical Constraint,\ntherefore, Jackendoﬀadopts a very close bind-\ning of linguistic analysis and categories at\nhis semantico-conceptual level of represen-\ntation:\navailable linguistic realizations and\npatternings lead directly to the positing of\ncorresponding categories and relationships\nat the level of semantic/conceptual struc-\nture. In Jackendoﬀ’s case, the linguistic ev-\nidence admitted is organized in terms of X-\ntheory [Chomsky, 1980, Jackendoﬀ, 1977] and\nso close correspondences appear between cat-\negories of this theory and categories of the\nsemantic/conceptual structure. In particular,\nhe states that:\n1. “...\nevery major phrasal constituent in\nthe syntax of a sentence corresponds to\na conceptual constituent that belongs to\none of the major ontological categories.”\n2. “... the lexical head X of a major phrasal\nconstituent corresponds to a function in\nconceptual structure — a chunk of the\ninner code with zero or more argument\nplaces that must be ﬁlled in order to form\na complete conceptual constituent. The\nargument places are ﬁlled by the readings\nof the major phrasal constituents strictly\nsubcategorized by X.” [Jackendoﬀ, 1983,\np67]\nThus, he suggests the following approxima-\ntion to conceptual structure for the sen-\ntence The man put the book on the table\n[Jackendoﬀ, 1983, p68].\n\n\nevent\nput(\n\u0014\nthing\nthe man\n\u0015\n,\n\u0014\nthing\nthe book\n\u0015\n,\n\n\nplace\non(\n\u0014\nthing\nthe table\n\u0015\n)\n\n)\n\n\nThis structure, if we ignore the textual in-\nformation represented abbreviated here with\nthe, shows striking similarities with the in-\nput speciﬁcation described earlier for Penman\n(cf.\nFigures 2 and 3).\nThe structure may\nbe glossed as stating that a predicate put of\ntype event holds over three arguments: the\nﬁrst two are of type thing, the latter is an\non-relation of type place. Each of the pred-\nicates are taken to be deﬁned as semantico-\nconceptual categories motivated primarily by\nlinguistic patterning. Further examples of the\nmotivation of semantico-conceptual categories\nfrom linguistic evidence is the following list of\nexample categories oﬀered by Jackendoﬀ:\nInterrogative probe\nsupports category:\na. What did you buy?\n[thing]\nb. Where is my coat?\n[place]\nc. Where did they go?\n[direction]\nd. What did you do?\n[action]\ne. What happened next?\n[event]\nf. How did you cook the eggs?\n[manner]\ng. How long was the ﬁsh?\n[amount]\nSubsequently, further categories of diﬀerentia-\ntions are made working from intuitions on the\nmeanings of sentences and their constituents\nsupported by example sentences. Moreoever,\nanalogously to the perceived relationship be-\ntween syntactic structures and rules for their\nwell-formedness, Jackendoﬀtakes the position\nthat the inter-relationships between the se-\nmantic/conceptual categories will also be ex-\npressed in terms of well-formedness rules. An\n21\nexample for the category [path] is as follows\n[Jackendoﬀ, 1983, p166]:\n[path] →\n\nPath\n\n\n\n\n\n\n\n\n\nto\nfrom\ntoward\naway-from\nvia\n\n\n\n\n\n\n\n\n\n\u0012\u001a\n[T hing y]\n[P lace y]\n\u001b\u0013\n\n\nThe combination of a number of rules such\nas these begins to deﬁne a hierarchy of inter-\nrelated categories analogous to the standard\nhierarchical organization that I have assumed\nappropriate for ontology construction.\nA comparison of Jackendoﬀ’s semantico-\nconceptual categories with, for example, the\nsuperﬁcially very diﬀerent categories arising\nfrom cognitive linguistics is very illuminating\nconcerning the role that motivations from lan-\nguage can play for ontology construction. The\ngeneral methodology of proponents of cogni-\ntive linguistics is to examine ‘grammatical’ el-\nements — however these come to be deﬁned —\nin order to uncover the conceptual organiza-\ntion they presuppose. For example, Talmy of-\nfers the following break down of the this/that\ndistinction in English.\n‘A closed-class element of this type\nspeciﬁes the location of an indicated ob-\nject as being, in eﬀect, on the speaker-\nside or the non-speaker-side of a con-\nceptual partition drawn through space\n(or time or other qualitative dimen-\nsion).’ [Talmy, 1987, p168]\nThis is summarized as:\n• a ‘partition’ that divides a space into ‘re-\ngions’/‘sides’\n• the ‘locatedness’ (a particular relation) of\na ‘point’ (or object idealizable as a point)\n‘within’ a region\n• (a side that is the) ‘same as’ or ‘diﬀerent\nfrom’\n• a ‘currently indicated’ object and a ‘cur-\nrently communicating’ entity.\nBy sampling across a wide range of languages\nthe Cognitive Grammarian compiles a list of\nsuch distinctions and attempts to provide in-\nternal organization and structure rooted in a\npresumed linguistically relevant area of con-\nceptual organization. The ﬂavor of this orga-\nnization can be seen in the following examples\nof proposed categories from Talmy.\nDimension “The category of ‘dimension’ has\ntwo principal member notions, ‘space’ and\n‘time’. The kind of entity that exists in space\nis — in respectively continuous or discrete\nform — ‘matter’ or ‘objects’.\nThe kind of\nentity existing in time is, correspondingly,\n‘action’ or ‘events’. . . ” [Talmy, 1987, p174].\nThis is schematized as:\ndimension\ncontinuous\ndiscrete\nspace :\nmatter\nobjects\ntime :\naction\nevents\nPlexity ‘Plexity’ is a generalization of notions\nsuch as singular and plural to cover actions\nalso. For example:\nmatter\naction\na.\nuniplex\nA bird ﬂew in.\nHe sighed (once).\nb.\nmultiplex\nBirds ﬂew in.\nHe kept sighing.\nBoundedness ‘Boundedness’ is a generalization\nof notions such as mass and count with re-\nspect to nouns to include again actions in ad-\ndition to objects. This Talmy relates to im-\nperfective and perfective and similar terms in\nthe treatment of verbs. Essentially, “[w]hen\na quantity is speciﬁed as ‘unbounded’, it is\nconceived as continuing on indeﬁnitely with\nno necessary characteristic of ﬁniteness in-\ntrinsic to it. When a quantity is speciﬁed as\n‘bounded’, it is conceived to be demarcated\nas an individual unit entity.” ([Talmy, 1987,\np178]). Similar, far more formal, expressions\nof this idea can now be found in a number of\napproaches (e.g. [Krifka, 1989]).\nDividedness “A\nquantity\nis\n‘discrete’\n(or\n‘particulate’)\nif\nit\nis\nconceptualized\nas\nhaving breaks,\nor interruptions,\nthrough\nits composition.\nOtherwise,\nthe quan-\ntity\nis\nconceptualized\nas\n‘continuous’.”\n[Talmy, 1987, p180]\nThese categories hold of a given ‘quantity’\nsimultaneously and so classify that quantity\nalong the dimensions described.\nMoreover,\ndiﬀerent linguistic consequences are intended\nto follow from each distinction.\nAlthough\nthere are many interesting distinctions sug-\ngested which could help enrich proposed on-\ntologies along a number of dimensions, the\nlack of an accepted, detailed grammatical\nframework nevertheless limits the generaliza-\ntions that can be found.\nLangacker claims\nthat:\n“. . . basic grammatical categories such\nas noun, verb, adjective, and ad-\nverb are semantically deﬁnable.\nThe\n22\nentities referred to as nouns, verbs, etc.\nare symbolic units, each with a seman-\ntic and a phonological pole, but it is\nthe former that determines the catego-\nrization. All members of a given class\nshare fundamental semantic properties,\nand their semantic poles thus instanti-\nate a single abstract schema subject to\nreasonably explicit characterization. A\nnoun, for example, is a symbolic struc-\nture whose semantic pole instantiates\nthe schema [thing]. . . In a similar fash-\nion, a verb is said to designate a pro-\ncess, whereas adjectives and adverbs\ndesignate diﬀerent kinds of atemporal\nrelations.” [Langacker, 1987, p189]\nAlthough with the proposed conceptual cat-\negories restricted in this way to follow from\ngrammatical categories that are so directly\n‘observable’, i.e., often inﬂectional and word-\nbased such as singular and plural, mass and\ncount, nouns and verbs, etc., one would not\nexpect a particularly rich ontology, in fact, a\nlarge number of ﬁnely diﬀerentiated categories\nare set up — primarily on the basis of con-\ntrastive examples that do not rely on detailed\nsyntactic analysis.\nThis shows conclusively\nthe value of examining a very wide range of\nnatural occuring examples, in contrast to the\noft criticised (e.g., [Rohrer, 1986]), but nev-\nertheless still prominent, tendency in main-\nstream linguistics to study constructed ex-\namples in areas that illuminate the currently\nfashionable linguistic phenomena. Neverthe-\nless, the lack of a formally speciﬁable mapping\nbetween the categories proposed and linguistic\nrealization renders the consequences of estab-\nlishing any particular set of categories almost\nimpossible to investigate and this is certainly\nless of a problem in a contrasting account such\nas that of Jackendoﬀwhere the relation to a\ndetailed account of grammar and lexis is al-\nways clear. The value noted above of being\nable to test out and justify proposed categories\nfor ontologies formally applies here strongly.\nJackendoﬀis able, therefore, even on the basis\nof rather limited linguistic breadth of motiva-\ntion, to suggest a more detailed set of cate-\ngories and interrelationships. The semantico-\nconceptual representations are substantially\nmore abstract than syntactic classes (as ev-\nidenced by the generalizations that they per-\nmit to be drawn) but are nevertheless tied\nreasonably precisely with possibilities for lin-\nguistic expression. An ideal situation would\ntherefore be to have a very broad, detailed\nand formally speciﬁed grammar, capable of\ndescribing very ﬁne-grained grammatical and\nlexical diﬀerences.\nEven despite the lack of formally speci-\nﬁed mappings to linguistic form within cog-\nnitive linguistics,\nthere has still been at\nleast one signiﬁcant application of its pro-\nposed concepts in a computationally con-\ntext.\nThis is in their use to provide a sys-\ntem of semantic features for stating mean-\nings to be preserved across languages in\nmachine translation [Zelinsky-Wibbelt, 1987,\nZelinsky-Wibbelt, 1988]. Although the work\nsuﬀers from the lack of explicit deﬁnition\nthat the conceptual categories have so far re-\nceived — making it diﬃcult for coders us-\ning the semantic features reliably to clas-\nsify the meanings that are involved — this\nsituation may be improved signiﬁcantly by\nsome current work in progress18 which is in-\ntended to improve the necessary connection\nbetween the semantic categories and their\nlinguistic realization.\nThe situation apply-\ning Jackendoﬀ’s categories in a computational\ncontext has, as would be expected, been\nmore straightforward. A number of proposals\nhave been made for such an application, and\nsome have been implemented. For example,\n[Meteer, 1988] comments on the possible or-\nganization of abstract linguistic terms at the\ntext message level for the sentence generator\nMumble-86 that a system such as Jackendoﬀ’s\ncould provide and we have already seen that\nboth [Dorr, 1987, Dorr, 1990]’s work on the\nunitran translation system and approaches\nwithin\nkbmt\n[Nirenburg and Levin, 1991]\nhave implemented aspects of the semantico-\nconceptual structure.19\n18For example by Cornelia Zelinsky-Wibbelt and\nWiebke Ramm of IAI/Eurotra-D on syntactic tests\nthat coders could apply to resolve diﬃcult cases.\n19Further analogous areas of research which often\nfall somewhere between the explicit grammatical foun-\ndation attempted by Jackendoﬀand the, until now,\nmore impressionistic linguistic motivations of Lan-\ngacker and others, include the large body of work\non the ‘conceptualization’ and linguistic expression of\nspatial-temporal information, e.g.: [Herskovits, 1986,\nBierwisch and Lang, 1989] and many others.\n23\n4.2\nInterface ontologies and lin-\nguistic theory\nIn contrast to the accounts of the previous\nsection, the separation of information found\nin the interface ontology and a more abstract\nconceptual ontology is consonant with theo-\nretical positions that assume a higher degree\nof stratiﬁcation in the linguistic system. The\nmixed ontology view goes well with a stan-\ndard syntax-semantics-pragmatics distinction\nwhere ‘semantics’ includes the conceptual rep-\nresentation and ‘pragmatics’ provides pro-\ncedures that operate over the semantico-\nconceptual representation to produce active\ninterpretations in context. In this sense, prag-\nmatics is not a further stratum in a linguis-\ntic system and has a distinct theoretical sta-\ntus to that of syntax or semantics. In con-\ntrast to this, the interface ontology architec-\nture suggests at least a three-way stratiﬁca-\ntion between lexico-grammatical information,\nsemantic information, and a contextualizing\nlevel of ‘conceptual’ information.\nEach of\nthese strata appears to have rather similar\nformal properties: most of the information of\neach, for example, would appear to be repre-\nsentable as a subsumption lattice deﬁned over\nsorts, possibly augmented with structured in-\nheritance.20\nI have already mentioned one view of the\nlinguistic system that seems compatible with\nthis stratiﬁcation:\nthe approach to seman-\ntics and context proposed by [Bierwisch, 1982,\nBierwisch and Lang, 1989] that acted as one\ninﬂuence for the lilog design — even though\nthe ﬁnal speciﬁcation of the ontology within\nlilog does not seem to have remained in\nthe spirit of this theory. Within the linguis-\ntic model of Bierwisch, conceptual represen-\ntations are maintained strictly separate from\nsemantic representations, and semantic ex-\npressions are used to constrain construction\nof conceptual expressions during interpreta-\ntion. Thus, ‘words’ (actually lexicogrammat-\nical patterns) are related to semantic forms\nwhich determine functions from contexts to\nconceptual structures.\nThe distinction be-\ntween the two levels in this kind of two-level\nsemantics is nicely summarized by Michael\nHerweg as follows:\n20Current work in information-based syntax makes\nthis point for syntax [Pollard and Sag, 1987].\n‘Semantic\nrepresentations\nare\nstruc-\ntured conﬁgurations of semantic units\nwhich, on the one hand, are deter-\nmined by the grammatical system of\nthe language in question and, on the\nother hand, are grounded in — or\nmotivated by — the conceptual sys-\ntem.\n. . . Conceptual representations\nare structured conﬁgurations of concep-\ntual units, which are mental representa-\ntions of certain aspects of the external\nworld.’ [Herweg, 1991, p152/3]\nThe two classes of categories — the semantic\nand the conceptual — thus have very diﬀerent\ntheoretical statuses and allow very diﬀerent\nkinds of motivations.\nThis is therefore pre-\ncisely the kind of structuring of the linguistic\nsystem that one requires to support the use of\ninterface and conceptual type ontologies.\nThe most successful of the interface ontolo-\ngies described in Section 3.3, the Penman Up-\nper Model, clearly has a natural relation to\nthe stratiﬁcation found in this kind of ‘two-\nlevel semantics’. For example, the sorts of the\nUpper Model are determined by the gram-\nmatical system (concretely, the Nigel gram-\nmar component of the Penman system) as is\nrequired.\nAlthough there is also a relation-\nship to be drawn with accounts that are ex-\nplicitly seeking semantic organizations closely\nlinked to language regardless of these organi-\nzations’ further embedding at higher levels of\nabstraction,21, the relation between a proper\nview of the Upper Model and two-level se-\nmantics becomes even closer when we exam-\nine instead of the Upper Model, rather the\ntheoretical position of which the Upper Model\nis only a very partial instantiation: i.e., that\nof systemic-functional theory [Halliday, 1961,\nHalliday, 1978,\nMatthiessen and Halliday, forthcoming].\nSystemic-functional theory is a highly strat-\niﬁed general linguistic theory with respect to\nwhich the Penman text generation and its de-\nscendents have been, and continue to be, de-\nveloped. In some ways perhaps analogously\nto the situation in lilog, many aspects of the\ncurrent implementation of the Penman system\nare not accurate instantiations of that theory.\nOf particular importance here is the very in-\nstantiation of the concept of linguistic strata\n21Or, alternatively, by seeking an embedding in an\naccount such as model-theoretic semantics to ‘bottom\nout’ in a formally speciﬁable way.\n24\n— since it is precisely this construct which\nis necessary for motivating the kind of multi-\nlevelled representation that we ﬁnd in inter-\nface ontologies and their contextualizing con-\nceptual ontologies.\nThe notion of stratiﬁcation in systemic-\nfunctional theory is depicted diagrammati-\ncally in Figure 5.\nThe linguistic system\nis broken down here into three strata: lex-\nicogrammar, semantics, and context.\nBe-\ntween each stratum the same relationship\n— that of realization — holds.\nSystemic-\nfunctional theory is essentially a functional\ntheory, i.e., one that is concerned crucially\nwith the functions that language fulﬁlls in\nparticular contexts, and this informs the un-\nderstanding of the realization relationship be-\ntween strata as follows. Each higher-level (i.e.,\nmore abstract) stratum is seen as providing\nthe functional motivation for the next lower-\nlevel stratum; and each lower-level stratum is\nseen as providing a resource that generalizes\nacross the possibilities of the next-higher stra-\ntum [Halliday, 1978]. This gives us a more de-\ntailed view on how strata in the linguistic sys-\ntem interact than that usually found in strat-\niﬁed accounts. Additionally, each higher-level\nstratum is seen as contextualizing the levels\nbeneath.\nThe organization of the Penman-style ar-\nchitecture version of systemic theory instan-\ntiates the stratiﬁcation as follows.\nNear-\nest the surface there are realization state-\nments of syntagmatic organization, or syntac-\ntic form.\nThese statements are classiﬁed in\nterms of their potential for expressing commu-\nnicative functions that are realized grammati-\ncally, such as asserting/questioning/ordering,\nactive/passive, etc.:\nthis denotes paradig-\nmatic organization and is represented in terms\nof a grammatical system network.\nThis or-\nganization captures the possible alternatives\nthat are available given any choices that\nhave already been made; i.e., a collection\nof ‘paradigms’ of the form ‘a linguistic unit\nof type A is either an A of functional sub-\ntype X, or an A of functional subtype Y, . . . ,\nor an A of functional subtype Z’ are given.\nAt each level these subtypes are disjoint and\nserve to successively classify linguistic units\nalong ever more ﬁnely discriminated dimen-\nsions.\nThis formulation of classiﬁcations in\nterms of increasingly ﬁne discrimination is\nin systemic-functional linguistics termed the\nprinciple of delicacy. The grammatical com-\nmunicative functions are then in turn moti-\nvated by semantic distinctions that classify se-\nmantic circumstances according to the gram-\nmatical features which are appropriate to ex-\npress those situations: this classiﬁcation is the\ncombined responsibility of choosers and in-\nquiries [Mann, 1983].\nFinally, the possibili-\nties for classiﬁcation that the inquiries have\nare deﬁned in terms of the abstract ontol-\nogy of the Upper Model. In relation to Fig-\nure 5, then, the Penman-style architecture\nrepresents a computational instantiation only\nfor the lower two strata and the relationship\nbetween them.\nWhile at a rather general level very simi-\nlar to the breakdown proposed by Bierwisch,\nthe systemic-functional account also goes into\nmore detail about the internal organization of\neach stratum. It is this feature which is largely\nresponsible both for the more abstract status\nthat has been achieved for the sorts of the Up-\nper Model and for the early adoption of the\nprinciple of motivating sources on the basis\nof the grammar.\nNot only is all grammati-\ncal variation captured by abstract choices be-\ntween minimal grammatical alternatives, but\nalso all such abstract choices must have ex-\nplicit motivations, or semantic conditions, de-\nﬁned. Only then is the grammar fully deﬁned\nas a resource for grammatical expression: we\nhave to know what each grammatical possi-\nbility is an expression of. This has naturally\ngiven rise to the notion of covering the gram-\nmar in terms of a set of motivations for each\nchoice that the grammar oﬀers. This is de-\npicted graphically in Figure 6. The categories\nnecessary for this motivational covering are\nthen organized into sorts in a subsumption\nlattice — thus deﬁning the Upper Model.\nIt is worth noting that this provides a\nvery strong methodology for interface ontol-\nogy construction. Until a grammar alterna-\ntion is explicitly connected into a motivational\nrelationship, the alternation is considered to\nbe only formally (in the sense of linguistic\nform) deﬁned. The grammar in fact acts as\na (highly structured) list of phenomena that\nrequire semantic motivation. In addition, the\nfunctional organization of the grammar itself\ngoes a long way towards providing a useful\npre-classiﬁcation of syntactic phenomena so\nas to be amenable to systematic semantic in-\nterpretation. The extra boost in abstraction\n25\nlexicogrammatical\nresources\nmotivation\ngeneralization\nmotivation\ngeneralization\nsemantic \nresources\ncontextual\nresources\nFigure 5: Stratiﬁcation with systemic-functional linguistics\nlexico–\ngrammar\nsemantics\nFigure 6: Covering the grammar semantically\n26\nthat the grammar oﬀers is responsible for the\nincreased level of abstraction that the Upper\nModel has already achieved.\nI have noted, however, that the Upper\nModel does not instantiate the full organi-\nzation required by the theory.\nSome of the\nconsequences of this have already been men-\ntioned.\nFor example, the upwards relations\nof the Upper Model to context has not been\nmodelled within Penman in terms of a ‘real-\nization’ relationship: domain models are di-\nrectly subordinated to the Upper Model hi-\nerarchy. I will return to this and some other\nproblems below.\nImportantly, since the full\ninput of the theory has not yet been taken\ninto account, we have available a number of\npossible directions for development that may\nprovide a far more sophisticated implementa-\ntion of both interface and conceptual ontolo-\ngies.\n4.3\nA comparative evaluation\nIn this section, I will apply the possible lin-\nguistic theoretical underpinnings that could\nbe provided for the diﬀerent ontology types in\norder to consider those ontology types more\ncritically. I will suggest here that there are\nclear reasons for dispreferring accounts that\nadopt a mixed ontology approach.\nSubse-\nquently, in the next section, I will discuss\npossible future developments for interface and\nconceptual ontologies drawing further on the\nconnections to theory established.\nWe have seen that the type of account based\non a style of argumentation such as that of\nJackendoﬀmanages to gain abstractness while\nstill maintaining contact with details of lin-\nguistic realization. I have noted that the in-\ncrease in abstraction is a generally necessary\nproperty for improving the functionality of\nnlp systems. One of the principle diﬀerences\nbetween such an account and the linguistic\ntheories supportive of interface ontologies was\nin the degree and explicitness of stratiﬁca-\ntion.\nOne can ask the question, therefore,\nis there any evidence for the more stratiﬁed\nview of the linguistic system? If it proves nec-\nessary, or beneﬁcial, to diﬀerentiate between\ninformation that is particularly linguistic and\nthe kind of information sought in accounts of\nreal-world, commonsense knowledge, then a\nmixed ontology will not be sensitive to this. A\nvery important issue to address is, therefore,\nwhether the selection between a mixed ontol-\nogy and a more diﬀerientiated set of interre-\nlated ontologies is one which is still open to de-\nbate, or arbitrary — or are there grounds for\ndeciding for one architecture over the other.\n4.3.1\nPopulating a mixed ontology\nIf we assume that we have an account such\nas that proposed by Jackendoﬀ, possibly aug-\nmented by a range of concepts from cognitive\nlinguistics with a more formally expressed re-\nlationship to the lexicogrammar, it is still the\ncase that there the resulting ontology is not\nyet very large. The number of general sorts\nthat occur in, for example, [Jackendoﬀ, 1990]\n(i.e., not the conceptual equivalents of lexical\nitems, which seem to be introduced freely),\nis less than 40: these include predicates such\nas event, state, be, orient, path, go,\nwith, from, to, towards, inchoative, re-\nact, affect, etc. Most conceptual items are\ndecomposed into these ‘primitives’.\nI will\nnot discuss whether or not these items are\ngood candidates psychologically for concep-\ntual primitives, but relying on this small set of\ncategories is unlikely to capture many general-\nizations of linguistic expression when a broad\nlexicogrammar is considered. If we include ex-\nperience such as that obtained within the de-\nvelopment of the lilog ontology or the Upper\nModel, many intermediate sorts will express\nuseful generalizations over distinct linguistic\npatterns.\nRelying on a smaller than neces-\nsary set of categories either misses general-\nizations or places more work on the mapping\nwith lexicogrammatical form.\nThe method-\nological question arises of how the sort hier-\narchy is to be extended beyond the very gen-\neral categories that most attempts at ontol-\nogy construction assume as basic on intuitive\ngrounds.\nThe primary source of evidence for exten-\nsion is the classiﬁcation of lexicogrammati-\ncal patterns.\nThis posits semantic features\nthat co-occur with particular classes of Lex-\nical Conceptual Structures. But these classes\nare constructed on the purely syntactic lin-\nguistic behaviour of the investigated lexemes.\nThis, while being the best methodology avail-\nable and one I have defended throughout this\npaper, cannot itself be expected to give rise\nto conceptual classes.\nOnly the assumption\nthat such semantic patterns are simultane-\n27\nously conceptual makes this plausible: there\nis no obvious connection to be drawn between\naspects of domain and commonsense knowl-\nedge and lexically derived categories.\nThe\nlatter are often subject to criticism for be-\ning too shallow even for an interface ontol-\nogy:\nthey must appear very unlikely can-\ndidates for a conceptual ontology.\nAs we\nhave found with the problems with the Upper\nModel (Section 3.3.1), there is no guarantee\nthat particular domain-motivated categories\nwill choose lexically-motivated categories that\nbelong to a consistent more general ontologi-\ncal type. More often items belonging to very\ndiﬀerent lexical classes are treated as seman-\ntically equivalent for speakers’ expressive pur-\nposes. Representing this in a single ontology\nthen requires that concepts may be consis-\ntently classiﬁed along the two dimensions si-\nmultaneously: which complicates the formal\nproperties of the resulting ontology consid-\nerably since exactly what may be inherited\nwhere becomes unclear.\nThis is shown concretely in the linguisti-\ncally motivated evaluation that [Lang, 1991]\nundertakes for lilog. There he examines the\nsorts proposed for the ontology according to\nthe kinds of motivations accepted for their in-\nclusion. He ﬁnds the following diﬀerentially\nmotivated sorts all combined in the single sub-\nsumption lattice:\n• ‘Conceptually based sorts’ which are in-\ncluded on extra-linguistic (conceptual)\ngrounds.\n• ‘Text base speciﬁc sorts’ which are con-\ncepts corresponding to special vocabulary\nitems required by the particular domain\nand text with which lilog as a project\nwas concerned.\n• ‘Sorts\nprojected\nfrom\nthe\ngrammar’\nwhich are notions found in the grammar,\nsuch as preposition, transferred to the on-\ntology.\n• ‘Sorts of mixed origin’ which are concepts\nwhere both extra-linguistic and linguistic\ncriteria are involved.\nThis mixing of motivations organizes itself\nloosely according to the vertical and horizon-\ntal dimensions in the hierarchy. Thus,\n‘The vertical structure of the sort hier-\narchy, which is based on the subsump-\ntion relation, draws mainly on the avail-\nability of corresponding linguistic la-\nbels categorized as nouns . . . or as verbs\n. . . However, the horizontal dimension\nof the sort hierarchy, that is the selec-\ntion of subsorts to be assigned to a com-\nmon supersort, is mainly determined by\nfeatures that emerge from our extra-\nlinguistic conceptual knowledge of ob-\njects and spatio-temporally speciﬁable\nevents or situations . . . ’ [Lang, 1991,\np466/7]\nLang shows the following problems for the\nresulting organization in a single subsump-\ntion lattice that this inconsistency, or variety,\nof motivations for concepts in the hierarchy\ncreates.\nFirst, since extra-linguistic or con-\nceptual criteria are less than well understood,\nthere is a degree of arbitrariness in the catego-\nrizations that appear. Second, it is never clear\nfrom the concepts that are found in the hier-\narchy alone whether they are to be expected\nto have a corresponding linguistic eﬀect or\nnot. Third, the co-existence of distinct kinds\nof concepts means that the precise meaning of\n‘subsumption’ with respect to particular cases\nis underspeciﬁed — diﬀerent kinds of concepts\nhave diﬀerent relations between their ‘wholes’\nand their ‘parts’ and until this is clariﬁed it\nis unclear what kind of subsumption actually\nholds. These diﬀerences entail diﬀerent formal\nproperties so that diﬀerent objects can call for\ndiﬀerent inheritance properties. Thus, for ex-\nample, a supposedly general ‘part-whole’ re-\nlation is intended sometimes as ‘is a compo-\nnent of’, sometimes as ‘is spatially included\nin’, somtimes as ‘pertains to’, sometimes as\n‘inalienable possession’, sometimes as ‘alien-\nable possession’, etc. This range of possibil-\nities makes the inferences that in fact follow\nfrom any statement in the ontology far more\ndiﬃcult to foresee and substantially compli-\ncates in any case any axioms for inference that\nare designed.\nThis can also be seen concretely in many\nversions of semantics where a mixed on-\ntology is relied upon — in order to han-\ndle the very ﬂexibility of the relationship\nbetween\nthe\nconcepts\nthat\nare\nto\nfunc-\ntion for the linguistic expression, and those\nwhich are not, complex and often uncon-\nstrained mechanisms are introduced:\nthe\n28\n‘projective inheritance’ of [Pustejovsky, 1991]\nand\nmany\ninstances\nof\n‘type\ncoercion’\nas\nused\nby,\ne.g.,\n[Sag and Pollard, 1991,\nPustejovsky, 1991] are probably prime exam-\nples of this, but there are many others.\nA\nmixed ontology is, therefore, a very weakly\nconstraining theoretical construct, which does\nnot provide optimal assistance either for the-\nory construction or for system construction.\n4.3.2\nStratiﬁcation\nThe just mentioned ﬂexibility of relationship\nbetween conceptual categories and the cate-\ngories that are determinative of their linguis-\ntic realization is a very typical property of a\nrelationship between linguistic strata.\nIt is\nthis very ﬂexibility, in fact, which provides the\nprimary linguistic evidence for stratiﬁcation.\nAs an example of this, consider the following\nissue of ontological design.\nRegardless of whether a mixed ontology is\nadopted or not, some portion of some on-\ntology is assumed which oﬀers an expression\nof the chunking that language expects and\ndemands of knowledge if it going to be ex-\npressible through the grammatical and lexi-\ncal resources of the linguistic system.\nOne\nquestion that can be asked, therefore, is: is\nthe information in a conceptual ontology that\nwill support this chunking already organized\nin this way or not?\nIf it is then it will\nbe straightforward to construct a mechanism\nsuch as that suggested by Jackendoﬀabove,\nwhereby one simply ‘takes a view’ on some\nconceptual structure and already has a spec-\niﬁcation of the semantic predicate-argument\nstructure which can in turn control the gram-\nmar and lexis to produce appropriate results.\nIf not, however, then some reorganization of\nthe structure will be necessary.\nIn all ex-\namples that are presented of alleged concep-\ntual structures that are already appropriate\nfor direct lexicogrammatical realization, e.g.,\nby viewing as predicate-argument structure,\nwe can make the following observations:\nFirst, the lexical items and class of gram-\nmatical patterns appropriate is already so\nhighly constrained as to follow directly from\nthe expression; for example,\n[State orient ([Thing weathervane], [Path\nnorth])]\nas one reading for the sentence: The weath-\nervane pointed north [Jackendoﬀ, 1990, p74].\nCertain variability in lexicogrammatical ex-\npression will be produced by the mapping\nrules of syntax formation, but other decisions,\nincluding: the choice of word for the concept\nweathervane given that the hearer might not\nknow what a weathervane is, or that the sen-\ntence may be uttered among world-experts\non the subject of weathervanes who would\nnormally select a far more restrictive descrip-\ntion, etc. have already been built into the de-\nscription. Widely diﬀering selections of pos-\nsible expression according to text type, reg-\nister, formality, situation, time availability\n(cf. [Hovy, 1988, Bateman and Paris, 1]) are\nexcluded.\nSecond, the granularity of the correspond-\ning language has also been built into the de-\nscription. For example, we know that a sen-\ntence is going to be produced (or if the linking\nrules are good enough: a sentence or a nom-\ninalization) rather than a short discussion of\nthe wind’s eﬀect on an object whose position\nof equilibrium under the pressure of the wind\nserves as an indication of the wind’s direction.\nA nice example22 of maximal ﬂexibility here\nmight be the diﬀerence, for example, in the\nlanguage produced in response to the concep-\ntual real-world category beer for the purposes\nof a dictionary entry, e.g.,\n‘Beer is a bitter alcoholic drink made\nfrom grain. There are a lot of diﬀerent\nkinds of beer.’\n[Collins cobuild En-\nglish Language Dictionary, 1987]\nand that produced for the purpose for an entry\nin an industrial chemical encyclopedia, which\ngoes on for 40 pages.\nThe response to both of these problems\nwithin the semantico-conceptual approach is\nstraightforward: the diﬀerences are expressed\nbeforehand in the semantico-conceptual orga-\nnization and are produced by conceptual pro-\ncesses for information organization and man-\nagement. But this misses the generalization\nthat regardless of the information to be ex-\npressed that same linguistic granularity is im-\nposed: there will be a set of descriptions of\nsome predicate with an argument structure,\nincluding speciﬁcations of participants and\ncircumstances. The two sentences concerning\nbeer in the dictionary and the hundreds in the\n22Due to Karin Haenelt.\n29\nencyclopedia all exhibit the same kind of orga-\nnization. Knowledge is variable scale, but lan-\nguage is predominantly ﬁxed-grain,23 as de-\nﬁned by the grammar. This means that for\nall the knowledge available in the semantico-\nconceptual ontology, there need to be con-\nstruction mechanisms available which convert\nsome selected fragment of the information, of\nany scale, and produce an appropriate sized\nchunk of semantico-conceptual structure for\nmotivating a sentence.\nWith unconstrained inferencing across the\nknowledge\nbase\nthis\nmay\nbe\nachievable\nby\ninheriting\nconstraints\nback\nfrom\nthe\ngrammar and checking the equivalence of\nconstructed semantico-conceptual structures\nwith the originally selected fragment.\nBut,\ncrucially, for all such selected fragments, the\nsame class of ‘semantico-conceptual’ para-\nphrases will be potentially available:\ni.e.,\nthose licensed by their grammatical express-\nability.\nFurthermore, also regardless of the\noriginally selected semantico-conceptual frag-\nment, the lexico-grammatically licensed set\nof ‘semantico-conceptual’ speciﬁcations gov-\nern speciﬁable sets of inferences that oper-\nate only on such speciﬁcations:\nfor exam-\nple the inferences that determine the tex-\ntual variations that are appropriate when\nrealizing the speciﬁcation lexicogrammati-\ncally [Bateman and Matthiessen, to appear],\nthat certain abstract semantic classiﬁcations\napply for which there is no conceptual ev-\nidence [Schriefers, 1990], and others.\nThus,\nnot representing this distinguished set sepa-\nrately fails to capture a signiﬁcant generaliza-\ntion about the organization of the linguistic\nsystem as a whole.24\n23Apart from the resources for combining clauses,\nnominal groups, etc. into ‘complexes’, which are not\nrelevant to the current argument.\n24It is also engenders dubious nlp system design;\nfactoring out the commonalities in a separate stratum\nis analogous to the following application of object-\noriented programming:\n“In an object-oriented application . . . the\nsystem uses predeﬁned mappings from ob-\njects to the routines that know how to pro-\ncess those objects (or can choose among dif-\nferent routines depending on the context).\nThe eﬃciency of using predeﬁned mappings\nfor known types comes in drastically reduc-\ning or entirely eliminating search; the onus\nis put on the developer to deﬁne the de-\ncisions available to a type at each level,\nrather than presenting all options at all\ntimes and letting a search procedure ﬁnd\nFinally, it is worth emphasizing that this\nﬂexibility between strata is typical and not\nunique to the relation between semantics and\nconceptual levels of representation. The re-\nlationship between, for example, the Upper\nModel and the lexicogrammar already ex-\nhibits much of the same kind of ﬂexibility. For\nexample, the expressive resources of the gram-\nmar of nominal groups is not restricted to the\nsingle grain-size of sorts that are subtypes of\nan Upper Model sort object. It is equally pos-\nsible to realize Upper Model classiﬁed events\nas nominal groups or conﬁgurations of events\nas single clauses if the textual conditions are\nappropriate. [Bateman and Paris, 1] present\nother examples of this theoretical ﬂexibility\nfor other categories in the grammar. It is not\nat all surprising given the theoretical similar-\nity, therefore, to ﬁnd exactly this kind of ﬂex-\nibility again between the sort lattice of the\nsemantic ontology and that of the conceptual\nontology.\nThis discussion of stratiﬁcation is summa-\nrized in Figure 7. Here we see three strata and\nthe repeated variability in expression that any\nselected semantic speciﬁcation has. Crucially,\nthe common, reoccuring coding possibilities\nthat are available for all elements from the\nconceptual stratum are not repeated at that\nlevel, but are factored into a single statement\nat the level of the semantic interface with a\nmapping from sorts at the conceptual stra-\ntum to sorts at the interface stratum.\nNot\nrepresenting this generalization both guaran-\ntees a complication of the theory and makes\na usable nlp system based on the theory un-\nlikely. Again, the power of the theory to bring\nmethodological and contentful constraints to\nbear on system design is compromised.\n5\nSome\nPrinciples\nand\nMethods; and some for-\nmer puzzles resolved\nThe discussion up to this point has attacked\nmixed ontologies on the basis that they are\ninternally inconsistent, and has criticised the\nnon-statiﬁcational linguistic accounts under-\nlying such mixed ontologies on the basis that\nthe best one.” [Meteer, 1989, p6]\nThis is also one property of using an interface ontology\nsuch as Meteer’s or the Upper Model.\n30\nA\nB\nC\nA\nB\nC\nconceptual\ngrammar\nNo Stratification\nsemantics\nconceptual\ngrammar\nWith Stratification\n1\n2\n3\n1\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n3\n3\n3\n3\n3\n2\n3\nFigure 7: Capturing generalizations via stratiﬁcation\nthey fail to capture theoretically important\nand practically useful generalizations. Both\nweaknesses have one consequence in common:\nthey provide a seriously reduced set of con-\nstraints for ontology design and construction.\nSince one purpose of this paper is to sug-\ngest principles and methodologies for ontol-\nogy construction, mixed ontologies and under-\nstratiﬁed linguistic accounts are clearly to be\navoided. The kinds of ontologies most appro-\npriate for nlp systems and for which linguis-\ntic support needs to be sought can now be\nrestricted to the following two types.\n• Type Oi: an abstract semantic organiza-\ntion underlying our use of grammar and\nlexis that is motivated on essentially lin-\nguistic grounds and that acts as a com-\nplex interface between lexicogrammatical\nresources and higher-level strata in the\nlinguistic system — the categories of this\ninterface should be maximally general,\ni.e., apply across distinct real-world situ-\nations, but speciﬁc enough to maximally\nconstrain possible lexicogrammatical ex-\npression.\n• Type Oc:\nan abstract organization of\nreal-world knowledge (commonsense or\notherwise) that relates downwards to the\ninterface to lexicogrammar.\nWith these restrictions in place, I will now\ngo further and suggest some particular guide-\nlines for ontology construction.\nIn order to\ndo this, however, it is also necessary to make\nsome further commitments to the kinds of in-\nformation that will be made available at par-\nticular levels in the linguistic system. The rea-\nson for this is that the linguistic, and particu-\nlarly lexico-grammatical, constructs are essen-\ntial for guiding ontology design. This follows\nthe increasingly wide range of linguistic the-\nories that are returning to the position that\nthe relation between grammar and semantics\nis not arbitrary; we saw a selection of these\nin Section 4 above, e.g., [Langacker, 1987,\nTalmy, 1987,\nWierzbicka, 1988,\nJackendoﬀ, 1983, Halliday, 1978].\nIf we ac-\ncept this, then it is also to be accepted that\nthe selection of particular accounts of lexi-\ncogrammar has consequences for the subse-\nquent ontology design.\nSince such conse-\nquences cannot be avoided, it makes sense to\nmake selection decisions in ways which will\nmaximally help in the task of ontology con-\nstruction overall. I will distinguish between\n31\ndecisions in the following two areas:\n• type of grammar\n• contents of grammar\nand will make some ﬁrm suggestions for the\nformer and discuss the consequences of diﬀer-\nences that arise in the latter.\nFirst, we can note that the most successful\ninterface ontology developed so far is prob-\nably that of the Upper Model.\nThe Upper\nModel has achieved both a detailed account\nand a generally applicable account. We can\nask, then, what is it about its underlying the-\noretical organization that let this occur? Sec-\nond, we can further note that although the\nUpper Model is the most detailed instantia-\ntion of an ontology of type Oi that has been\ndeveloped, is nevertheless not a full instan-\ntiation of the theory on which it is based.\nIt is therefore worthwhile considering brieﬂy\nwhat additional constraints the theory could\nbring to bear if it were to be more fully im-\nplemented.\nThe kind of grammar on which the ab-\nstractions\nproposed\nin\nthe\nPenman\nUp-\nper Model is easily classiﬁed.\nIt is a\nparadigmatic-functional grammar exhibiting\nthe standard Hallidayan metafunctional diver-\nsiﬁcation [Halliday, 1985, Matthiessen, 1990,\nMatthiessen and Bateman, 1991].\nThis means that it is organized, ﬁrstly around\nchoice — the paradigms of grammatical con-\nstructions that stand in functional opposition\n— and second around a factorization of that\nchoice according to its semantic motivation:\nis the choice to do with the propositional con-\ntent of the linguistic entity to be classiﬁed\n(ideational), is the choice to do with the tex-\ntual placing of the linguistic entity to be clas-\nsiﬁed (textual), or is the choice to be classiﬁed\nas to do with the interpersonal relationship\nbetween speaker and hearer or with the atti-\ntude of the speaker towards the information\nexpressed by the linguistic entity (interper-\nsonal). The motivations for the choices pro-\nvides hypotheses concerning the sorts neces-\nsary for controlling those choices.\nThe Up-\nper Model has been derived by considering\nmotivations for those choices exclusively as-\nsigned to the ideational metafunction: there is\nno mixing of categories across metafunctional\ndomains.25\nThis builds into the design of an ontology\nmotivated in such a way as the Upper Model\nthe following features.\nFirst, we require an ontology that is sig-\nniﬁcantly more abstract than syntactic real-\nization classes. I have already suggested how\nthis has been achieved with the Upper Model.\nThe grammar, being organized in terms of a\nfunctional classiﬁcation of possible constraints\non constituency structure, is already more\nabstract than constituency structure per se.\nFurther classiﬁcation across the paradigms\nuncovered is then automatically more abstract\nand achieves a generalization across particu-\nlar lexico-grammatical contexts that supports\na greater ﬂexibility of expression of input\nexpressions.\nThe strict relationship to the\ngrammatical stratum also makes sure that the\nkinds of mixed sorts that [Lang, 1991] ﬁnds\nand criticises in the lilog hierarchy cannot\noccur: either an (interface, i.e., semantic) on-\ntological category has a speciﬁed consequence\nfor lexico-grammatical expression or it is not\naccepted.\nSecond, given the stratiﬁcation suggested\nby the theory the Upper Model is automat-\nically only the ‘next level up’ in the linguistic\nsystem: it is an ontology strongly connected\nto grammar below. It does not, by itself, pro-\nvide the necessary organization of higher level\nontologies. Thus, in short, we see that an or-\nganization closely reminiscent of a two-level\nsemantics is automatically achieved, and that\nboth levels require ontologies.\nThird, we have seen that it is a design\ngoal that an ontology be as general as pos-\nsible — that it helps with classiﬁcation across\ndomains, tasks, and applications, but also\nbe substantial enough to provide a rich scaf-\nfolding for domain description.\nThis raises\nthe question:\nHow can we guarantee that\na proposed ontology is as general as we re-\nquire? We can now see that ontologies such\nas the Upper Model, which are based on\nmotivations from grammar, are guaranteed\nto have the domain-independence required\n25Although it is perfectly possible to imagine ap-\nplying the same ‘grammar-as-ﬁlter’ methodology on\nunderlying motivational ontologies as carried out for\nthe ideational metafunction — cf. [Bateman, 1991] for\nexamples of this applied to the textual metafunction\nand [Matthiessen and Bateman, 1991] for general dis-\ncussion — the resulting organizations of information\nhave very diﬀerent properties.\n32\nof them.\nSince ontological categories are\nmotivated by the grammatical distinctions\n(and not by more arbitrary lexical collec-\ntions found in a given domain), those cate-\ngories are forced to be at least as general as\nthe grammatical categories. It is, therefore,\nvery unlikely that [Klose and von Luck, 1991,\np462]’s claim that the lilog ontology has a\n‘more domain-independent status’ than the\nearly version of the Upper Model described\nin [Mann et al., 1985] would apply to current\nversions of the Upper Model.\nBut we can go further and move beyond\nthe kind of generalizeability that refers sim-\nply to domain-independence — which is gen-\neralizeability ‘upwards’ in the linguistic sys-\ntem, and beyond generalizeablity across the\nlexicogrammar — which is generalizeability\n‘downwards’ in the linguistic system. When\nwe also consider the metafunctional organi-\nzation of the linguistic system posited by\nsystemic-functional theory, then we can see\nthat generalizations both across ‘text in-\nstances’ and across ‘speech functions’ are also\nguaranteed — i.e., generalizations ‘horizon-\ntally’ across the same stratum of the linguistic\nsystem. This is depicted graphically in Fig-\nure 8. These constraints rule out certain other\npotential sorts from the ontology, e.g., sorts\nconcerned with the particular appearance of\nan entity at a given position in a text or with\nthe speaker’s attitude towards an event. Cer-\ntain of the sorts found in [Meteer, 1989]’s in-\nterface ontology are good examples of the for-\nmer kind. Having such sorts requires reclas-\nsiﬁcation of domain information whenever a\ndomain object is used in a text, since the tex-\ntual statuses of domain objects changes over\nthe development of a text — i.e., from new to\ngiven, from theme to rheme, etc. This change\nof course needs to be represented: the point\nis that representing such information in the\ninterface ontology again mixes very diﬀerent\nkinds of information — although this time on\na ‘horizontal’ dimension across the linguistic\nsystem rather than a ‘vertical’ one.\nThe kind of grammar that we employed as\nthe initial motivation for guiding the develop-\nment of the Upper Model has, therefore, gone\na long way towards ensuring that the prop-\nerties desired of ontologies obtain.\nBut an\narea of ﬂexibility in the description then arises\nfrom the depth of grammatical description,\ni.e., the contents, rather than the type. Par-\nticularly within the systemic-functional ap-\nproach, lexical descriptions are seen as more\nspeciﬁc versions of grammatical descriptions\n— there is no diﬀerence in kind. Thus, if we\npush lexicogrammatical description further in\nthe direction of lexis, we automatically push\nfurther the depth of motivating semantic on-\ntology constructs that are needed.\nThis bi-\nfurcation in potential description needs more\ntheoretical work before we can make any ﬁrm\nstatements about whether it is more helpful\nto pursue one at the expense of the other, or\nwhether they should be pursued in parallel as\nhas been the case with the more general area\nof the grammar.\nWe can now also consider some possible im-\nprovements and explanations for some awk-\nward phenomena/intuitions that have previ-\nously hindered ontological engineering.\nFor\nexample, if there is a stratiﬁcation of the kind\nargued for, why is it that suggestions for con-\nceptual structure that have been put forward\nin a number of approaches appear also to be\ncandidates for representation as sorts in the\ninterface ontology? — When the categories of\nthe Upper Model, for example, are examined,\nmany similar classes to the proposed ‘concep-\ntual’ ontology work are to be found.\nTo\ngive\na\nconcrete\nexample\nof\nthis,\n[Lang, 1991, p474], after careful discussion\nconcerning the problems of a mixed ontol-\nogy, deﬁnes some basic assumptions con-\ncerning the structure of the conceptual on-\ntology\ndrawn\nfrom\nearlier\nwork,\ninclud-\ning [Bierwisch and Lang, 1989]. With respect\nto these assumptions, he outlines the following\nset of conceptual domains which are to form\nbasic subsorts of the conceptual ontology:\nD1: objects;\nD2: substances; D3: locations;\nD4: time intervals; D5: events;\nD6: attitudes\nWe can also note here similarities with some\nof the classes above from [Jackendoﬀ, 1983,\nJackendoﬀ, 1990,\nLangacker, 1987,\nTalmy, 1987], etc.\nBut these are also sorts\nalready found, for example, in the Penman\nUpper Model, where they have been entered\npurely on the grounds that they are necessary\nto directly constrain possible grammatical re-\nalizations. Is it the case that the claim we saw\nabove by [Gust, 1991, p133] that: ‘there are\ncontinuous variations between semantic forms\nand conceptual structures’ is, after all, true?\nCan we introduce strict stratiﬁcation and still\n33\nontology\ncontext\ntext\nresources\ninteraction\nresources\nlexicogrammar\n\u0001\u0003\u0006\u0003\b\u0002\u0005\u0004\u000b\u0002\n\u0004\u0007\u0006\t\nFigure 8: Capturing generalizations via metafunctionality\naccount for the intuition that these concepts\nindeed function at diﬀerent strata?\nLang already suggests that there may be\ncertain genuinely ‘linguistic’ features that\nfunction deﬁnitionally for features at the ‘con-\nceptual’ stratum:\n‘. . . the representation of nouns like\nOfen [oven], Fahrzeug [vehicle], Boot\n[boat] in the lexicon contains a spe-\nciﬁc component purpose (hence, an el-\nement of our linguistic knowledge) by\nmeans of which the sort Nutzgegenstand\n[article for practical use] in the knowl-\nedge base is being accessed. This is but\none example of how linguistic aspects\nof lexical representation can be made\nuse of in deﬁning ontological sorts in the\nknowledge base.’ [Lang, 1991, p470]\nOther ‘genuine linguistic features’ that Lang\nsuggests for the basis of the ontological dis-\ntinctions include: ‘bounded object’ vs. ‘non-\nbounded object’, ‘concrete object’ vs.\n‘ab-\nstract object’ — both very similar to other\ntheoretical accounts. We can now go further\nand explain the relation between the linguistic\n(semantic) ontology types and the conceptual\nontology types as follows.\nAll of the reasoning that we have applied\nto the development of the Upper Model ontol-\nogy with respect to its motivation in the lexi-\ncogrammar can be applied precisely to the re-\nlation between the Upper Model ontology and\nsome higher stratum ontology. This follows as\na consequence from the theoretical statement\nof the nature of realization within the strat-\niﬁed linguistic account. This means that we\nwill need to ﬁnd motivations for the seman-\ntic interface ontology sorts.\nIt also means,\nhowever, that we can make use of the realiza-\ntion relation starting from the standpoint of\nthe higher stratum and interpret the status of\nthe semantic interface ontology as generalizing\nacross diﬀerent conceptual stratum situations;\ncf. Figure 5. Thus, for both the lexicogram-\nmar with respect to the semantic interface on-\ntology, and for the semantic interface ontology\nwith respect to the conceptual ontology, it is\nlikely that the more general intra-stratal or-\nganization of the lower stratum is likely to be\nechoed in the overall intra-organization of the\nhigher stratum.\nThis gives us the observed\nlink between constructs that are motivateable\nas general semantic concepts and constructs\nthat appear to organize the conceptual hier-\narchy. There is, then, no ‘mixing’ of the cat-\n34\negories of diﬀerent strata, there is just a res-\nonance or echo of categories at one stratum\ntaken up at another.\nGiven both this theoretical and practi-\ncal\nbinding\nof\nthe\ncontents\nof\nthe\ndif-\nferent\nstrata,\nis\nit\nclear\nwhy\nthere\nis\nthen a certain tension between strata —\nas\n[Klose and von Luck, 1991,\np462]\nnote\nfrom their experience with the lilog ontol-\nogy:\n‘The tension between linguistic and in-\nferential demands on the modeling is\nalive and forces compromises on both\nsides.’\nI have suggested that the kind of view of re-\nalization between strata found in systemic-\nfunctional linguistics, where there is both a\npractical and a theoretical ‘pulling’ in both\ndirections — upwards to context and down-\nwards to (experiential) lexicogrammar, of-\nfers an appropriate way of operating within\nthis tension between strata.\nThe resulting\nmethodology then uses the tension to help\nconstrain organization decisions for the con-\nstruction of interface ontologies that are use-\nful for nlp and to remove the need for genuine\n‘compromises’ where an inappropriate cate-\ngory is postulated at one level because that\nlevel is insuﬃciently functionally diﬀerenti-\nated from others.\nIt is clear, however, that we know a great\ndeal more about possibilities for ontologies of\ntype Oi than we do about ontologies of type\nOc.\nMoreover, given the results of the last\nsection, perhaps we know even less than we\nthought — clearly conceptual categories are\nnow sometimes best reappropriated to a more\nabstract semantic type.\nThis is a less than\nideal situation — particularly given the view\nof stratiﬁcation shown in Figure 5 and the es-\ntablished dialectic between strata.\nBecause\nthe realization relationship between strata is\nbi-directional, we should be able to use a\nhigher-strata to constrain our accounts at a\nlower-strata. But the fact that we know very\nlittle about the higher-strata in this case re-\nmoves one source of possible constraint.\nFinally, here, however, I will draw atten-\ntion to one interesting consequence for the\nstatus of the higher-stratum ontology when\nwe take into account the bi-directionality of\nthe inter-stratal relationship.\nSince there is\nno diﬀerence assumed in the theoretical sta-\ntus of the levels related by the interstratal re-\nlationship, one might ask how it is that the\ninterface ontology is termed ‘linguistic’ and\n‘semantic’, whereas the higher-stratum ontol-\nogy is ‘non-linguistic’ and ‘conceptual’. I be-\nlieve that a far more appropriate view of the\nrelationship is as depicted graphically in Fig-\nure 9. All strata that stand in an interstratal\nrelationship of the kind explored and used in\nthis paper should be seen as semiotic levels\nof greater and lesser degrees of abstraction.\nThe conceptual ontology thus becomes more\nof a contextual ontology, with context being\ninterpreted in the sense of a level of social\nsituation — closely in line with, for exam-\nple, [Halliday, 1978]. There is, then, the ad-\nditional question of how this entire complex\nof inter-related levels of semiotic descriptions\nrelates to the supporting conceptual system\nof human psychology. This is probably a very\ndiﬀerent kind of relation than realization —\nalthough it will probably again turn out to be\na dialectic relationship rather than a one-way\ndetermination. This puts us in the position\nto criticise some of the conceptual sorts pro-\nposed by Lang on exactly the same grounds\nthat he has criticised mixed ontologies. For\nexample, alongside the above mentioned do-\nmains, all of which may be more plausi-\nbly ground in the conceptual/perceptual sys-\ntem, [Lang, 1991, p474] places: ‘social insti-\ntutions (law, administration, marriage, edu-\ncation)’ and communicative behaviour (eti-\nquette, conversation, group dynamics). Such\na mixed set of sorts is unlikely to form a very\nstable or usable ontology: it is probably cru-\ncial to begin to reﬁne further our levels of\nontology, and their interactions, so that the\nmistakes made at the least abstract levels of\nontological engineering are not just repeated\nagain, at the next level ‘up’. More detailed\nstatements must, however, be left to future\nresearch!\n6\nSummary,\nconclusion\nand ﬁnal words\nThis discussion of this paper has considered\nthe notion of ‘ontology’.\nStarting from the\nview that an ontology is an organization of\nthe world — which has been approached\nby ‘naive physics’, ‘conceptual dependencies’,\n35\nPhonology\nLexicogrammar\nSemantics\nContext\nConcepts\nConceptual World Knowledge\nLinguistic\nConceptual\nPhonology\nLexicogrammar\nSemantics\nConceptual World Knowledge\nLinguistic\n‘Conceptual’\n‘quasi–stratal’\nFigure 9: The relationship between semiotic descriptions and conceptual representation\n‘commonsense (meta)physics’, and others — I\ndrew attention to the fact that such accounts\ndo not bring strong methodological and sub-\nstantive constraints to bear on ontology con-\nstruction. Also unclear is the relationship of\nsuch ontologies to language. The gap is of-\nten so large that this level is too abstract\nto have any direct relationship to required\nforms of expression.\nContrariwise, this gap\nalso leads to a weakening of the discriminative\npower of the constraints that can be brought\nto bear by linguistic patternings. Concretely,\nthen, one cannot, for example, generate nat-\nural language directly from such levels of de-\nscription without resolving, or ‘ﬁxing’ an im-\nmense number of degrees of freedom that re-\nmain unaddressed (often quite rightly, if this\nis seen as a conceptual ontology) in the on-\ntology itself. Much of the work that an nlp\nsystem requires to be done is, therefore, sim-\nply not taken into consideration by the ab-\nstract ontology. Such ontologies are also, be-\ncause of their abstractness, diﬃcult to popu-\nlate reliably — if sizeable and potentially dis-\ntributed resource construction is undertaken,\nas it increasingly is, then this virtually guar-\nantees poor intercoder consistency. In short,\nsuch ontologies are of very limited value for\nnlp work.\nThese problems have been noted by some\nof those who have sought principles for on-\ntology design (cf. [Skuce and Monarch, 1990])\nand those who need real shareable resources\n(as for example in machine translation —\ncf. [Steiner and Reuther, 1989]). The only so-\nlution that has been found to this endeavor is\nto place more reliance on language as a source\nof constraint. For this reason, then, views on\nlanguage and the organization of the linguis-\ntic system become crucial for ontology design\nthat is appropriate for nlp. Moreover, only by\ntaking views on the linguistic system that are\nmaximally supportive of the functionalities re-\nquired of ontologies can we avoid problems of\nlack of abstractness (i.e., being dominated by\nlinguistic form) and problems of too much ab-\nstractness (i.e., being dominated by semantic\ntheories of particular areas that lack connec-\ntion to linguistic form). In short, ontological\nengineering faces the following dilemma: in-\nterface ontologies\n• need to be abstract, large-scale, re-usable\ninformation classiﬁcation devices,\n• but they cannot be too abstract,\n36\n• or too near syntax,\n• and need to be constrained from lan-\nguage.\nThe theoretical assumptions and resulting or-\nganizational decisions that I have pursued in\nthis paper appear to oﬀer a very practical way\nof preceding within this state of aﬀairs. I have\nalso shown that several other beneﬁcial prop-\nerties for nlp systems are derivable from the\nabstract organization of the linguistic system\nthat systemic-functional theory posits.\nThe paper has presented for broader debate\na round of discussion that begun in the con-\ntext of the developing ontology of the Penman\ntext generation system.\nThis work, begin-\nning with the pre-computational descriptive\naccount, called the Bloomington Lattice by\nHalliday and Matthiessen has passed through\nseveral instantiations in computational form.\nNow future work will have again consider\nbringing together the linguistic descriptive\naccount — reworked to a new level of de-\ntail in [Halliday and Matthiessen, to appear]\n— and the computational model. It is to be\nhoped that this approach will build on the for-\nmer success of the Upper Model, simultane-\nously moving us in some of the directions that\nI raised as responses to problems with the Up-\nper Model. Thus, I have not suggested that\nthe Upper Model we ﬁnd in Penman is the\n‘general solution’ to ontological engineering —\nthere are many more criticisms to be made of\nthis ontology, again mostly concerning the ex-\ntent to which it succeeds as an instantiation of\nthe theoretical principles that underlie it. The\nfunction of the ontology is also more ﬁnely cir-\ncumscribed than many others — but again\nstrictly according to the underlying theory.\nWe are not yet at a stage where an ontology\ncan be accepted, even pragmatically for the\nneeds of current nlp systems, as ‘complete’:\nwhat is more at issue is the development of ap-\npropriate methodologies for constructing on-\ntologies, and here again constraints oﬀered by\nthe linguistic system are of paramount impor-\ntance.\nThe linguistic system, when viewed\nappropriately, gives a rich multidimensional\nset of constraints on adequate and appropriate\ndesigns for computational systems. The prin-\nciple dimensions applied in this paper were\nthose of strata and metafunctions. This by no\nmeans exhausts the possible input of the the-\nory, however. For further dimensions of the\ntheory, see [Matthiessen and Bateman, 1991];\nfor additional examples of using these dimen-\nsions to constrain computational system de-\nsign, see [Bateman et al., 1992]. I hope that\nthe paper has suggested some of the beneﬁts\nof employing such linguistic motivations, and\nthat further attempts to apply wider sets of\nmotivations will help us in the future.\nAcknowledgments\nThis paper is based on the work of the nat-\nural language group at ISI, including over\nthe years the input of Bill Mann, Ed Hovy,\nChristian Matthiessen, Bob Kasper, Johanna\nMoore, C´ecile Paris, Richard Whitney, and\nRobert Albano. Further theoretical discussion\nwith Erich Steiner, J¨org Sch¨utz, and Cornelia\nZelinsky-Wibbelt (IAI – Saarbr¨ucken), Elisa-\nbeth Maier, Elke Teich, Renate Henschel and\nLeo Wanner (IPSI), Martin Emele and R´emi\nZajac (IMS – Stuttgart) and with participants\nat the Technical University of Berlin Interna-\ntional Workshop on ‘Text Representation and\nDomain Modelling’ (October 1991) and of a\nKIT Projekt Kolloquium (TU Berlin; Febru-\nary 1992) have also helped the development\nof the discussion signiﬁcantly.\nThe particu-\nlar opinions expressed in the paper, and es-\npecially their deﬁciencies, remain however my\nresponsibility.\nReferences\n[Allgayer et al., 1989] J¨urgen\nAllgayer,\nKarin\nHarbusch, Alfred Kobsa, Carola Reddig, Nor-\nbert Reithinger, and Dagmar Schmauks. Xtra:\na natural-language access system to expert sys-\ntems. International Journal of Man-Machine\nCommunication, 1989.\n[Bateman and Matthiessen, to appear] John\nA.\nBateman and Christian M.I.M. Matthiessen.\nUncovering the text base. In Hermann Bluhme\nand Hao Keqi, editors, Selected Papers from\nthe International Conference on Research in\nText and Language, Xi’an Jiaotong University,\nXi’an, P.R. China, 29-31 March 1989. Xi’an\nJiaotong University Press, Xi’an, People’s Re-\npublic of China, to appear.\n[Bateman and Paris, 1] John A. Bateman and\nC´ecile L. Paris.\nPhrasing a text in terms\nthe user can understand.\nIn Proceedings of\nthe Eleventh International Joint Conference on\n37\nArtiﬁcial Intelligence, Detroit, Michigan, 1.\nIJCAI-89.\n[Bateman et al., 1990] John\nA.\nBate-\nman, Robert T. Kasper, Johanna D. Moore,\nand Richard A. Whitney. A general organiza-\ntion of knowledge for natural language process-\ning: the penman upper model. Technical re-\nport, USC/Information Sciences Institute, Ma-\nrina del Rey, California, 1990.\n[Bateman et al., 1991] John A. Bateman, Chris-\ntian M.I.M. Matthiessen, Keizo Nanri, and\nLicheng Zeng. Multilingual text generation: an\narchitecture based on functional typology. In\nInternational Conference on Current Issues in\nComputational Linguistics, Penang, Malaysia,\n1991. Also available as technical report of the\ndepartment of Linguistics, University of Syd-\nney.\n[Bateman et al., 1992] John Bateman, Elisabeth\nMaier, Christian Matthiessen, and Cecile Paris.\nGeneration systems design:\nIssues of mod-\nularity.\nTechnical report, GMD, Integrated\nPublication and Information Systems Institute,\nDarmstadt, Germany, 1992. forthcoming.\n[Bateman, 1989] John A. Bateman. Upper mod-\nelling for machine translation: a level of ab-\nstraction for preserving meaning. Technical Re-\nport Eurotra-d Working Papers, No. 12, In-\nstitut f¨ur Angewandte Informationsforschung,\nSaarbr¨ucken, West Germany, 1989.\n[Bateman, 1990a] John A. Bateman.\nFinding\ntranslation\nequivalents:\nan\napplication\nof\ngrammatical metaphor.\nIn 13th. Interna-\ntional Conference on Computational Linguis-\ntics (COLING-90), volume II, pages 13–18,\nHelsinki, Finland, 1990.\n[Bateman, 1990b] John A. Bateman.\nUpper\nmodeling:\norganizing knowledge for natural\nlanguage processing.\nIn 5th. International\nWorkshop on Natural Language Generation, 3-\n6 June 1990, Pittsburgh, PA., 1990. Organized\nby Kathleen R. McKeown (Columbia Univer-\nsity), Johanna D. Moore (University of Pitts-\nburgh) and Sergei Nirenburg (Carnegie Mellon\nUniversity).\n[Bateman, 1991] John A. Bateman.\nUncover-\ning textual meanings: a case study involving\nsystemic-functional resources for the genera-\ntion of Japanese texts.\nIn C´ecile L. Paris,\nWilliam R. Swartout, and William C. Mann,\neditors, Natural language generation in arti-\nﬁcial intelligence and computational linguis-\ntics. Kluwer Academic Publishers, July 1991.\nPresented at the Fourth International Work-\nshop on Natural Language Generation. Santa\nCatalina Island, California, July, 1988.\n[Bierwisch and Lang, 1989]\nManfred Bierwisch and Ewald Lang, editors.\nDimensional adjectives. Grammatical structure\nand conceptual interpretation. Springer-Verlag,\nBerlin, 1989.\n[Bierwisch, 1982] M. Bierwisch. Semantische und\nkonzeptuelle Repr¨asentation lexikalischer Ein-\nheiten. In R. Ruˇziˇcka and W. Motsch, editors,\nUntersuchungen zur Semantik, pages 61 – 99.\nAkademie-Verlag, Berlin, 1982.\n[Bosch, 1991] Peter Bosch. The Bermuda trian-\ngle: natural language semantics between lin-\nguistics, knowledge representation, and knowl-\nedge\nprocessing.\nIn O. Herzog and\nC.-\nR. Rollinger, editors, Text understanding in\nlilog:\nintegrating computational linguistics\nand artiﬁcial intelligence, Final report on the\nIBM Germany lilog-Project, pages 243 – 258.\nSpringer-Verlag, Berlin, 1991. Lecture notes in\nartiﬁcial intelligence, 546.\n[Brachman and Schmolze, 1985] Ronald\nJ.\nBrachman and J. Schmolze.\nAn overview of\nthe kl-one knowledge representation system.\nCognitive Science, 9(2), 1985.\n[Calder et al., 1989] Jo Calder, Mike Reape, and\nHenk Zeevat. An algorithm for generation in\nuniﬁcation categorial grammar. In Proceedings\nof the 4th Conference of the European Chapter\nof the Association of Computational Linguis-\ntics, Manchester, England, 1989. Association\nfor Computational Linguistics.\n[Calzolari, 1991] Nicolleta Calzolari.\nAcquiring\nand representing semantic information in a\nLexical Knowledge Base.\nIn James Puste-\njovsky and Sabine Bergler, editors, Proceedings\nof 1991 ACL Workshop on Lexical Semantics\nand Knowledge Representation, pages 188–197,\n1991.\n[Carbonell and Tomita, 1987] Jaime\nG.\nCarbonell and Masaru Tomita.\nKnowledge-\nbased machine translation, the cmu approach.\nIn Sergei Nirenburg, editor, Theoretical and\nMethodological\nIssues\nin\nMachine\nTransla-\ntion, pages 68–89. Cambridge University Press,\nCambridge, 1987.\n[Chen and Cha, 1988]\nKeh-Jiann Chen and Chuan-Shu Cha. The de-\nsign of a conceptual structure and its relation\nto the parsing of chinese sentences.\nIn Pro-\nceedings of the 1988 International Conference\non Computer Processing of Chinese and Ori-\nental Languages, Toronto, Canada, August 29\n- September 1 1988.\n[Chomsky, 1980] Noam Chomsky.\nOn binding.\nLinguistic Inquiry, 11(1):1–46, 1980.\n38\n[Dahlgren et al., 1989] Kathleen Dahlgren, Joyce\nMcDowell, and Edward P. Stabler. Knowledge\nrepresentation for commonsense reasoning with\ntext.\nComputational Linguistics, 15(3):149–\n170, 1989.\n[Dorr, 1987] Bonnie\nJ.\nDorr.\nUnitran:\na\nprinciple-based approach to machine transla-\ntion. Technical Report MIT AI Technical Re-\nport 1000, Massachussetts Institute of Tech-\nnology,\nDepartment of Electrical Engineer-\ning and Computer Science, Cambridge, Mas-\nsachussetts, 1987.\n[Dorr, 1990] Bonnie J. Dorr.\nLexical concep-\ntual structure and machine translation.\nPhD\nthesis, Massachussetts Institute of Technol-\nogy, Department of Electrical Engineering and\nComputer Science,\nCambridge,\nMassachus-\nsetts, 1990.\n[Dorr, 1991] Bonnie J. Dorr. A two-level knowl-\nedge representation for machine translation:\nlexical semantics and tense/aspect. In James\nPustejovsky and Sabine Bergler, editors, Pro-\nceedings of the 1991 ACL Workshop on Lexi-\ncal Semantics and Knowledge Representation,\npages 250 – 263, Berkeley, CA, June 1991.\n[Emele et al., 1990] Martin Emele, Ulrich Heid,\nWalter Kehl, Stefan Momma, and R´emi Za-\njac. Organizing linguistic knowledge for mul-\ntilingual generation. Technical report, Project\nPolygloss, University of Stuttgart, West Ger-\nmany, 1990. Paper submitted to COLING-90.\n[Emele, 1989] Martin C. Emele. A typed-feature\nstructure uniﬁcation-based approach to gener-\nation.\nIn Proceedings of the WGNLC of the\nIECE, Oita University, Japan, 1989.\n[Fawcett, 1987] Robin P. Fawcett.\nThe seman-\ntics of clause and verb for relational processes.\nIn Robin P. Fawcett and David J. Young, ed-\nitors, New Developments in Systemic Linguis-\ntics: Volume 1. Frances Pinter, London, 1987.\n[Fillmore, 1968] Charles J. Fillmore. The case for\ncase. In Emons Bach and Robert T. Harms,\neditors, Universals in Linguistic Theory. Holt,\nRinehart and Wilson, New York, 1968.\n[Gust, 1991] Helmar Gust.\nRepresenting word\nmeanings. In O. Herzog and C.-R. Rollinger,\neditors, Text understanding in lilog:\ninte-\ngrating computational linguistics and artiﬁcial\nintelligence, Final report on the IBM Ger-\nmany lilog-Project, pages 127 – 142. Springer-\nVerlag, Berlin, 1991. Lecture notes in artiﬁcial\nintelligence, 546.\n[Hale and Keyser, 1986] K. Hale and J. Keyser.\nSome transitivity alternations in english. Tech-\nnical Report Lexicon Project Working Pa-\npers 7, Massachussetts Institute of Technology,\nCambridge, Massachussetts, 1986.\n[Halliday and Matthiessen, to appear]\nMichael A.K. Halliday and Christian M.I.M.\nMatthiessen.\nConstruing experience through\nmeaning: a language-based approach to cogni-\ntion. de Gruyter, Berlin, to appear.\n[Halliday, 1961] Michael A.K. Halliday.\nCate-\ngories of the theory of grammar. Word, 17:241–\n292, 1961.\nReprinted in abbreviated form in\nHalliday (1976) edited by Gunther R. Kress,\npp 52-72.\n[Halliday, 1978] Michael A.K. Halliday. Language\nas social semiotic.\nEdward Arnold, London,\n1978.\n[Halliday, 1982] Michael A.K. Halliday. How is a\ntext like a clause? In Sture All´en, editor, Text\nProcessing. Almqvist and Wiksell, Stockholm,\n1982.\n[Halliday, 1985] Michael A.K. Halliday.\nAn In-\ntroduction to Functional Grammar.\nEdward\nArnold, London, 1985.\n[Hayes, 1979] Patrick J. Hayes. The naive physics\nmanifesto.\nIn Donald Michie, editor, Expert\nsystems in the microelectronic age. Edinburgh\nUniversity Press, Edinburgh, Scotland, 1979.\n[Hayes, 1985] Patrick J. Hayes.\nNative physics\ni:\nontology for liquids.\nIn Jerry R. Hobbs\nand R.C. Moore, editors, Formal theories of\nthe commonsense world, pages 71 – 108. Ablex\nPublishing Corporation, New Jersey, 1985.\n[Heid et al., 1988] Ulrich Heid, Dietmar R¨osner,\nand Birgit Roth. Generating german from se-\nmantic relations: Semantic relations as an in-\nput to the semsyn generator.\nIn Erich H.\nSteiner, Paul Schmidt, and Cornelia Zelinksy-\nWibbelt, editors, From Syntax to Semantics:\nexperiences from Machine Translation. Frances\nPinter, London, 1988.\n[Herskovits, 1986] A. Herskovits. Language and\nSpatial Cognition: an interdisciplinary study of\nthe prepositions in English. Cambridge, 1986.\n[Herweg, 1991] Michael Herweg.\nAspectual re-\nquirements of temporal connectives: evidence\nfor a two-level approach to semantics. In James\nPustejovsky and Sabine Bergler, editors, Pro-\nceedings of the 1991 ACL Workshop on Lexi-\ncal Semantics and Knowledge Representation,\npages 152 – 164, Berkeley, CA, June 1991.\n[Herzog and Rollinger, 1991] Otthein\nHer-\nzog and Claus-Rainer Rollinger, editors. Text\nunderstanding in lilog: integrating computa-\ntional linguistics and artiﬁcial intelligence, Fi-\nnal report on the IBM Germany lilog-Project.\nSpringer-Verlag, Berlin, 1991. Lecture notes in\nartiﬁcial intelligence, 546.\n39\n[Hinrichs et al., 1987] E.W.\nHinrichs,\nD.M.\nAyuso, and R. Scha. The syntax and semantics\nof the janus semantic interpretation language,\npages 27–31.\nBBN Laboratories, Report No.\n6552, 1987.\n[Hobbs and Moore, 1985] Jerry R. Hobbs and\nR.C. Moore, editors.\nFormal theories of the\ncommonsense world. Ablex Publishing Corpo-\nration, New Jersey, 1985.\n[Hobbs et al., 1987] Jerry\nR.\nHobbs,\nWilliam\nCroft, Todd Davies, Douglas Edwards, and\nKenneth Laws. Commonsense metaphysics and\nlexical semantics.\nComputational Linguistics,\n13(3-4):241 – 250, July - December 1987.\n[Hobbs, 1985] Jerry R. Hobbs. On the coherence\nand structure of discourse.\nTechnical Report\nCLSI-85-37, Center for the Study of Language\nand Information, Stanford, CA, October 1985.\n[Horacek, 1989] Helmut Horacek. Towards prin-\nciples of ontology. In D. Metzing, editor, Pro-\nceedings of the German Workshop on Artiﬁ-\ncial Intelligence: GWAI89, pages 323 – 330.\nSpringer-Verlag, Berlin, Heidelberg, New York,\n1989.\n[Hovy, 1988] Eduard H. Hovy.\nGenerating nat-\nural\nlanguage\nunder\npragmatic\nconstraints.\nLawrence\nErlbaum,\nHillsdale,\nNew Jersey,\n1988.\n[Jackendoﬀ, 1977] Ray Jackendoﬀ. X Syntax: a\nstudy of phrase structure.\nThe M.I.T. Press,\nCambridge, MA, 1977.\n[Jackendoﬀ, 1983] Ray Jackendoﬀ.\nSemantics\nand Cognition. The M.I.T. Press, Cambridge,\nMA, 1983.\n[Jackendoﬀ, 1987] Ray Jackendoﬀ. The status of\nthematic relations in linguistic theory. Linguis-\ntic Inquiry, 18(3):369–411, 1987.\n[Jackendoﬀ, 1990] Ray Jackendoﬀ.\nSemantic\nStructures. The M.I.T. Press, Cambridge, MA,\n1990.\n[Klose and von Luck, 1991] Gudrun\nKlose\nand\nKai von Luck.\nThe background knowledge\nof the lilog system.\nIn O. Herzog and C.-\nR. Rollinger, editors, Text understanding in\nlilog:\nintegrating computational linguistics\nand artiﬁcial intelligence, Final report on the\nIBM Germany lilog-Project, pages 455 – 463.\nSpringer-Verlag, Berlin, 1991. Lecture notes in\nartiﬁcial intelligence, 546.\n[Klose et al., 1991] Gudrun Klose, Ewald Lang,\nand Thomas Pirlein.\nDie Ontologie und Ax-\niomatik der Wissensbasis von LEU/2:\nEr-\nfahrungen – Probleme – Ausblicke. Technical\nReport IWBS Report 171, IBM Deutschland,\nStuttgart, 1991.\n[Krifka, 1989] Manfred\nKrifka.\nNominalref-\nerenz, Zeitkonstitution, Aspekt, Aktionsart:\nEine semantische Erkl¨arung ihrer Interpre-\ntation.\nIn W. Abraham and T. Janssen,\neditors, Tempus—Aspekt—Modus. Niemeyer,\nT¨ubingen, 1989.\n[Lang, 1991] Ewald Lang.\nThe lilog ontology\nfrom a linguistic point of view.\nIn O. Her-\nzog and C.-R. Rollinger, editors, Text under-\nstanding in lilog: integrating computational\nlinguistics and artiﬁcial intelligence, Final re-\nport on the IBM Germany lilog-Project, pages\n464 – 481. Springer-Verlag, Berlin, 1991. Lec-\nture notes in artiﬁcial intelligence, 546.\n[Langacker, 1987] Ronald W. Langacker. Foun-\ndations in Cognitive Grammar. Stanford Uni-\nversity Press, Stanford, California, 1987.\n[Lenat and Guha, 1988] Doug Lenat and R.V.\nGuha. The world according to cyc. Technical\nReport MCC Technical Report ACA-AI-300-\n88, Microelectronics and Computer Technology\nCorporation, Austin, Texas, September 1988.\n[Levin, 1987] Lori Levin. Towards a linking the-\nory of relation changing rules in lfg. Technical\nReport Report No. CSLI-87-115, Center for the\nStudy of Language and Information, Stanford,\nCalifornia, 1987.\n[Mann and Matthiessen, 1985] William C. Mann\nand Christian M.I.M. Matthiessen.\nDemon-\nstration of the Nigel text generation computer\nprogram. In James D. Benson and William S.\nGreaves, editors, Systemic Perspectives on Dis-\ncourse, Volume 1. Ablex, Norwood, New Jer-\nsey, 1985.\n[Mann et al., 1985] William\nC.\nMann,\nYigal\nArens, Christian M.I.M. Matthiessen, Shari\nNaberschnig,\nand Norman K. Sondheimer.\nJanus abstraction structure — draft 2. Tech-\nnical report, USC/Information Sciences Insti-\ntute, Marina del Rey, California, October 1985.\n(Circulated in draft form only.).\n[Mann, 1983] William C. Mann. The anatomy of\na systemic choice. Discourse Processes, 1983.\nAlso available as USC/Information Sciences In-\nstitute, Research Report ISI/RR-82-104, 1982.\n[Mann, 1985] William C. Mann. Janus abstrac-\ntion structure – draft 1, 1985.\nAn informal\nproject technical memo of the Janus project at\nISI.\n[Matsukawa and Yokota, 1991] Tomoyoshi Mat-\nsukawa and Eiji Yokota. Development of the\nconcept dictionary – implementation of lex-\nical knowledge.\nIn James Pustejovsky and\nSabine Bergler, editors, Proceedings of the ACL\nWorkshop on Lexical Semantics and Knowledge\n40\nRepresentation, pages 206 –223, Berkeley, CA,\nJune 1991.\n[Matthiessen and Bateman, 1991]\nChristian M.I.M. Matthiessen and John A.\nBateman.\nText generation\nand\nsystemic-\nfunctional linguistics: experiences from English\nand Japanese. Frances Pinter Publishers and\nSt. Martin’s Press, London and New York,\n1991.\n[Matthiessen and Halliday, forthcoming]\nChristian\nM.I.M.\nMatthiessen\nand Michael A.K. Halliday.\nSystemic Func-\ntional Grammar. In Fred C.C. Peng and J. Ney,\neditors, Current Approaches to Syntax. Ben-\njamins and Whurr, Amsterdam and London,\nforthcoming.\n[Matthiessen, 1990] Christian\nM.I.M.\nMatthiessen. Lexicogrammatical cartography:\nEnglish systems. Technical report, University\nof Sydney, Linguistics Department, 1990. On-\ngoing expanding draft.\n[McKeown and Paris, 1987] Kathleen R. McKe-\nown and C´ecile L. Paris.\nFunctional uniﬁca-\ntion grammar revisited. In Proceedings of the\n25th Annual Meeting of the ACL, Palo Alto,\nCalifornia, 1987. Association of Computational\nLinguistics.\n[Meteer et al., 1987] Marie W. Meteer, David D.\nMcDonald, S.D. Anderson, D. Forster, L.S.\nGay, A.K. Huettner, and P. Sibun. Mumble-\n86:\nDesign and implementation.\nTechni-\ncal Report 87-87, COINS, University of Mas-\nsachusetts, 1987.\n[Meteer, 1988] Marie W. Meteer. Deﬁning a vo-\ncabulary for text planning, August 1988. Pre-\nsented at the AAAI-88 Workshop on Text Plan-\nning and Realization, organized by Eduard H.\nHovy, Doug Appelt, David McDonald and Sh-\neryl Young.\n[Meteer, 1989] Marie\nW.\nMeteer.\nThe\nspokesman natural language generation sys-\ntem. Technical Report BBN Report No. 7090,\nBBN Systems and Technologies Corporation,\nCambridge, MA, 1989.\n[Moens and Steedman, 1988]\nM. Moens and M. Steedman. Temporal ontol-\nogy and temporal reference.\nComputuational\nLinguistics, 14(2), 1988.\n[Moens et al., 1989] Marc\nMoens,\nJo\nCalder,\nEwan Klein, Mark Reape, and Henk Zeevat.\nExpressing generalizations in uniﬁcation-based\nformalisms. In Proceedings of the 4th. Confer-\nence of the European Chapter of the Associa-\ntion for Computational Linguistics, pages 174–\n181, Manchester, England, 1989.\n[Momma and D¨orre, 1987] Stefan Momma and\nJochen D¨orre.\nGeneration from f-structures.\nIn Ewan Klein and Johann Van Bentham, ed-\nitors, Categories, Polymorphism and Uniﬁca-\ntion. Cognitive Science Centre, University of\nEdinburgh, Edinburgh, Scotland, 1987.\n[Moore and Arens, 1985] Johanna D. Moore and\nYigal Arens.\nA hierarchy for entities, 1985.\nUSC/Information Sciences Institute, Internal\nDraft.\n[Moore, 1989] Johanna D. Moore. A reactive ap-\nproach to explanation in expert and advice-\ngiving systems. PhD thesis, University of Cali-\nfornia, Los Angeles, 1989.\n[Nebel et al., 1991] Bernhard\nNebel,\nChristof\nPeltason, and Kai von Luck.\nProceedings of\ninternational workshop on terminological log-\nics.\nTechnical Report DFKI-D-91-13, DFKI,\nSaarbr¨ucken, May 1991.\n[Nerbonne, 1992] John Nerbonne. Representing\ngrammar, meaning and knowledge, May 1992.\n(Papers from KIT-FAST Workshop, Technical\nUniversity Berlin, October 9th - 11th 1991).\n[Nirenburg and Levin, 1991] Sergei\nNirenburg\nand Levin. Syntax-driven and ontology-driven\nlexical semantics.\nIn James Pustejovsky and\nSabine Bergler, editors, Proceedings of the ACL\nWorkshop on Lexical Semantics and Knowledge\nRepresentation, Berkeley, CA, June 1991.\n[Nirenburg and Raskin, 1987] Sergei\nNirenburg\nand Victor Raskin. The subworld concept lexi-\ncon and the lexicon management system. Com-\nputational Linguistics, 13(3-4), 1987.\n[Nirenburg et al., 1987] Sergei\nNirenburg,\nV. Raskin, and A. Tucker.\nThe structure of\ninterlingua in translator.\nIn Sergei Niren-\nburg, editor, Machine Translation: Theoretical\nand Methodological Issues. Cambridge Univer-\nsity Press, Cambridge, 1987.\n[Onyshvekych and Nirenburg, 1991]\nBoyan A. Onyshvekych and Sergei Nirenburg.\nLexicon, ontology and text meaning. In James\nPustejovsky and Sabine Bergler, editors, Pro-\nceedings of the ACL Workshop on Lexical Se-\nmantics and Knowledge Representation, Berke-\nley, CA, June 1991.\n[Penman Project, 1989] Penman Project.\npen-\nman documentation:\nthe Primer, the User\nGuide, the Reference Manual, and the Nigel\nmanual.\nTechnical report, USC/Information\nSciences Institute, Marina del Rey, California,\n1989.\n[Pirlein, 1991] Thomas Pirlein.\nKonstruktion\nund Evaluation von Wissensbasen in textver-\nstehenden Systemen. In Th. Christaller, edi-\ntor, GWAI-91: 15. Fachtagung f¨ur K¨unstliche\n41\nIntelligenz, pages 147 –156. Springer-Verlag,\nBerlin, 1991.\n[Pollard and Sag, 1987] Carl Pollard and Ivan A.\nSag. Information-based syntax and semantics:\nvolume 1. Chicago University Press, Chicago,\n1987. Center for the Study of Language and\nInformation; Lecture Notes Number 13.\n[Pustejovsky, 1988] James Pustejovsky. Event se-\nmantic structure.\nTechnical report, Brandeis\nUniversity, Waltham, MA., 1988.\n[Pustejovsky, 1991] James Pustejovsky. Towards\na generative lexicon. Computational Linguis-\ntics, 17(4), 1991.\n[Reinhardt and Whipple, 1988]\nT. Reinhardt and C. Whipple.\nSummary of\nconclusions from the longman’s taxonomy ex-\nperiment. In B. Goodman, editor, Annual Re-\nport. BBN Systems and Technologies Corpora-\ntion, Cambridge, MA, 1988.\n[Rohrer, 1986] Christian Rohrer. Linguistic bases\nfor machine translation. In Proceedings of col-\ning 86, pages 353–355, 1986.\n11th. Interna-\ntional Conference on Computational Linguis-\ntics; Bonn, August.\n[R¨osner, 1988] Dietmar R¨osner. The generation\nsystem of the semsyn project: towards a task-\nindependent generator for German. In Michael\nZock and G´erard Sabah, editors, Advances in\nNatural Language Generation:\nan interdisci-\nplinary perspective; volume 2. Frances Pinter,\nLondon, 1988.\n[Sag and Pollard, 1991] Ivan A. Sag and Carl\nPollard. An integrated theory of complement\ncontrol. Language, 67(1):63 – 113, 1991.\n[Schank and Abelson, 1977] Roger\nC.\nSchank\nand R. P. Abelson. Scripts, Plans, Goals and\nUnderstanding. Lawrence Erlbaum Associates,\nHillsdale, New Jersey, 1977.\n[Schriefers, 1990] Heribert Schriefers.\nLexical\nand conceptual factors in the naming of rela-\ntions. Cognitive Psychology, 22:111 – 142, 1990.\n[Simmons, 1991] G. Simmons. Empirical meth-\nods for ontological engineering.\nIn Gudrun\nKlose, Ewald Lang, and Thomas Pirlein, ed-\nitors, Die Ontologie und Axiomatik der Wis-\nsensbasis von LEU/2: Erfahrungen – Probleme\n– Ausblicke, number IWBS Report 171, pages\nVI. 1 – 38. 1991.\n[Skuce and Monarch, 1990] Doug Skuce and Ira\nMonarch. Ontological issues in knowledge base\ndesign: some problems and suggestions. In Pro-\nceedings of the BanﬀWorkshop on Knowledge\nAcquisition, Banﬀ, Canada, 1990.\n[Smolka and A¨it-Kaci, 1989] Gert\nSmolka\nand\nHassan A¨it-Kaci. Inheritance hierarchies: se-\nmantics and uniﬁcation.\nJournal of symbolic\ncomputation, 7:343 – 370, 1989.\n[Smolka, 1989] Gert Smolka. A feature logic with\nsubsorts. Technical Report LILOG Report, 33,\nIWBS, IBM Deutschland, Postfach 80 08 80,\nStuttgart, 1989. (To appear in the Proceedings\nof the Workshop on Uniﬁcation Formalisms –\nSyntax, Semantics, and Implementation, Ti-\ntisee, The MIT Press, 1990.).\n[Steiner and Reuther, 1989] Erich H. Steiner and\nUrsula Reuther. Semantic relations. Eurotra\nreference manual, Version 6, 1989. (Commis-\nsion of the European Community).\n[Steiner et al., 1987] Erich\nH.\nSteiner,\nUrsula\nEckert, Birgit Weck, and Jutta Winter. The\ndevelopment of the eurotra-d system of se-\nmantic relations.\nTechnical Report Eurotra-\nD Working Papers, No. 2, Institut der ange-\nwandten\nInformationsforschung,\nUniversit¨at\ndes Saarlandes, Saarbr¨ucken, West Germany,\n1987.\n[Steiner, 1987] Erich H. Steiner. Semantic rela-\ntions in lfg and eurotra-d — a comparison.\nTechnical Report Eurotra-d Working Papers\nNo. 5, Institut f¨ur Angewandte Informations-\nforschung, Saarbr¨ucken, West Germany, 1987.\n[Talmy, 1987] Leonard Talmy.\nThe relation of\ngrammar to cognition.\nIn B. Rudzka-Ostyn,\neditor, Topics in Cognitive Linguistics. John\nBenjamins, 1987.\n[Vendler, 1967] Z. Vendler. Linguistics in Philos-\nophy. Cornell University Press, Ithaca, 1967.\n[Weischedel, 1989] Ralph M. Weischedel. A hy-\nbrid approach to representation in the janus\nnatural language processor.\nIn 27th Annual\nMeeting of the Association for Computational\nLinguistics, 26-29 June 1989, pages 193–202,\nVancouver, British Columbia, 1989. The Asso-\nciation for Computational Linguistics.\n[Wierzbicka, 1988] Anna Wierzbicka.\nThe se-\nmantics of grammar. John Benjamins Publish-\ning Company, Amsterdam/Philadelphia, 1988.\nStudies in Language Companion Series 18.\n[Zajac, 1989] R´emi Zajac. A transfer model using\na typed feature structure rewriting system with\ninheritance. In 27th Annual Meeting of the As-\nsociation for Computational Linguistics, 26-29\nJune 1989, pages 193–202, Vancouver, British\nColumbia, 1989. The Association for Compu-\ntational Linguistics.\n[Zelinsky-Wibbelt, 1987] Cornelia\nZelinsky-\nWibbelt.\nSemantische Merkmale f¨ur die au-\ntomatische Disambiguierung: ihre Generierung\n42\nund\nihre\nVerwendung.\nTechnical\nReport\neurotra-d Working Papers No. 4, Institut f¨ur\nAngewandte Informationsforschung, Eurotra-\nD, Saarbr¨ucken, West Germany, 1987.\n[Zelinsky-Wibbelt, 1988]\nCornelia Zelinsky-Wibbelt. The semantic rep-\nresentation of sentences by means of seman-\ntic features.\nIn Erich Steiner, Paul Schmidt,\nand Cornelia Zelinksy-Wibbelt, editors, From\nSyntax to Semantics:\ninsights from Machine\nTranslation. Frances Pinter, London, 1988.\n43\n",
  "categories": [
    "cmp-lg",
    "cs.CL"
  ],
  "published": "1997-04-25",
  "updated": "1997-04-25"
}