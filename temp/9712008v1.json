{
  "id": "http://arxiv.org/abs/cmp-lg/9712008v1",
  "title": "What is word sense disambiguation good for?",
  "authors": [
    "Adam Kilgarriff"
  ],
  "abstract": "Word sense disambiguation has developed as a sub-area of natural language\nprocessing, as if, like parsing, it was a well-defined task which was a\npre-requisite to a wide range of language-understanding applications. First, I\nreview earlier work which shows that a set of senses for a word is only ever\ndefined relative to a particular human purpose, and that a view of word senses\nas part of the linguistic furniture lacks theoretical underpinnings. Then, I\ninvestigate whether and how word sense ambiguity is in fact a problem for\ndifferent varieties of NLP application.",
  "text": "arXiv:cmp-lg/9712008v1  23 Dec 1997\nWhat is word sense disambiguation good for?\nAdam Kilgarriﬀ∗\nITRI\nUniversity of Brighton\nAbstract\nWord sense disambiguation has developed as a sub-area\nof natural language processing, as if, like parsing, it was\na well-deﬁned task which was a pre-requisite to a wide\nrange of language-understanding applications. First, I\nreview earlier work which shows that a set of senses for\na word is only ever deﬁned relative to a particular hu-\nman purpose, and that a view of word senses as part of\nthe linguistic furniture lacks theoretical underpinnings.\nThen, I investigate whether and how word sense ambi-\nguity is in fact a problem for NLP applications.\nWhat word senses are not\nThere is now a substantial literature on the problem of\nword sense disambiguation (WSD). The goal of WSD\nresearch is generally taken to be disambiguation be-\ntween the senses given in a dictionary, thesaurus or sim-\nilar. The idea is simple enough and could be stated as\nfollows:\nMany words have more than one meaning. When a\nperson understands a sentence with an ambiguous\nword in it, that understanding is built on the basis\nof just one of the meanings. So, as some part of the\nhuman language understanding process, the appro-\npriate meaning has been chosen from the range of\npossibilities.\nStated in this way, it would seem that WSD might be\na well-deﬁned task, undertaken by a particular mod-\nule within the human language processor. This module\ncould then be modelled computationally in a WSD pro-\ngram, and this program, performing, as it did, one of\nthe essential functions of the human language processor,\nwould stand alongside a parser as a crucial component\nof a broad range of NLP applications.\nThere are problems with this view.\nThe simplest\nstems from the observation that diﬀerent dictionaries\n∗Research supported by the EPSRC, grant K18931.\nEmail: Adam.Kilgarriff@itri.bton.ac.uk\nvery often give diﬀerent sets of senses for a word. A\ncloser investigation reveals a lack of theoretical foun-\ndations to the concept of ‘word sense’. The concept is\nintimately connected to our knowledge and experience\nof dictionaries, but these are social artifacts created to\nsatisfy such human purposes as playing word-games, re-\nsolving family arguments, and making proﬁts for pub-\nlishers. Amid all these competing goals, the pursuit of\ntruth is not always dominant.\nIn particular, a standard dictionary speciﬁes the\nrange of meaning of a word in a list, possibly nested,\nof senses.\nThis is not the outcome of an analysis of\nhow word-meaning operates, but is, rather, a response\nto constraints imposed by:\n• tradition\n• the printed page\n• compactness\n• a single, simple method of access\n• resolving disputes about what a word does and does\nnot mean.\nThe format of the dictionary has remained fairly sta-\nble since Dr. Johnson’s day. The reasons for the format,\nand the reasons it has proved so resistant to change and\ninnovation, are explored at length in Nunberg (1994).\nIn short, the development of printed discourse, particu-\nlarly the new periodicals, in England in the early part of\nthe eighteenth century brought about a re-evaluation of\nthe nature of meaning. No longer could it be assumed\nthat a disagreement or confusion about a word’s mean-\ning could be settled face-to-face, and it seemed at the\ntime that the new discourse would only be secure if\nthere was some mutually acceptable authority on what\nwords meant. The resolution to the crisis came in the\nform of Johnson’s Dictionary. Thus, from its inception,\nthe modern dictionary has had a crucial symbolic role\nas in-principle arbiter of disputes. Hence “the dictio-\nnary”, with its implications of unique reference and au-\nthority (cf. “the Bible”). Further evidence for this po-\nsition is to be found in McArthur (1987), for whom the\n“religious or quasi-religious tinge” (p 38) to reference\nmaterials is an enduring theme in their history; Sum-\nmers (1988), whose research into dictionary use found\nthat “settl[ing] family arguments” was a major use (p\n114, cited in B´ejoint (1994, p 151)); and Moon (1989)\nwho catalogues the use of the UAD (Unidentiﬁed Au-\nthorising Dictionary) from newspapers letters pages to\nrestaurant advertising materials (pp 60–64).\nTo solve disputes about meaning, a dictionary must\nbe, above all, clear. It must draw a line around a mean-\ning, so that a use can be classiﬁed as on one side of the\nline or the other. A dictionary which dwells on marginal\nor vague uses of a word, or which presents word meaning\nas context-dependent or variable or ﬂexible, will be of\nlittle use for purposes of settling arguments. The pres-\nsure from this quarter is for the dictionary to present\na set of discrete, non-overlapping meanings for a word,\neach deﬁned by the necessary and suﬃcient conditions\nfor its application —whatever the facts of the word’s\nusage.\nLexicographers are vividly aware of the problem.\nThey have frequently lamented the possibly-nested list\nmodel Stock (1983; Hanks (1994; Fillmore and Atkins\n(1992).\nThey know all too well the injustice it fre-\nquently does to a word’s range of meaning and use.\nBut WSD researchers, at least until recently, have gen-\nerally proceeded as if this was not the case: as if a sin-\ngle program —disambiguating, perhaps, in its English-\nlanguage version, between the senses given in some hy-\nbrid descendant of Merriam-Webster, LDOCE, COM-\nLEX, Roget, OALDCE and WordNet —would be rele-\nvant to a wide range of NLP applications.1\nThe sets of word senses presented in diﬀerent dic-\ntionaries and thesauri have been prepared, for various\npurposes, for various human users: there is no a pri-\nori reason to believe those sets are appropriate for any\nNLP application.2\nIt seems likely that NLP application lexicons —which\nare, in the mid 1990s, almost invariably hand-built\nrather than MRD-derived— will be application-driven\nrather than resource-driven, so will only contain the\nword senses and make the word sense distinctions rele-\n1The most promising recent WSD work is moving away\nfrom this position, determining the senses between which\nthe program is to disambiguate either directly from the\nclusters in the corpus (Sch¨utze, 1997), or through a small\namount of human input (Clear, 1994), or a choice of either\n(Yarowsky, 1995).\n2For a full account of the nature of word senses, in dic-\ntionaries and elsewhere, see Kilgarriﬀ(1992; 1993; 1997b).\nvant to the application. They might not encounter word\nsense ambiguity on anything like the scale that a brief\nglance at a dictionary (or at the WSD literature) would\nsuggest. The remainder of the paper addresses whether\nthis is so, and what scale of problem word sense ambi-\nguity causes for diﬀerent varieties of NLP application.3\nTaxonomy\nFirst, let us distinguish ﬁve types of application for\nwhich WS ambiguity is potentially an issue:\n• Information Retrieval (IR)\n• Machine Translation (MT)\n• Parsing (and, implicitly, all those applications for\nwhich parsing is one stage of processing)\n• Lexicography\n• Residual, ‘core’ language understanding (including\ndatabase front ends, dialogue systems, Information\nExtraction as in MUC) —hereafter NLU.\nIR\nThe intellectual aﬃnities of most recent WSD work are\nwith IR. The problem of ﬁnding whether a particu-\nlar sense applies to an instance of a word can be con-\nstrued as equivalent to the essential IR task of ﬁnding\nwhether a document is relevant to a query. The homol-\nogy is made explicit at various points in the literature\n(Gale, Church, and Yarowsky, 1992; Gale, Church, and\nYarowsky, 1993).\nMost work in IR disregards syntactic structure en-\ntirely, ‘stemming’ words so that clean, cleaner, clean-\ning and cleaned are all mapped to clean, and then treats\na document as a bag of stems. It does not use POS-\ntagging or name-recognition, although these are rela-\ntively mature and reliable technologies for these tasks\nwithin NLP, and parsing has not been found to improve\nIR performance: the linguistic processing has not been\nfast, robust or portable enough, and it is not in any case\nclear whether it provides relevant information for the IR\ntask. This is very much a live issue: see Strzalkowski\n(1994), Strzalkowski and Vauthey (1995) for recent ev-\nidence of the potential of NLP in IR. However, to date,\nIR has made progress through applying sophisticated\nstatistical techniques to documents treated as objects\nwithout linguistic structure, and this is the approach to\nWSD which has recently ﬂourished.\nWithin IR, WSD can be viewed as an alternative to\nNLP, rather than a technique within it. If a statistical\nmodel based on a bag of stems is inadequate, one way to\n3My sources include an informal email survey on the\nCORPORA mailing list, to which I had 28 responses.\n2\nget closer to the meaning of a text is WSD; another is a\nlinguistically-informed technique such as parsing. They\nare not mutually exclusive, but nor are they readily\ncompatible.\nA high proportion of WSD research is oriented to-\nwards IR, yet it is not clear whether WSD has the po-\ntential to signiﬁcantly improve IR performance. In the\nﬁrst careful study of the question, Krovetz and Croft\n(1992) conducted some experiments which suggested\nthat WS-ambiguity causes only limited degradation of\nIR performance. Their experiments were on the small,\nspecialist CACM corpus.\nThey used a standard set\nof queries for which “correct answers” are available.\nThey compared system performance ‘with ambiguity’\nand ‘without ambiguity’: the ‘with ambiguity’ condi-\ntion was the normal situation, while for the ‘without\nambiguity’ condition, all relevant terms had been man-\nually disambiguated, in a simulation of a perfect WSD\nprogram. For this corpus and query-set, they concluded\nthat a perfect WSD program would improve perfor-\nmance by 2%.\nSanderson (1994) performed a similar experiment us-\ning pseudo-words.\nA pseudo-word is a word formed\nby ‘pretending’ that two distinct words were a single\nword with two meanings, one corresponding to each\nof the original words. Thus the pseudo-word banana-\nkalashnikov could be formed by replacing all instances\nof banana and kalashnikov in a corpus by banana-\nkalashnikov: then a WSD program would have the task\nof determining which were originally bananas, which\nkalashnikovs. The method allowed Sanderson to reg-\nulate the degree of ambiguity in the corpus, and to\nmodel both accurate and inaccurate WSD programs.\nHe found that introducing extra ambiguity did little\nto degrade performance, but, when the WSD algorithm\nmade mistakes, this did do harm. Also, in longer queries\nthe diﬀerent words in the query will tend to be mutu-\nally disambiguating, so WSD is probably only relevant\nwhere the query is very short. He concludes “the per-\nformance of [IR] systems is insensitive to ambiguity but\nvery sensitive to erroneous disambiguation” (p 149).\nSch¨utze (1997) ﬁrst distinguishes sense discrimina-\ntion from disambiguation.\nDiscrimination involves\nidentifying distinct senses and classifying occurrences\nof the word as belonging to one of those senses. It does\nnot involve labelling the senses (which correspond to\nclusters of occurrences) or associating them with any\nexternal knowledge source such as a dictionary. Thus,\nin keeping with the spirit of this paper, his senses are\nautomatically devised to match the corpus. System per-\nformance improved by up to 4.3%.4 with the addition\n4They cite an improved average precision (over 11 levels\nof recall) of 14.4% compared to the baseline, from 29.9% to\nof the disambiguation module (and the added sophisti-\ncation that a word can be assigned to more than one\nword sense, where it is ‘near’ more than one in vector\nspace).\nIt is debatable how important an improvement of 2\nor 4 percentage points is. On the one hand, WSD will\nclearly not revolutionise IR or render it a solved prob-\nlem. But IR is a fairly mature technology, very widely\nused by millions of users, and an average 4% improve-\nment across all those users and all their many queries\ncould be seen as very signiﬁcant indeed.\nMachine Translation\nIn IR, it is generally diﬃcult to assign blame for poor\nperformance to word sense ambiguity or any other spe-\nciﬁc source. MT, by contrast, wears its mistakes on its\nsleeve. It is abundantly clear to all in MT that word\nsense ambiguity is a huge problem.\nThe literature has surprisingly little to say about it.\nHutchins and Somers (1992) point out the two variants\nof the problem: monolingual ambiguity, where the word\nis ambiguous in the source language, and translational\nambiguity, where speakers of the source language do\nnot consider the word ambiguous but it has two pos-\nsible translations, as when English blue is translated\ndiﬀerently into Russian according to whether it is light\nblue or dark.\nMT is a technology rather than a science. MT sys-\ntems generally take a decade from idea to marketplace,\nso the theory available at their inception is destined to\nbe out of date by the time they perform. Thus no re-\ncent WSD work is employed in existing MT systems.\nThey use extensive sets of selection restrictions paired\nwith semantic features to make it possible for the sys-\ntem to make the correct lexical choice.\nMT systems\nusually use a number of very large lexicons where selec-\ntion restriction information, designed to resolve ambi-\nguity problems, accounts for a large proportion of the\nbulk. The SYSTRAN English-French lexicon respon-\nsible for word choice contains 400 rules governing the\none English word, oil, and when it should be translated\nas huile, when p´etrole (Hutchins and Somers, 1992, p\n179).\nOne paper which does bring state-of-the-art WSD\nto bear on Machine Translation, albeit in experimen-\ntal mode, is Dagan and Itai (1994). They use a bilin-\ngual lexicon to identify the possible translations, and\na parsed target language corpus to gather information\nabout the ‘tuples’ in which each of the possible trans-\nlations is often found.\nA ‘tuple’ comprises a gram-\n34.2%.\nThis improvement is 4.3% in absolute terms, but\n14.4% when calculated as an improvement on the baseline\nperformance.\n3\nmatical relation, such as subject-verb, and the oc-\ncupier of each of the slots of that relation, so “The man\nwalked home” would give the triple (subject-verb,\nman, walk). The source-language text to be translated\nin then parsed, to give a source language tuple. The\nbilingual dictionary and the target-language statistics\nare then used to ﬁnd the best match.\nThe paper applies sophisticated WSD to a real prob-\nlem, with the discriminations that the system makes\nbeing deﬁned by the needs of the application.\nParsing\nAccurate parsing is a requirement for a wide range of\nNLP applications, so if WSD is critical for parsing ac-\ncurately, it is, by implication, signiﬁcant for all those\napplications that depend on parsing. McCarthy (1997)\nexplores WSD methods explicitly for purposes of im-\nproving parsing. Before assessing whether WS ambigu-\nity is critical, let us take a step back.\nIt is well-established that “the problem of syntactic\nambiguity is AI-complete” (Hobbs et al., 1992, p 269).\nHere, let us focus on one particular, but pervasive, va-\nriety of syntactic ambiguity: prepositional phrase (PP)\nattachment. A problem is AI-complete if its solution\nrequires a solution to all the general AI problems of\nrepresenting and reasoning about arbitrary real-world\nknowledge. In principle, any item of general knowledge\nmight be the datum required to make a PP-attachment.\nIf that is all that can be said, the outlook is bleak. We\nwould hope that, in practice, a small and tractable sub-\nset of general knowledge will resolve a high proportion\nof ambiguities.\nSome approaches to high-quality parsing make exten-\nsive use of machine-readable dictionaries (MRDs). In\nthe 1990s, Microsoft have been the leading proponents\nof ‘MRDs-for-parsing’.5 The hypothesis behind the ap-\nproach is that dictionary entries provide, implicitly or\nexplicitly, the information required to resolve most syn-\ntactic ambiguities.\nNote that, even if this hypothesis is true, it does not\nimply that WSD has an important role to play. Lexi-\ncal information can resolve many syntactic ambiguities\nwithout being sense-disambiguated. Consider\n1 I love baking cakes with friends.\n2 I love baking cakes with butter icing.\nThe PP attachment ambiguity is resolved, along with\nthe ambiguity of with, by the semantic class of the ﬁnal\nnoun phrase. Where the head of this noun phrase is\n5The method is used in the parser embedded in 1997 Mi-\ncrosoft Word’s grammar checker, as demonstrated by Steve\nRichardson at the ACL Conference in Applied NLP, Wash-\nington D.C., 1997.\nhuman, as in 1, the PP attaches to the verb. Where\nit is a cake ingredient, it attaches to cakes. Lexical in-\nformation is required to determine the attachment in 1\nand 2, but, since neither friends nor icing is ambiguous\nbetween humans and cake-ingredients, disambiguation\nis not required.\nThat lexical information will resolve a high propor-\ntion of syntactic ambiguities is one hypothesis; that a\nsigniﬁcantly higher proportion will be resolved, if the\nlexical information is sense-speciﬁc, is another.\nAlmost no work has been done to test either hypoth-\nesis. Whittemore, Ferrara, and Brunner (1990) tested\nand conﬁrmed a related hypothesis: that ‘lexical pref-\nerences’ of nouns and verbs for PPs of a particular\ntype are better predictors of PP-attachment than any\npurely syntactic considerations.\nThey took a sample\ncorpus and counted the PPs that would be correctly\nattached if each strategy was used.\nTo discover the\nsigniﬁcance of WS-ambiguity to parsing, a study is re-\nquired which combines this method with Krovetz and\nCroft’s, of manually disambiguating to determine the\nperformance improvement that would be achieved with\na perfect WSD program.\nLexicography\nNLP is most aware of lexicographers as suppliers of\nwares, but they are also customers. A linguistically an-\nnotated corpus is of more use to a lexicographer than\na ‘raw’ one, as he or she can then investigate the be-\nhaviour of a word in particular linguistic contexts with-\nout having to trawl through large numbers of irrelevant\ncitations. A sense-annotated corpus would be partic-\nularly valuable, as the lexicographer would not have\nto trawl through ‘money bank’ citations when deﬁning\n‘river bank’ (Clear, 1994). There is then an intriguing\npossibility that the behaviour of WSD programs will\nfeed back into the nature of the dictionary senses they\ndisambiguate between.\nNLU\nFor existing NLP applications requiring a deeper under-\nstanding of the text, 99% of the ambiguity to be found\nin a desk dictionary is not relevant.\nThis is, ﬁrstly,\nbecause these applications deal only with very speciﬁc\ntext types. The speciﬁc sublanguage generally means\nthat, if a word has a meaning which is of interest, it is\nvery likely that occurrences of the word will be being\nused in that meaning and not some other. Secondly,\neven then the application can only interpret those in-\nputs for which there is a possible interpretation in the\nknowledge base (or in the system’s output behaviour).\nSeveral respondents to the email survey, where I asked,\n“does WS ambiguity cause problems for your system?”,\n4\ncommented “We don’t have any semantics in our lexi-\ncon, we just have hooks into the knowledge representa-\ntion”.\nWhere a word has one sense in the domain model,\nand one or more outside it, an NLU application can\ngenerally determine whether the word is being used in\nthe domain sense by identifying whether the entire sen-\ntence or query is coherent in terms of the domain model.\nIf it is, the word is almost certainly being used in the\ndomain sense. Where a word has more than one do-\nmain sense, it is unlikely that both will produce coher-\nent analyses. The domain model will generally provide\ndisambiguating material, not because it has been explic-\nitly added, but because type-checking and coherence-\nchecking which is necessary in any case will reject in-\nvalid senses.\nWith time, NLU systems will become more sophisti-\ncated, with richer domain models and less limitations in\nthe varieties of text they can analyse. This will make\nWSD more salient, though diﬀerent strategies will be\nrelevant for the ‘foreground lexicon’ containing the key\nwords for the domain model, and the ‘background lex-\nicon’, containing all other words. Foreground lexicon\nsenses will be tightly-deﬁned and domain-speciﬁc, and\nwill be disambiguated by coherence-checking.\nBack-\nground lexicon disambiguation will only need to be be-\ntween coarse-grained senses. Its function will be to in-\ncrease parse accuracy, and statistical methods will be\nappropriate. (The full argument is presented in Kilgar-\nriﬀ(1997).)\nAnswers\nThe answers to the question, “Does WS ambiguity\ncause problems for NLP applications?” are:\nIR: yes, to some moderate degree.\nProblems can\nsubstantially be overcome by using longer queries.\nWithin IR, WSD features as something of an alter-\nnative to NLP.\nMT: yes. Huge problem, with the problem space de-\nﬁned by all the one-to-many and many-to-many map-\npings in a bilingual dictionary. Addressed to date by\nlots and lots of selection restrictions.\nParsing: not known.\nLexicography: yes, WSD would be of beneﬁt.\nNLU: not much. NLU applications are mostly domain\nspeciﬁc, and have some sort of domain model.\nIt\nis generally necessary to have a detailed knowledge\nof the word senses that are in the domain, so the\nknowledge to disambiguate will often be available in\nthe domain model even where it has not explicitly\nbeen added for disambiguation purposes.\nReferences\n[B´ejoint1994] B´ejoint, Henri. 1994. Tradition and In-\nnovation in Modern English Dictionaries. OUP, Ox-\nford.\n[Clear1994] Clear, Jeremy. 1994. I can’t see the sense\nin a large corpus. In Ferenc Kiefer, Gabor Kiss, and\nJulia Pajzs, editors, Papers in Computational Lexi-\ncography: COMPLEX ’94, pages 33–48, Budapest.\n[Dagan and Itai1994] Dagan, Ido and Alon Itai. 1994.\nWord sense disambiguation using a second lan-\nguage monolingual corpus. Computational Linguis-\ntics, 20(4):563–596.\n[Fillmore and Atkins1992] Fillmore,\nCharles\nJ.\nand\nBeryl T. S. Atkins.\n1992. Towards a frame-based\nlexicon: the semantics of risk and its neighbours.\nIn Adrienne Lehrer and Eva Kittay, editors, Frames,\nFields and Contrasts. Lawrence Erlbaum, New Jer-\nsey, pages 75–102.\n[Gale, Church, and Yarowsky1992] Gale, William, Ken-\nneth Church, and David Yarowsky. 1992. Estimating\nupper and lower bounds on the performance of word-\nsense disambiguation programs. In Proceedings, 30th\nACL, pages 249–156.\n[Gale, Church, and Yarowsky1993] Gale, William, Ken-\nneth Church, and David Yarowsky. 1993. A method\nfor disambiguating word senses in a large corpus.\nComputers and the Humanities, 26(1–2):415–439.\n[Hanks1994] Hanks, Patrick.\n1994.\nLinguistic norms\nand pragmatic exploitations or, why lexicographers\nneed prototype theory, and vice versa.\nIn Fer-\nenc Kiefer, Gabor Kiss, and Julia Pajzs, editors,\nPapers in Computational Lexicography: COMPLEX\n’94, pages 89–113, Budapest.\n[Hobbs et al.1992] Hobbs, Jerry R., Douglas Appelt,\nMabry Tyson, John Bear, and David Israel. 1992.\nDescription of the fastus system used for muc-4. In\nProceedings, 4th Message Understanding Conference,\npages 268–275.\n[Hutchins and Somers1992] Hutchins, John and Harold\nSomers. 1992. Introduction to Machine Translation.\nAcademic Press.\n[Kilgarriﬀ1992] Kilgarriﬀ, Adam.\n1992.\nPolysemy.\nPh.D. thesis, University of Sussex, CSRP 261, School\nof Cognitive and Computing Sciences.\n[Kilgarriﬀ1993] Kilgarriﬀ, Adam.\n1993.\nDictionary\nword sense distinctions: An enquiry into their nature.\nComputers and the Humanities, 26(1–2):365–387.\n5\n[Kilgarriﬀ1997] Kilgarriﬀ, Adam.\n1997.\nForeground\nand background lexicons and word sense disambigua-\ntion for information extraction. In Proc. Workshop\non Lexicon Driven Information Extraction, Frascati,\nItaly, July.\n[Kilgarriﬀ1998] Kilgarriﬀ, Adam.\n1998.\n‘I don’t be-\nlieve in word senses’. Computers and the Humanities,\nforthcoming.\n[Krovetz and Croft1992] Krovetz, Robert and W. Bruce\nCroft. 1992. Lexical ambiguity and information re-\ntrieval. ACM Transactions on Information Systems,\n10(2):115–141.\n[McArthur1987] McArthur, Tom. 1987. Worlds of ref-\nerence. CUP, Cambridge, England.\n[McCarthy1997] McCarthy, Diana.\n1997. Word sense\ndisambiguation for acquisition of selectional prefer-\nences. In Proc. ACL/EACL Workshop on Automatic\nInformation Extraction and building of lexical seman-\ntic resources, pages 52–60, Madrid, July. ACL.\n[Moon1989] Moon, Rosamund.\n1989.\nObjective or\nobjectionable?\nideological aspects of dictionar-\nies.\nEnglish Language Research, 3: Language and\nIdeology:59–94.\n[Nunberg1994] Nunberg, Geoﬀrey. 1994. The once and\nfuture dictionary. Presentation at The Future of the\nDictionary Workshop, Uriage-les-Bains, France, Oc-\ntober.\n[Sanderson1994] Sanderson, Mark.\n1994.\nWord sense\ndisambiguation and information retrieval.\nIn Pro-\nceedings, ACM Special Interest Group on Informa-\ntion retrieval, pages 142–151.\n[Sch¨utze1997] Sch¨utze, Hinrich. 1997. Automatic word\nsense discrimination.\nComputational Linguistics,\nforthcoming.\n[Stock1983] Stock, Penelope F.\n1983.\nPolysemy.\nIn\nProc. Exeter Lexicography Conference, pages 131–\n140.\n[Strzalkowski1994] Strzalkowski, Tomek. 1994. Robust\ntext processing in automated inofrmation retrieval.\nIn 4th Conference on Applied Natural Language Pro-\ncessing, pages 168–173, Stuttgart, October.\n[Strzalkowski and Vauthey1995] Strzalkowski,\nTomek\nand Barbara Vauthey. 1995. Information retrieval\nusing robust natural language processing. In AAAI\nSpring Symposium on Representation and Acquisi-\ntion of Lexical Information, pages 104–111, Stanford.\n[Summers1988] Summers, Della.\n1988.\nThe role of\ndictionaries in language learning.\nIn R. A. Carter\nand M. McCarthy, editors, Vocabulary and Language\nTeaching. Longman, London, pages 111–125.\n[Whittemore, Ferrara, and Brunner1990] Whittemore,\nGreg, Kathleen Ferrara, and Hans Brunner.\n1990.\nEmpirical study of predictive powers of simple at-\ntachment schemes for post-modiﬁer prepositional\nphrases. In ACL Proceedings, 28th Annual Meeting,\npages 23–30, Pittsburgh.\n[Yarowsky1995] Yarowsky, David. 1995. Unsupervised\nword sense disambiguation rivalling supervised meth-\nods. In ACL 95, pages 189–196, MIT.\n6\n",
  "categories": [
    "cmp-lg",
    "cs.CL"
  ],
  "published": "1997-12-23",
  "updated": "1997-12-23"
}